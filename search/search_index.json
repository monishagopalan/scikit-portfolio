{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to scikit-portfolio \u00b6 Scikit-portfolio is a Python package designed to introduce data scientists and machine learning engineers to the problem of optimal portfolio allocation in finance . The main idea of scikit-portfolio is to provide many well-known portfolio optimization methods with an easily accessible scikit-learn inspired set of API. This approach makes it possible to incorporate portfolio estimators as if they are classical scikit-learn estimators , thus enabling cross-validation and hyperparameters optimization with the tools of the Python data-science toolkit, and with an eye the highly technical domain of investment portfolio management. This library is based upon the following open-source tools: PyPortfolioOpt cvxpy : a tool for convex optimization that makes it very easy to write optimization problem, with complex objective functions and constraints. numpy : numerical analysis and linear algebra in Python pandas : manipulation of structured data tables in Python. Getting started \u00b6 If you already have some background of portfolio optimization, and just want to jump start into the usage of the library, read here\ud83d\udcbb\ufe0f\u270d\ufe0f . Otherwise if you are relatively new to financial portfolio optimization, read this introduction \ud83d\udc68\u200d\ud83c\udf93\ufe0f , where we provide the reader a coincise overview over the main ideas and methods in portfolio optimization.","title":"Home"},{"location":"#welcome-to-scikit-portfolio","text":"Scikit-portfolio is a Python package designed to introduce data scientists and machine learning engineers to the problem of optimal portfolio allocation in finance . The main idea of scikit-portfolio is to provide many well-known portfolio optimization methods with an easily accessible scikit-learn inspired set of API. This approach makes it possible to incorporate portfolio estimators as if they are classical scikit-learn estimators , thus enabling cross-validation and hyperparameters optimization with the tools of the Python data-science toolkit, and with an eye the highly technical domain of investment portfolio management. This library is based upon the following open-source tools: PyPortfolioOpt cvxpy : a tool for convex optimization that makes it very easy to write optimization problem, with complex objective functions and constraints. numpy : numerical analysis and linear algebra in Python pandas : manipulation of structured data tables in Python.","title":"Welcome to scikit-portfolio"},{"location":"#getting-started","text":"If you already have some background of portfolio optimization, and just want to jump start into the usage of the library, read here\ud83d\udcbb\ufe0f\u270d\ufe0f . Otherwise if you are relatively new to financial portfolio optimization, read this introduction \ud83d\udc68\u200d\ud83c\udf93\ufe0f , where we provide the reader a coincise overview over the main ideas and methods in portfolio optimization.","title":"Getting started"},{"location":"backtesting/","text":"Backtesting \u00b6","title":"Backtesting"},{"location":"backtesting/#backtesting","text":"","title":"Backtesting"},{"location":"datasets/","text":"Datasets \u00b6 scikit-portfolio contains a small number of datasets, mostly used for testing and demonstration purpose. Once loaded they are cached in the home directory under the .skportfolio hidden folder, similarly to what is done with seaborn . Technological stock prices \u00b6 This small dataset contains almost five years of adjusted closing prices of technological stocks: Apple (AAPL), Microsoft (MSFT), Tesla (TSLA), Amazon (AMZN) and Microstrategy (MSTR). The data have been obtained through the excellent Python package yfinance Simulated normal returns \u00b6 These simulated returns are obtained from the Matlab financial toolbox, with random seed set to 42. rng(42) m = [ 0.05; 0.1; 0.12; 0.18 ]; C = [ 0.0064 0.00408 0.00192 0; 0.00408 0.0289 0.0204 0.0119; 0.00192 0.0204 0.0576 0.0336; 0 0.0119 0.0336 0.1225 ]; m = m/12; C = C/12; AssetScenarios = mvnrnd(m, C, 20000); This tool is very useful for testing against commercial implementations of various portfolio optimization methods, see for example the tests in efficient MAD SP500 prices \u00b6 SP500 index price NASDAQ100 prices \u00b6 NASDAQ100 prices","title":"Datasets"},{"location":"datasets/#datasets","text":"scikit-portfolio contains a small number of datasets, mostly used for testing and demonstration purpose. Once loaded they are cached in the home directory under the .skportfolio hidden folder, similarly to what is done with seaborn .","title":"Datasets"},{"location":"datasets/#technological-stock-prices","text":"This small dataset contains almost five years of adjusted closing prices of technological stocks: Apple (AAPL), Microsoft (MSFT), Tesla (TSLA), Amazon (AMZN) and Microstrategy (MSTR). The data have been obtained through the excellent Python package yfinance","title":"Technological stock prices"},{"location":"datasets/#simulated-normal-returns","text":"These simulated returns are obtained from the Matlab financial toolbox, with random seed set to 42. rng(42) m = [ 0.05; 0.1; 0.12; 0.18 ]; C = [ 0.0064 0.00408 0.00192 0; 0.00408 0.0289 0.0204 0.0119; 0.00192 0.0204 0.0576 0.0336; 0 0.0119 0.0336 0.1225 ]; m = m/12; C = C/12; AssetScenarios = mvnrnd(m, C, 20000); This tool is very useful for testing against commercial implementations of various portfolio optimization methods, see for example the tests in efficient MAD","title":"Simulated normal returns"},{"location":"datasets/#sp500-prices","text":"SP500 index price","title":"SP500 prices"},{"location":"datasets/#nasdaq100-prices","text":"NASDAQ100 prices","title":"NASDAQ100 prices"},{"location":"docker/","text":"Docker \u00b6 You can use scikit-portfolio through docker, provided you have docker installed or available in your system. Docker makes development efficient and predictable. Docker takes away repetitive, mundane configuration tasks and is used throughout the development lifecycle for fast, easy and portable application development \u2013 desktop and cloud. Docker\u2019s comprehensive end to end platform includes UIs, CLIs, APIs and security that are engineered to work together across the entire application delivery lifecycle. Docker build \u00b6 From root of repo issue the following command docker build -f docker/Dockerfile . -t skportfolio Docker run an interpreter \u00b6 You can start an IPython interpreter docker run -it skportfolio poetry run ipython or even a Jupyter notebook that you can remotely connect to! docker run -it -p 8888:8888 skportfolio poetry run jupyter notebook --allow-root --no-browser --ip 0.0.0.0 Then open a browser pointing at http://127.0.0.1:8888/?token=xxx where xxx is the token indicated by the output of the above command. Docker run pytest \u00b6 docker run -t skportfolio poetry run pytest Docker open a bash shell \u00b6 docker run -it skportfolio bash","title":"Docker"},{"location":"docker/#docker","text":"You can use scikit-portfolio through docker, provided you have docker installed or available in your system. Docker makes development efficient and predictable. Docker takes away repetitive, mundane configuration tasks and is used throughout the development lifecycle for fast, easy and portable application development \u2013 desktop and cloud. Docker\u2019s comprehensive end to end platform includes UIs, CLIs, APIs and security that are engineered to work together across the entire application delivery lifecycle.","title":"Docker"},{"location":"docker/#docker-build","text":"From root of repo issue the following command docker build -f docker/Dockerfile . -t skportfolio","title":"Docker build"},{"location":"docker/#docker-run-an-interpreter","text":"You can start an IPython interpreter docker run -it skportfolio poetry run ipython or even a Jupyter notebook that you can remotely connect to! docker run -it -p 8888:8888 skportfolio poetry run jupyter notebook --allow-root --no-browser --ip 0.0.0.0 Then open a browser pointing at http://127.0.0.1:8888/?token=xxx where xxx is the token indicated by the output of the above command.","title":"Docker run an interpreter"},{"location":"docker/#docker-run-pytest","text":"docker run -t skportfolio poetry run pytest","title":"Docker run pytest"},{"location":"docker/#docker-open-a-bash-shell","text":"docker run -it skportfolio bash","title":"Docker open a bash shell"},{"location":"efficient_cdar/","text":"Efficient Conditional Drawdown At Risk Frontier \u00b6 Conditional drawdown at risk is a measure often used in portfolio optimization for effective risk management introduced by Cheklov, Uryasev and Zabarankin in 2000 1 , 2 . The CDar (conditional drawdown-at-risk) is the average of all drawdowns for all the instances that drawdown exceeded a certain threshold. Drawdown is a measure of downside risk. Conditional drawdown is the average of all drawdowns, or cumulative losses, in excess of a certain threshold. That threshold is referred to as drawdown-at-risk. It is very similar to how expected shortfall is defined. CDar in the context of portfolio optimization was first proposed by Alexeei Chekhlov, Stanislav Uryasev and Michael Zabarankin in 2003. The main goal of their paper was to show that the optimization of CDar can be solved using linear programming, a kind of problems that cvxpy is very good at solving. Following the specifics present at the PyPortfolioOpt documentation , the notation required to formulate the drawdown concept mathematically is the following: \\begin{equation} \\textrm{CDaR}(\\mathbf{w}, \\beta) = \\frac{1}{1-\\beta} \\int_{D(w,r,t) \\geq \\alpha(w)} D(w,r,t) p(r(t)) d r(t) \\end{equation} In the above expression the quantities are \\(\\mathbf{w}\\) is the vector of portfolio weights \\(\\mathbf{r}\\) is the vector of cumulative asset returns (daily), with p.m.f \\(p(\\mathbf{r}(t))\\) . \\(D(\\mathbf{w},\\mathbf{r},t) = \\max_{r < t}\\left( \\mathbf{w}^T r(\\tau) - \\mathbf{w}^T\\mathbf{r}(t)\\right)\\) is the drawdown of the portfolio. \\(\\alpha\\) is the portfolio drawdown (DaR) with confidence \\(\\beta\\) . The portfolio conditional drawdown at risk is based on using portoflio drawdowns rathar than returns. For the definition look here and the original PyPortfolioOpt version . Here we offer three specific classes to handle the efficient CDar frontier, namely the portfolio with the Minimum CDar, and the portfolios of lowest CDar given target return or the highest return given CDar. Minimum CDar portfolio \u00b6 The minimum CDar portfolio identifies the point with the least Conditional Drawdown at risk along the CDar efficient frontier. The optimization problem is solved through the MinimumCDar class. Efficient return on mean-cdar frontier \u00b6 The efficient return CDar-frontier portfolio identifies the point with the least Conditional Drawdown at risk along the CDar efficient frontier, conditioned on having at least the specified target return. The optimization problem is solved through the CDarEfficientReturn class. Efficient risk on mean-cdar frontier \u00b6 The efficient risk CDar-frontier portfolio identifies the point with the highest return having at most the target Conditional Drawdown at risk. The optimization problem is solved through the CDarEfficientRisk class. References \u00b6 Chekhlov, Alexei, Stanislav Uryasev, and Michael Zabarankin. \"Portfolio optimization with drawdown constraints.\" Supply chain and finance. 2004. 209-228. \u21a9 Chekhlov, Alexei, Stanislav Uryasev, and Michael Zabarankin. \"Drawdown measure in portfolio optimization.\" International Journal of Theoretical and Applied Finance 8.01 (2005): 13-58. \u21a9","title":"Conditional Drawdown At Risk"},{"location":"efficient_cdar/#efficient-conditional-drawdown-at-risk-frontier","text":"Conditional drawdown at risk is a measure often used in portfolio optimization for effective risk management introduced by Cheklov, Uryasev and Zabarankin in 2000 1 , 2 . The CDar (conditional drawdown-at-risk) is the average of all drawdowns for all the instances that drawdown exceeded a certain threshold. Drawdown is a measure of downside risk. Conditional drawdown is the average of all drawdowns, or cumulative losses, in excess of a certain threshold. That threshold is referred to as drawdown-at-risk. It is very similar to how expected shortfall is defined. CDar in the context of portfolio optimization was first proposed by Alexeei Chekhlov, Stanislav Uryasev and Michael Zabarankin in 2003. The main goal of their paper was to show that the optimization of CDar can be solved using linear programming, a kind of problems that cvxpy is very good at solving. Following the specifics present at the PyPortfolioOpt documentation , the notation required to formulate the drawdown concept mathematically is the following: \\begin{equation} \\textrm{CDaR}(\\mathbf{w}, \\beta) = \\frac{1}{1-\\beta} \\int_{D(w,r,t) \\geq \\alpha(w)} D(w,r,t) p(r(t)) d r(t) \\end{equation} In the above expression the quantities are \\(\\mathbf{w}\\) is the vector of portfolio weights \\(\\mathbf{r}\\) is the vector of cumulative asset returns (daily), with p.m.f \\(p(\\mathbf{r}(t))\\) . \\(D(\\mathbf{w},\\mathbf{r},t) = \\max_{r < t}\\left( \\mathbf{w}^T r(\\tau) - \\mathbf{w}^T\\mathbf{r}(t)\\right)\\) is the drawdown of the portfolio. \\(\\alpha\\) is the portfolio drawdown (DaR) with confidence \\(\\beta\\) . The portfolio conditional drawdown at risk is based on using portoflio drawdowns rathar than returns. For the definition look here and the original PyPortfolioOpt version . Here we offer three specific classes to handle the efficient CDar frontier, namely the portfolio with the Minimum CDar, and the portfolios of lowest CDar given target return or the highest return given CDar.","title":"Efficient Conditional Drawdown At Risk Frontier"},{"location":"efficient_cdar/#minimum-cdar-portfolio","text":"The minimum CDar portfolio identifies the point with the least Conditional Drawdown at risk along the CDar efficient frontier. The optimization problem is solved through the MinimumCDar class.","title":"Minimum CDar portfolio"},{"location":"efficient_cdar/#efficient-return-on-mean-cdar-frontier","text":"The efficient return CDar-frontier portfolio identifies the point with the least Conditional Drawdown at risk along the CDar efficient frontier, conditioned on having at least the specified target return. The optimization problem is solved through the CDarEfficientReturn class.","title":"Efficient return on mean-cdar frontier"},{"location":"efficient_cdar/#efficient-risk-on-mean-cdar-frontier","text":"The efficient risk CDar-frontier portfolio identifies the point with the highest return having at most the target Conditional Drawdown at risk. The optimization problem is solved through the CDarEfficientRisk class.","title":"Efficient risk on mean-cdar frontier"},{"location":"efficient_cdar/#references","text":"Chekhlov, Alexei, Stanislav Uryasev, and Michael Zabarankin. \"Portfolio optimization with drawdown constraints.\" Supply chain and finance. 2004. 209-228. \u21a9 Chekhlov, Alexei, Stanislav Uryasev, and Michael Zabarankin. \"Drawdown measure in portfolio optimization.\" International Journal of Theoretical and Applied Finance 8.01 (2005): 13-58. \u21a9","title":"References"},{"location":"efficient_cdar_api/","text":"Conditional Drawdown at Risk \u00b6 Minimum CDaR \u00b6 class skportfolio.frontier._efficientfrontier. MinimumCDar ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False ) Bases skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum Conditional DaR portfolio Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient return optimization on CDaR frontier \u00b6 class skportfolio.frontier._efficientfrontier. CDarEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient return at given target CVar Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient risk optimization on CDaR frontier \u00b6 class skportfolio.frontier._efficientfrontier. CDarEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient CVar at given target return Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Conditional Drawdown At Risk (CDaR)"},{"location":"efficient_cdar_api/#conditional-drawdown-at-risk","text":"","title":"Conditional Drawdown at Risk"},{"location":"efficient_cdar_api/#minimum-cdar","text":"class skportfolio.frontier._efficientfrontier. MinimumCDar ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False ) Bases skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum Conditional DaR portfolio Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum CDaR"},{"location":"efficient_cdar_api/#efficient-return-optimization-on-cdar-frontier","text":"class skportfolio.frontier._efficientfrontier. CDarEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient return at given target CVar Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient return optimization on CDaR frontier"},{"location":"efficient_cdar_api/#efficient-risk-optimization-on-cdar-frontier","text":"class skportfolio.frontier._efficientfrontier. CDarEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._EfficientCDarEstimator skportfolio.frontier._mixins._EfficientCDarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient CVar at given target return Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient risk optimization on CDaR frontier"},{"location":"efficient_cvar/","text":"Efficient Conditional Value At Risk Frontier \u00b6 Conditional value at risk is a measure often used in portfolio optimization for effective risk management . The CVar (conditional value-at-risk) also called expected shortfall is a popular measure of tail risk . CVaR is derived by taking a weighted average of the \"extreme\" losses in the tail of the distribution of possible returns, beyond the value at risk (VaR) cutoff point \\(\\beta\\) . For example, if we calculate the CVaR to be 10% for \\(\\beta=0.95\\) , we can be \\(95\\%\\) confident that the worst-case average daily loss will be 3 %. In other words, one can see CVar in terms of percentiles, so that it boils down to the average of all losses so severe that they only occur \\((1\u2212\\beta)\\%\\) of the times. We will adopt the following notation: w for the vector of portfolio weights r for a vector of asset returns (daily), with probability distribution \\(p(r)\\) . \\(L(w, r) = - w^T r\\) for the loss of the portfolio \\(\\alpha\\) for the portfolio value-at-risk (VaR) with confidence \\(\\beta\\) . The CVaR can then be written as: \\[\\begin{equation} CVaR(w, \\beta) = \\frac{1}{1-\\beta} \\int_{L(w, r) \\geq \\alpha (w)} L(w, r) p(r)dr. \\end{equation}\\] This is a nasty expression to optimize because we are essentially integrating over VaR values. The key insight of Rockafellar and Uryasev (2001) 1 is that we can can equivalently optimize the following convex function: \\[\\begin{equation} F_\\beta (w, \\alpha) = \\alpha + \\frac{1}{1-\\beta} \\int [-w^T r - \\alpha]^+ p(r) dr, \\end{equation}\\] where \\([x]^+ = \\max(x, 0)\\) . The authors prove that minimising \\(F_\\beta(w, \\alpha)\\) over all \\(w, \\alpha\\) minimises the CVaR. Suppose we have a sample of T daily returns (these can either be historical or simulated). The integral in the expression becomes a sum, so the CVaR optimization problem reduces to a linear program: \\[\\begin{equation*} \\begin{aligned} & \\underset{w, \\alpha}{\\text{minimise}} & & \\alpha + \\frac{1}{1-\\beta} \\frac 1 T \\sum_{i=1}^T u_i \\\\ & \\text{subject to} & & u_i \\geq 0 \\\\ &&& u_i \\geq -w^T r_i - \\alpha. \\\\ \\end{aligned} \\end{equation*}\\] This formulation introduces a new variable for each datapoint (similar to Efficient Semivariance), so you may run into performance issues for long returns dataframes. At the same time, you should aim to provide a sample of data that is large enough to include tail events. Minimum CVar portfolio \ud83d\udcd6 \u00b6 Efficient return on mean-cvar frontier \ud83d\udcd6 \u00b6 Efficient risk on mean-cvar frontier \ud83d\udcd6 \u00b6 References \u00b6 Chekhlov, A.; Rockafellar, R.; Uryasev, D. (2005). Drawdown measure in portfolio optimization \u21a9","title":"Conditional Value At Risk"},{"location":"efficient_cvar/#efficient-conditional-value-at-risk-frontier","text":"Conditional value at risk is a measure often used in portfolio optimization for effective risk management . The CVar (conditional value-at-risk) also called expected shortfall is a popular measure of tail risk . CVaR is derived by taking a weighted average of the \"extreme\" losses in the tail of the distribution of possible returns, beyond the value at risk (VaR) cutoff point \\(\\beta\\) . For example, if we calculate the CVaR to be 10% for \\(\\beta=0.95\\) , we can be \\(95\\%\\) confident that the worst-case average daily loss will be 3 %. In other words, one can see CVar in terms of percentiles, so that it boils down to the average of all losses so severe that they only occur \\((1\u2212\\beta)\\%\\) of the times. We will adopt the following notation: w for the vector of portfolio weights r for a vector of asset returns (daily), with probability distribution \\(p(r)\\) . \\(L(w, r) = - w^T r\\) for the loss of the portfolio \\(\\alpha\\) for the portfolio value-at-risk (VaR) with confidence \\(\\beta\\) . The CVaR can then be written as: \\[\\begin{equation} CVaR(w, \\beta) = \\frac{1}{1-\\beta} \\int_{L(w, r) \\geq \\alpha (w)} L(w, r) p(r)dr. \\end{equation}\\] This is a nasty expression to optimize because we are essentially integrating over VaR values. The key insight of Rockafellar and Uryasev (2001) 1 is that we can can equivalently optimize the following convex function: \\[\\begin{equation} F_\\beta (w, \\alpha) = \\alpha + \\frac{1}{1-\\beta} \\int [-w^T r - \\alpha]^+ p(r) dr, \\end{equation}\\] where \\([x]^+ = \\max(x, 0)\\) . The authors prove that minimising \\(F_\\beta(w, \\alpha)\\) over all \\(w, \\alpha\\) minimises the CVaR. Suppose we have a sample of T daily returns (these can either be historical or simulated). The integral in the expression becomes a sum, so the CVaR optimization problem reduces to a linear program: \\[\\begin{equation*} \\begin{aligned} & \\underset{w, \\alpha}{\\text{minimise}} & & \\alpha + \\frac{1}{1-\\beta} \\frac 1 T \\sum_{i=1}^T u_i \\\\ & \\text{subject to} & & u_i \\geq 0 \\\\ &&& u_i \\geq -w^T r_i - \\alpha. \\\\ \\end{aligned} \\end{equation*}\\] This formulation introduces a new variable for each datapoint (similar to Efficient Semivariance), so you may run into performance issues for long returns dataframes. At the same time, you should aim to provide a sample of data that is large enough to include tail events.","title":"Efficient Conditional Value At Risk Frontier"},{"location":"efficient_cvar/#minimum-cvar-portfolio","text":"","title":"Minimum CVar portfolio \ud83d\udcd6"},{"location":"efficient_cvar/#efficient-return-on-mean-cvar-frontier","text":"","title":"Efficient return on mean-cvar frontier \ud83d\udcd6"},{"location":"efficient_cvar/#efficient-risk-on-mean-cvar-frontier","text":"","title":"Efficient risk on mean-cvar frontier \ud83d\udcd6"},{"location":"efficient_cvar/#references","text":"Chekhlov, A.; Rockafellar, R.; Uryasev, D. (2005). Drawdown measure in portfolio optimization \u21a9","title":"References"},{"location":"efficient_cvar_api/","text":"Conditional Value at Risk \u00b6 Minimum CVaR \u00b6 class skportfolio.frontier._efficientfrontier. MinimumCVar ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False ) Bases skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum Conditional Var portfolio Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient return optimization on CVaR frontier \u00b6 class skportfolio.frontier._efficientfrontier. CVarEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient return at given target CVar Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient risk optimization on CDaR frontier \u00b6 class skportfolio.frontier._efficientfrontier. CVarEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient CVar at given target return Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Conditional Value At Risk (CVaR)"},{"location":"efficient_cvar_api/#conditional-value-at-risk","text":"","title":"Conditional Value at Risk"},{"location":"efficient_cvar_api/#minimum-cvar","text":"class skportfolio.frontier._efficientfrontier. MinimumCVar ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False ) Bases skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum Conditional Var portfolio Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum CVaR"},{"location":"efficient_cvar_api/#efficient-return-optimization-on-cvar-frontier","text":"class skportfolio.frontier._efficientfrontier. CVarEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient return at given target CVar Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient return optimization on CVaR frontier"},{"location":"efficient_cvar_api/#efficient-risk-optimization-on-cdar-frontier","text":"class skportfolio.frontier._efficientfrontier. CVarEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , beta=0.95 , rets_estimator=MeanHistoricalLinearReturns() , market_neutral=False , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._EfficientCVarEstimator skportfolio.frontier._mixins._EfficientCVarMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseCVarCDarEstimator skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Efficient CVar at given target return Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient risk optimization on CDaR frontier"},{"location":"efficient_frontier/","text":"Classical Markowitz Mean-Variance optimization \u00b6 In the classical mean-variance optimization one seeks a combination of asset weights that optimize either the volatility measured by standard deviation of asset returns, given a target return, or maximizes the return given an upper bound on the volatility. Maximum Sharpe ratio portfolio for example, is given by the selection of weights maximizing the ratio of expected returns and volatility given a risk-free rate, typically implied by bonds, which are carrying no risk. The efficient frontier is the set of optimal portfolios that provides the highest expected return for a given level of risk, or the lowest risk for a given level of expected return. Portfolios that do not correspond with the efficient frontier are sub-optimal by definition. The efficient frontier is commonly depicted as a hyperbola, with the portfolio return on the vertical axis and risk or volatility on the horizontal axis, like in the following figure: Note In the picture above, the maximum return portfolio always corresponds to the portfolio weighted 100% on the riskiest asset , that is also coincident with maximum volatility (\ud83d\udd35\ufe0f blue dot in the upper right part of the efficient frontier plot). The minimum risk portfolio instead corresponds to the \ud83d\udfe2 green dot at the left spectrum of the lowest risk and lowest return. All other black dots \u26ab\ufe0f are portfolios consisting of a single asset. Minimum volatility \ud83d\udcd6 \u00b6 Calculates the portfolio with the least volatility over the efficient frontier, namely the green dot \ud83d\udfe2 in the Markowitz mean-variance efficient frontier. This portfolio algorithm requires no estimates on expected returns, hence its estimation is typically considered more robust than other points along the frontier. The optimal weights are determined by the following portfolio optimization problem, where portfolio volatility is minimized: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w} \\in [0,1]^N}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol{\\Sigma} \\mathbf{w} \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\] Additional constraints can be added manually by specifiying with the add_constraint method Example usage \u00b6 The basic usage of the class is very easy, in one line you fit the MinimumVolatility portfolio and get the weights from skportfolio.frontier import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices MinimumVolatility().fit(prices).weights_ # or fit portfolio on returns, but apply weights on prices MinimumVolatility(returns_data=True).fit(returns).predict(prices) Altenatively, one can modify the risk estimator. Rather than the SampleCovariance , other covariance estimators can be chosen, such as the weighted exponential moving average of covariance CovarianceExp (see the returns and risk estimators section : from skportfolio import CovarianceExp from skportfolio.frontier import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices import matplotlib.pyplot as plt import pandas as pd prices = load_tech_stock_prices() # compare the two allocations between sample covariance and exponentially moving weighted average covariance with a span of 180 days w_sample_cov = MinimumVolatility(frequency=252).fit(prices).weights_.rename('Min Vol - sample covariance') w_cov_exp = MinimumVolatility(risk_estimator=CovarianceExp(frequency=252, span=180), frequency=252).fit(load_tech_stock_prices()).weights_.rename('MinVol-CovarianceExp') pd.concat([w_sample_cov, w_cov_exp], axis=1).plot.bar() plt.grid(True) Note In this example, the optimization problem is the same, but one can observe some differences in terms of allocation. This is mainly due to the different covariance estimator. The best covariance estimator must always be chosen by backtesting on data and looking at the best cross-validation score. For more information, look at the backtesting section. Efficient return on mean variance frontier \ud83d\udcd6 \u00b6 Calculates the portfolio over the efficient frontier given target portfolio return \\(\\rho_P^\\star\\) . It explicitly solves the following optimization problem, where portfolio volatility is minimized given a lower bound on portfolio returns \\(\\mathbf{w}^T \\boldsymbol \\mu\\) : \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol \\Sigma \\mathbf{w} \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq \\rho_P^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\] Example usage \u00b6 from skportfolio.frontier import MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices, with target_return set in initialization MeanVarianceEfficientReturn(target_return=0.05).fit(prices).weights_ # or fit portfolio on returns, changing target return and applying weights on prices MeanVarianceEfficientReturn(returns_data=True).set_target_return(target_return=0.05).fit(returns).predict(prices) Efficient risk on mean variance frontier \ud83d\udcd6 \u00b6 Calculates the portfolio over the efficient frontier given target portfolio volatility \\(\\sigma_P^\\star\\) . It explicitly solves the following optimization problem, where portfolio return is maximized given an upper limit to portfolio volatility \\(\\sigma^\\star_P\\) . \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{maximize}} & & \\mathbf{w}^T \\boldsymbol \\mu \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol{\\Sigma} \\mathbf{w} \\leq \\sigma^{2\\star}_P \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\] Example usage \u00b6 from skportfolio.frontier import MeanVarianceEfficientRisk from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices, with target_return set in initialization MeanVarianceEfficientRisk(target_return=0.05).fit(prices).weights_ # or fit portfolio on returns, changing target return and applying weights on prices MeanVarianceEfficientRisk(returns_data=True).set_target_risk(target_return=0.05).fit(returns).predict(prices) Plotting the efficient frontier \u00b6 You can simply create the specific portfolio object and call '.plot_frontier' specifying the number of points along the frontier to be computed. All the classes inheriting from _BaseEfficientFrontierPortfolioEstimator have the possibility to explore the efficient frontier, given prices or returns data. Currently, these are the portfolio estimators supporting the .estimate_frontier and .plot_frontier Classic Mean-Variance Mean-Semivariance CVar CDar Mean Absolute Deviation Omega ratio Example \u00b6 Plotting the efficient frontier is very easy. The plot_frontier method accepts a large number of aesthetic arguments to make the visualization more readable and content-rich. Look at the method documentation for further information. from skportfolio import MinimumVolatility, MeanVarianceEfficientRisk from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() ax = MinimumVolatility().fit(prices).plot_frontier(prices, num_portfolios=20) ax = ( MeanVarianceEfficientRisk() .set_target_risk(0.5) .fit(prices) .plot_frontier( prices, num_portfolios=20, show_assets=True, show_only_portfolio=True, ax=ax ) ) The result is the following: References \u00b6 Markowitz H., \"Portfolio selection\", J. Fin, Vol. 7, No. 1. (1952), pp. 77-91 url \u21a9 Markowitz itself noted that the average portfolio return and standard deviation were not good measures. Cited from its 1952 paper: \"One suggestion as to tentative \\(\\mu_i\\) , \\(\\sigma_{ij}\\) to use the observed \\(\\mu_i\\) , \\(\\sigma_{ii}\\) for some period of the past. I believe that better methods, which take into account more information, can be found.\" \u21a9","title":"Classical Mean-Variance"},{"location":"efficient_frontier/#classical-markowitz-mean-variance-optimization","text":"In the classical mean-variance optimization one seeks a combination of asset weights that optimize either the volatility measured by standard deviation of asset returns, given a target return, or maximizes the return given an upper bound on the volatility. Maximum Sharpe ratio portfolio for example, is given by the selection of weights maximizing the ratio of expected returns and volatility given a risk-free rate, typically implied by bonds, which are carrying no risk. The efficient frontier is the set of optimal portfolios that provides the highest expected return for a given level of risk, or the lowest risk for a given level of expected return. Portfolios that do not correspond with the efficient frontier are sub-optimal by definition. The efficient frontier is commonly depicted as a hyperbola, with the portfolio return on the vertical axis and risk or volatility on the horizontal axis, like in the following figure: Note In the picture above, the maximum return portfolio always corresponds to the portfolio weighted 100% on the riskiest asset , that is also coincident with maximum volatility (\ud83d\udd35\ufe0f blue dot in the upper right part of the efficient frontier plot). The minimum risk portfolio instead corresponds to the \ud83d\udfe2 green dot at the left spectrum of the lowest risk and lowest return. All other black dots \u26ab\ufe0f are portfolios consisting of a single asset.","title":"Classical Markowitz Mean-Variance optimization"},{"location":"efficient_frontier/#minimum-volatility","text":"Calculates the portfolio with the least volatility over the efficient frontier, namely the green dot \ud83d\udfe2 in the Markowitz mean-variance efficient frontier. This portfolio algorithm requires no estimates on expected returns, hence its estimation is typically considered more robust than other points along the frontier. The optimal weights are determined by the following portfolio optimization problem, where portfolio volatility is minimized: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w} \\in [0,1]^N}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol{\\Sigma} \\mathbf{w} \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\] Additional constraints can be added manually by specifiying with the add_constraint method","title":"Minimum volatility \ud83d\udcd6"},{"location":"efficient_frontier/#example-usage","text":"The basic usage of the class is very easy, in one line you fit the MinimumVolatility portfolio and get the weights from skportfolio.frontier import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices MinimumVolatility().fit(prices).weights_ # or fit portfolio on returns, but apply weights on prices MinimumVolatility(returns_data=True).fit(returns).predict(prices) Altenatively, one can modify the risk estimator. Rather than the SampleCovariance , other covariance estimators can be chosen, such as the weighted exponential moving average of covariance CovarianceExp (see the returns and risk estimators section : from skportfolio import CovarianceExp from skportfolio.frontier import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices import matplotlib.pyplot as plt import pandas as pd prices = load_tech_stock_prices() # compare the two allocations between sample covariance and exponentially moving weighted average covariance with a span of 180 days w_sample_cov = MinimumVolatility(frequency=252).fit(prices).weights_.rename('Min Vol - sample covariance') w_cov_exp = MinimumVolatility(risk_estimator=CovarianceExp(frequency=252, span=180), frequency=252).fit(load_tech_stock_prices()).weights_.rename('MinVol-CovarianceExp') pd.concat([w_sample_cov, w_cov_exp], axis=1).plot.bar() plt.grid(True) Note In this example, the optimization problem is the same, but one can observe some differences in terms of allocation. This is mainly due to the different covariance estimator. The best covariance estimator must always be chosen by backtesting on data and looking at the best cross-validation score. For more information, look at the backtesting section.","title":"Example usage"},{"location":"efficient_frontier/#efficient-return-on-mean-variance-frontier","text":"Calculates the portfolio over the efficient frontier given target portfolio return \\(\\rho_P^\\star\\) . It explicitly solves the following optimization problem, where portfolio volatility is minimized given a lower bound on portfolio returns \\(\\mathbf{w}^T \\boldsymbol \\mu\\) : \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol \\Sigma \\mathbf{w} \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq \\rho_P^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\]","title":"Efficient return on mean variance frontier \ud83d\udcd6"},{"location":"efficient_frontier/#example-usage_1","text":"from skportfolio.frontier import MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices, with target_return set in initialization MeanVarianceEfficientReturn(target_return=0.05).fit(prices).weights_ # or fit portfolio on returns, changing target return and applying weights on prices MeanVarianceEfficientReturn(returns_data=True).set_target_return(target_return=0.05).fit(returns).predict(prices)","title":"Example usage"},{"location":"efficient_frontier/#efficient-risk-on-mean-variance-frontier","text":"Calculates the portfolio over the efficient frontier given target portfolio volatility \\(\\sigma_P^\\star\\) . It explicitly solves the following optimization problem, where portfolio return is maximized given an upper limit to portfolio volatility \\(\\sigma^\\star_P\\) . \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{maximize}} & & \\mathbf{w}^T \\boldsymbol \\mu \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol{\\Sigma} \\mathbf{w} \\leq \\sigma^{2\\star}_P \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\min} \\leq w_i \\leq w_{\\max}\\\\ \\end{aligned} \\end{equation*}\\end{split}\\]","title":"Efficient risk on mean variance frontier \ud83d\udcd6"},{"location":"efficient_frontier/#example-usage_2","text":"from skportfolio.frontier import MeanVarianceEfficientRisk from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # fit portfolio directly on prices, with target_return set in initialization MeanVarianceEfficientRisk(target_return=0.05).fit(prices).weights_ # or fit portfolio on returns, changing target return and applying weights on prices MeanVarianceEfficientRisk(returns_data=True).set_target_risk(target_return=0.05).fit(returns).predict(prices)","title":"Example usage"},{"location":"efficient_frontier/#plotting-the-efficient-frontier","text":"You can simply create the specific portfolio object and call '.plot_frontier' specifying the number of points along the frontier to be computed. All the classes inheriting from _BaseEfficientFrontierPortfolioEstimator have the possibility to explore the efficient frontier, given prices or returns data. Currently, these are the portfolio estimators supporting the .estimate_frontier and .plot_frontier Classic Mean-Variance Mean-Semivariance CVar CDar Mean Absolute Deviation Omega ratio","title":"Plotting the efficient frontier"},{"location":"efficient_frontier/#example","text":"Plotting the efficient frontier is very easy. The plot_frontier method accepts a large number of aesthetic arguments to make the visualization more readable and content-rich. Look at the method documentation for further information. from skportfolio import MinimumVolatility, MeanVarianceEfficientRisk from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() ax = MinimumVolatility().fit(prices).plot_frontier(prices, num_portfolios=20) ax = ( MeanVarianceEfficientRisk() .set_target_risk(0.5) .fit(prices) .plot_frontier( prices, num_portfolios=20, show_assets=True, show_only_portfolio=True, ax=ax ) ) The result is the following:","title":"Example"},{"location":"efficient_frontier/#references","text":"Markowitz H., \"Portfolio selection\", J. Fin, Vol. 7, No. 1. (1952), pp. 77-91 url \u21a9 Markowitz itself noted that the average portfolio return and standard deviation were not good measures. Cited from its 1952 paper: \"One suggestion as to tentative \\(\\mu_i\\) , \\(\\sigma_{ij}\\) to use the observed \\(\\mu_i\\) , \\(\\sigma_{ii}\\) for some period of the past. I believe that better methods, which take into account more information, can be found.\" \u21a9","title":"References"},{"location":"efficient_frontier_api/","text":"Mean Variance Optimization - efficient frontier API \u00b6 Minimum Volatility \u00b6 class skportfolio.frontier._efficientfrontier. MinimumVolatility ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() ) Bases skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Minimum volatility (minimum variance) portfolio. It does not need estimates of the expected returns, but only estimation of the covariance matrix. The following optimization problem is being solved. Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator MeanVarianceEfficientRisk \u00b6 class skportfolio.frontier._efficientfrontier. MeanVarianceEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() , rets_estimator=MeanHistoricalLinearReturns() , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Efficient risk in the Markowitz's Mean Variance framework. Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y , **kwargs ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None , **kwargs ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator MeanVarianceEfficientReturn \u00b6 class skportfolio.frontier._efficientfrontier. MeanVarianceEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() , rets_estimator=MeanHistoricalLinearReturns() , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Base class for all estimators in scikit-learn. Notes All estimators should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y , **kwargs ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None , **kwargs ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Mean Variance frontier"},{"location":"efficient_frontier_api/#mean-variance-optimization-efficient-frontier-api","text":"","title":"Mean Variance Optimization - efficient frontier API"},{"location":"efficient_frontier_api/#minimum-volatility","text":"class skportfolio.frontier._efficientfrontier. MinimumVolatility ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() ) Bases skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Minimum volatility (minimum variance) portfolio. It does not need estimates of the expected returns, but only estimation of the covariance matrix. The following optimization problem is being solved. Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum Volatility"},{"location":"efficient_frontier_api/#meanvarianceefficientrisk","text":"class skportfolio.frontier._efficientfrontier. MeanVarianceEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() , rets_estimator=MeanHistoricalLinearReturns() , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Efficient risk in the Markowitz's Mean Variance framework. Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y , **kwargs ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None , **kwargs ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"MeanVarianceEfficientRisk"},{"location":"efficient_frontier_api/#meanvarianceefficientreturn","text":"class skportfolio.frontier._efficientfrontier. MeanVarianceEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , risk_estimator=SampleCovariance() , rets_estimator=MeanHistoricalLinearReturns() , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMeanVariancePortfolio skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator skportfolio.frontier._mixins._EfficientMeanVarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin Base class for all estimators in scikit-learn. Notes All estimators should specify all the parameters that can be set at the class level in their __init__ as explicit keyword arguments (no *args or **kwargs ). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y , **kwargs ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. risk_reward ( model ) \u2014 Computes the risk-return for the current portfolio score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method risk_reward ( model=None ) Computes the risk-return for the current portfolio method fit ( X , y=None , **kwargs ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"MeanVarianceEfficientReturn"},{"location":"efficient_mad/","text":"MAD: Mean Absolute Deviation portfolio \u00b6 The portfolio estimators in the efficient MAD frontier implement what is known as mean-absolute deviation portfolio optimization (Konno and Yamazaki, 1993 1 ), which is generally referred to as MAD portfolio optimization. MAD portfolio optimization works with the same return proxies and portfolio sets as mean-variance portfolio optimization but uses mean-absolute deviation or L1-risk as the risk proxy, rather than portfolio volatility \\(\\sqrt{\\mathbf{w}^T\\mathbf{C}\\mathbf{w}}\\) . The L1-risk model involves no quadratic forms, hence it does not scale quadratically with the number of assets, but rather it scales linearly with the number of historical samples. It can be expressed as the average of the excess returns weighted by \\(\\mathbf{w}\\) , as follows: \\begin{equation} \\textrm{L1 risk} = \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack = \\frac{1}{T} \\sum_{t=1}^T \\sum_{i=1}^N \\bigl| (R_{t,i} - \\mu_i) w_i \\bigr| \\end{equation} where \\(\\mathbf{R} \\in \\mathbb{R}^{T \\times N}\\) is the asset returns matrix of \\(N\\) assets over \\(T\\) historical samples, and \\(\\boldsymbol \\mu\\) are the expected returns . In more general terms, the optimization problem solved by the MAD portfolio in the standard settings is the following: \\[\\begin{split}\\begin{equation} \\begin{aligned} \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq r^\\star \\\\ & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ & & w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation}\\end{split}\\] The above problem is linear, and can be implemented in any linear solver. The main advantage of MAD over the classical Markowitz frontier is that, being linear, it exhibits less dependency on small fluctuations of the expected returns. The MAD model is in fact used to solve huge portfolio optimization models including the internationally diversified investment model, the long-term asset liability management (ALM) model and the mortgage-backed security portfolio optimization model. It was recently shown that the MAD model possess several advantageous theoretical properties. In particular, all capital asset pricing model (CAPM)-type relations for the mean-variance model also hold for the MAD model. Furthermore, the MAD model is more compatible with the fundamental principle of rational decision-making 2 . Note In this picture above we show the efficient frontier for the MAD portfolio. On the x-axis the \\(L1\\) risk measure, on the \\(y\\) -axis the portfolio return. The purple lines indicate the efficient risk portfolio \ud83d\udfe3. The solid line is the target risk \\(\\approx 0.035\\) with the resulting return of \\(\\approx 0.09\\) . The green lines indicate the efficient return portfolio \ud83d\udfe2. The solid line is the target return \\(\\approx 0.011\\) with the resulting risk of \\(\\approx 0.05\\) . The black dot \u26ab\ufe0findicates the asset with the highest return and highest risk. The red dot \ud83d\udd34\ufe0f indicates the minimum MAD portfolio. Minimum MAD Portfolio \ud83d\udcd6 \u00b6 It calculates the portfolio minimizing the above L1-risk model, with the weight constraints. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ & & & w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\] Efficient return optimization on MAD frontier \ud83d\udcd6 \u00b6 It calculates the MAD efficient return portfolio, by minimizing the above L1-risk model, subject to a minimum portfolio return above the target return. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq r^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\] Efficient risk optimization on MAD frontier \ud83d\udcd6 \u00b6 It calculates the MAD efficient risk portfolio, by maximizing the portfolio return, subject to a L1-risk above the target risk. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{maximize}} & & \\mathbf{w}^T \\boldsymbol \\mu \\\\ & \\text{subject to} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\leq r^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\] Comparison of results with MATLAB\u2122 PortfolioMAD class. \u00b6 You can compare the construction of the efficient frontier of the MAD portfolio in scikit-portfolio with the ones obtained with an expensive commercial software like Matlab. Here we check that the results are the same up to a very small rounding error. This is likely caused by slight differences between the ECOS solver in scikit-portfolio and the internal linprog solver by MATLAB. Warning To reproduce this result you need the Matlab Financial Toolbox. This example has been run on Matlab 2021b. m = [ 0.05; 0.1; 0.12; 0.18 ]; C = [ 0.0064 0.00408 0.00192 0; 0.00408 0.0289 0.0204 0.0119; 0.00192 0.0204 0.0576 0.0336; 0 0.0119 0.0336 0.1225 ]; m = m/12; C = C/12; AssetScenarios = mvnrnd(m, C, 20000); NumPortfolios = 10 % the output of estimateFrontier is a 10 assets x 4 portfolio weights weights = estimateFrontier(setDefaultConstraints(PortfolioMAD('AssetScenarios',AssetScenarios)),NumPortfolios) weights' The result are the following weights, a 10 by 4 matrix, whose rows sum to 1, with the first row representing the minimum MAD portfolio, and the last row the riskiest portfolio composed by a single asset. ans = 0.8924 0.0365 0.0374 0.0337 0.7235 0.1323 0.0413 0.1029 0.5571 0.2263 0.0427 0.1739 0.3903 0.3205 0.0447 0.2445 0.2207 0.4184 0.0473 0.3136 0.0534 0.5074 0.0566 0.3827 0 0.4406 0.0437 0.5157 0 0.3076 0.0123 0.6801 0 0.1588 0 0.8412 0 0 0 1.0000 Now verify the results by manually reconstructing the frontier by returns with scikit-portfolio . It is very easy to generate the efficient frontier together with its weights with the .estimate_frontier method import numpy as np # here the same parameters as those from MATLAB example m = np.array([ 0.05, 0.1, 0.12, 0.18 ]) C = np.array([[ 0.0064, 0.00408, 0.00192, 0,], [0.00408, 0.0289, 0.0204, 0.0119], [0.00192, 0.0204, 0.0576, 0.0336], [0, 0.0119, 0.0336, 0.1225,]]) m = m/12 C = C/12 r = np.random.multivariate_normal(mean=m,cov=C, size=20000) from skportfolio import MinimumMAD MinimumMAD(returns_data=True).set_n_jobs(-1).estimate_frontier(r)[2] portfolio A B C D 0 0.8916 0.0370 0.0373 0.0340 1 0.7229 0.1328 0.0411 0.1032 2 0.5560 0.2268 0.0436 0.1736 3 0.3899 0.3203 0.0450 0.2447 4 0.2210 0.4172 0.0477 0.3141 5 0.0526 0.5077 0.0572 0.3825 6 0.0000 0.4419 0.0418 0.5163 7 0.0000 0.3074 0.0124 0.6803 8 0.0000 0.1588 0.0000 0.8412 9 0.0000 0.0000 0.0000 1.0000 The resulting output is shown above following, and it only takes 4 seconds! Given the large number of samples ( \\(T=20,000\\) ) we converge to the same result as from MATLAB, but twice as fast ! For completeness here we also report the entire self-explaining code for the generation of 10 points along the efficient frontier. import numpy as np import pandas as pd from skportfolio.frontier._mad import EfficientMeanAbsoluteDeviation from warnings import warn # here the same parameters as those from MATLAB example m = np.array([ 0.05, 0.1, 0.12, 0.18 ]) C = np.array([[ 0.0064, 0.00408, 0.00192, 0,], [0.00408, 0.0289, 0.0204, 0.0119], [0.00192, 0.0204, 0.0576, 0.0336], [0, 0.0119, 0.0336, 0.1225,]]) m = m/12 C = C/12 r = np.random.multivariate_normal(mean=m,cov=C, size=20000) # creates a well-formed dataframe returns = pd.DataFrame(r, columns=['A','B','C','D']) mu = returns.mean() # minimum risk portfolio, frontier starts here w_min = pd.Series( EfficientMeanAbsoluteDeviation( expected_returns=mu, returns=returns ).min_risk(), index=returns.columns ) NumPortfolios = 10 # minimum MAD risk proxy min_risk = np.mean(np.abs(w_min@(returns - mu).T)) # minimum portfolio return of the corresponding weight min_ret = w_min.T @ mu # compute frontier from efficient returns # the 1E-6 is needed to help converge nicely to the highest risk portfolio rets = np.linspace(min_ret, np.max(mu)-1E-6, NumPortfolios) risks = np.array([np.nan]*NumPortfolios) all_weights = [] for i,r in enumerate(rets): try: MAD = EfficientMeanAbsoluteDeviation( expected_returns=mu, returns=returns ) weights = pd.Series( MAD.efficient_return(target_return=r), index=returns.columns ) risks[i] = np.mean(np.abs(weights@(returns-mu).T)) all_weights.append(weights) except Exception as ex: warn(str(ex)) ## in case some solver error is raised, we simply print a warning risks = np.array(risks) all_weights = np.array(all_weights) all_weights.round(4) It is great to see that scikit-portfolio results are highly consistent with those from Matlab's \ud83c\udf89\ufe0f\ud83c\udf89\ufe0f\ud83c\udf89\ufe0f array([[0.8916, 0.037 , 0.0373, 0.034 ], [0.7228, 0.1328, 0.0412, 0.1032], [0.5559, 0.2269, 0.0436, 0.1736], [0.3899, 0.3204, 0.045 , 0.2447], [0.221 , 0.4172, 0.0477, 0.3141], [0.0526, 0.5077, 0.0572, 0.3825], [0. , 0.4419, 0.0418, 0.5163], [0. , 0.3074, 0.0124, 0.6803], [0. , 0.1588, 0. , 0.8412], [0. , 0. , 0. , 1. ]]) As you can see the portfolio weights are almost equal among the two systems, certifying the goodness of the scikit-portfolio implementation. Note In figure above the difference in basis points (1 BP = 0.01%) between the results of Matlab and results of EfficientMeanAbsoluteDeviation . As you can see the two are highly consistent. Colors are the assets in the portfolio, named 0,1,2,3 , while on the x-axis each integer represent the portfolio along the efficient frontier, with 0 being the minimum MAD portfolio and 9 the maximum MAD portfolio, hence the one with the maximum risk. The two efficient frontiers are also shown in the figure below: References \u00b6 Konno, Hiroshi, and Hiroaki Yamazaki. \"Mean-absolute deviation portfolio optimization model and its applications to Tokyo stock market.\" Management science 37.5 (1991): 519-531. https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.37.5.519 \u21a9 Hiroshi Konno & Tomoyuki Koshizuka (2005) Mean-absolute deviation model, IIE Transactions, 37:10, 893-900, DOI: 10.1080/07408170591007786 \u21a9 MATLAB reference manual, for MAD portfolio. https://it.mathworks.com/help/finance/portfoliomad.html \u21a9","title":"Mean Absolute Deviation (MAD)"},{"location":"efficient_mad/#mad-mean-absolute-deviation-portfolio","text":"The portfolio estimators in the efficient MAD frontier implement what is known as mean-absolute deviation portfolio optimization (Konno and Yamazaki, 1993 1 ), which is generally referred to as MAD portfolio optimization. MAD portfolio optimization works with the same return proxies and portfolio sets as mean-variance portfolio optimization but uses mean-absolute deviation or L1-risk as the risk proxy, rather than portfolio volatility \\(\\sqrt{\\mathbf{w}^T\\mathbf{C}\\mathbf{w}}\\) . The L1-risk model involves no quadratic forms, hence it does not scale quadratically with the number of assets, but rather it scales linearly with the number of historical samples. It can be expressed as the average of the excess returns weighted by \\(\\mathbf{w}\\) , as follows: \\begin{equation} \\textrm{L1 risk} = \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack = \\frac{1}{T} \\sum_{t=1}^T \\sum_{i=1}^N \\bigl| (R_{t,i} - \\mu_i) w_i \\bigr| \\end{equation} where \\(\\mathbf{R} \\in \\mathbb{R}^{T \\times N}\\) is the asset returns matrix of \\(N\\) assets over \\(T\\) historical samples, and \\(\\boldsymbol \\mu\\) are the expected returns . In more general terms, the optimization problem solved by the MAD portfolio in the standard settings is the following: \\[\\begin{split}\\begin{equation} \\begin{aligned} \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq r^\\star \\\\ & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ & & w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation}\\end{split}\\] The above problem is linear, and can be implemented in any linear solver. The main advantage of MAD over the classical Markowitz frontier is that, being linear, it exhibits less dependency on small fluctuations of the expected returns. The MAD model is in fact used to solve huge portfolio optimization models including the internationally diversified investment model, the long-term asset liability management (ALM) model and the mortgage-backed security portfolio optimization model. It was recently shown that the MAD model possess several advantageous theoretical properties. In particular, all capital asset pricing model (CAPM)-type relations for the mean-variance model also hold for the MAD model. Furthermore, the MAD model is more compatible with the fundamental principle of rational decision-making 2 . Note In this picture above we show the efficient frontier for the MAD portfolio. On the x-axis the \\(L1\\) risk measure, on the \\(y\\) -axis the portfolio return. The purple lines indicate the efficient risk portfolio \ud83d\udfe3. The solid line is the target risk \\(\\approx 0.035\\) with the resulting return of \\(\\approx 0.09\\) . The green lines indicate the efficient return portfolio \ud83d\udfe2. The solid line is the target return \\(\\approx 0.011\\) with the resulting risk of \\(\\approx 0.05\\) . The black dot \u26ab\ufe0findicates the asset with the highest return and highest risk. The red dot \ud83d\udd34\ufe0f indicates the minimum MAD portfolio.","title":"MAD: Mean Absolute Deviation portfolio"},{"location":"efficient_mad/#minimum-mad-portfolio","text":"It calculates the portfolio minimizing the above L1-risk model, with the weight constraints. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ & & & w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\]","title":"Minimum MAD Portfolio \ud83d\udcd6"},{"location":"efficient_mad/#efficient-return-optimization-on-mad-frontier","text":"It calculates the MAD efficient return portfolio, by minimizing the above L1-risk model, subject to a minimum portfolio return above the target return. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq r^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\]","title":"Efficient return optimization on MAD frontier \ud83d\udcd6"},{"location":"efficient_mad/#efficient-risk-optimization-on-mad-frontier","text":"It calculates the MAD efficient risk portfolio, by maximizing the portfolio return, subject to a L1-risk above the target risk. The optimization problem is the following: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{maximize}} & & \\mathbf{w}^T \\boldsymbol \\mu \\\\ & \\text{subject to} & & \\mathbb{E} \\left \\lbrack \\left| (\\mathbf{R} - \\boldsymbol \\mu)^T \\mathbf{w} \\right| \\right\\rbrack \\leq r^\\star \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{\\textrm{min}} \\leq w_i \\leq w_{\\textrm{max}} \\end{aligned} \\end{equation*}\\end{split}\\]","title":"Efficient risk optimization on MAD frontier \ud83d\udcd6"},{"location":"efficient_mad/#comparison-of-results-with-matlabtm-portfoliomad-class","text":"You can compare the construction of the efficient frontier of the MAD portfolio in scikit-portfolio with the ones obtained with an expensive commercial software like Matlab. Here we check that the results are the same up to a very small rounding error. This is likely caused by slight differences between the ECOS solver in scikit-portfolio and the internal linprog solver by MATLAB. Warning To reproduce this result you need the Matlab Financial Toolbox. This example has been run on Matlab 2021b. m = [ 0.05; 0.1; 0.12; 0.18 ]; C = [ 0.0064 0.00408 0.00192 0; 0.00408 0.0289 0.0204 0.0119; 0.00192 0.0204 0.0576 0.0336; 0 0.0119 0.0336 0.1225 ]; m = m/12; C = C/12; AssetScenarios = mvnrnd(m, C, 20000); NumPortfolios = 10 % the output of estimateFrontier is a 10 assets x 4 portfolio weights weights = estimateFrontier(setDefaultConstraints(PortfolioMAD('AssetScenarios',AssetScenarios)),NumPortfolios) weights' The result are the following weights, a 10 by 4 matrix, whose rows sum to 1, with the first row representing the minimum MAD portfolio, and the last row the riskiest portfolio composed by a single asset. ans = 0.8924 0.0365 0.0374 0.0337 0.7235 0.1323 0.0413 0.1029 0.5571 0.2263 0.0427 0.1739 0.3903 0.3205 0.0447 0.2445 0.2207 0.4184 0.0473 0.3136 0.0534 0.5074 0.0566 0.3827 0 0.4406 0.0437 0.5157 0 0.3076 0.0123 0.6801 0 0.1588 0 0.8412 0 0 0 1.0000 Now verify the results by manually reconstructing the frontier by returns with scikit-portfolio . It is very easy to generate the efficient frontier together with its weights with the .estimate_frontier method import numpy as np # here the same parameters as those from MATLAB example m = np.array([ 0.05, 0.1, 0.12, 0.18 ]) C = np.array([[ 0.0064, 0.00408, 0.00192, 0,], [0.00408, 0.0289, 0.0204, 0.0119], [0.00192, 0.0204, 0.0576, 0.0336], [0, 0.0119, 0.0336, 0.1225,]]) m = m/12 C = C/12 r = np.random.multivariate_normal(mean=m,cov=C, size=20000) from skportfolio import MinimumMAD MinimumMAD(returns_data=True).set_n_jobs(-1).estimate_frontier(r)[2] portfolio A B C D 0 0.8916 0.0370 0.0373 0.0340 1 0.7229 0.1328 0.0411 0.1032 2 0.5560 0.2268 0.0436 0.1736 3 0.3899 0.3203 0.0450 0.2447 4 0.2210 0.4172 0.0477 0.3141 5 0.0526 0.5077 0.0572 0.3825 6 0.0000 0.4419 0.0418 0.5163 7 0.0000 0.3074 0.0124 0.6803 8 0.0000 0.1588 0.0000 0.8412 9 0.0000 0.0000 0.0000 1.0000 The resulting output is shown above following, and it only takes 4 seconds! Given the large number of samples ( \\(T=20,000\\) ) we converge to the same result as from MATLAB, but twice as fast ! For completeness here we also report the entire self-explaining code for the generation of 10 points along the efficient frontier. import numpy as np import pandas as pd from skportfolio.frontier._mad import EfficientMeanAbsoluteDeviation from warnings import warn # here the same parameters as those from MATLAB example m = np.array([ 0.05, 0.1, 0.12, 0.18 ]) C = np.array([[ 0.0064, 0.00408, 0.00192, 0,], [0.00408, 0.0289, 0.0204, 0.0119], [0.00192, 0.0204, 0.0576, 0.0336], [0, 0.0119, 0.0336, 0.1225,]]) m = m/12 C = C/12 r = np.random.multivariate_normal(mean=m,cov=C, size=20000) # creates a well-formed dataframe returns = pd.DataFrame(r, columns=['A','B','C','D']) mu = returns.mean() # minimum risk portfolio, frontier starts here w_min = pd.Series( EfficientMeanAbsoluteDeviation( expected_returns=mu, returns=returns ).min_risk(), index=returns.columns ) NumPortfolios = 10 # minimum MAD risk proxy min_risk = np.mean(np.abs(w_min@(returns - mu).T)) # minimum portfolio return of the corresponding weight min_ret = w_min.T @ mu # compute frontier from efficient returns # the 1E-6 is needed to help converge nicely to the highest risk portfolio rets = np.linspace(min_ret, np.max(mu)-1E-6, NumPortfolios) risks = np.array([np.nan]*NumPortfolios) all_weights = [] for i,r in enumerate(rets): try: MAD = EfficientMeanAbsoluteDeviation( expected_returns=mu, returns=returns ) weights = pd.Series( MAD.efficient_return(target_return=r), index=returns.columns ) risks[i] = np.mean(np.abs(weights@(returns-mu).T)) all_weights.append(weights) except Exception as ex: warn(str(ex)) ## in case some solver error is raised, we simply print a warning risks = np.array(risks) all_weights = np.array(all_weights) all_weights.round(4) It is great to see that scikit-portfolio results are highly consistent with those from Matlab's \ud83c\udf89\ufe0f\ud83c\udf89\ufe0f\ud83c\udf89\ufe0f array([[0.8916, 0.037 , 0.0373, 0.034 ], [0.7228, 0.1328, 0.0412, 0.1032], [0.5559, 0.2269, 0.0436, 0.1736], [0.3899, 0.3204, 0.045 , 0.2447], [0.221 , 0.4172, 0.0477, 0.3141], [0.0526, 0.5077, 0.0572, 0.3825], [0. , 0.4419, 0.0418, 0.5163], [0. , 0.3074, 0.0124, 0.6803], [0. , 0.1588, 0. , 0.8412], [0. , 0. , 0. , 1. ]]) As you can see the portfolio weights are almost equal among the two systems, certifying the goodness of the scikit-portfolio implementation. Note In figure above the difference in basis points (1 BP = 0.01%) between the results of Matlab and results of EfficientMeanAbsoluteDeviation . As you can see the two are highly consistent. Colors are the assets in the portfolio, named 0,1,2,3 , while on the x-axis each integer represent the portfolio along the efficient frontier, with 0 being the minimum MAD portfolio and 9 the maximum MAD portfolio, hence the one with the maximum risk. The two efficient frontiers are also shown in the figure below:","title":"Comparison of results with MATLAB\u2122 PortfolioMAD class."},{"location":"efficient_mad/#references","text":"Konno, Hiroshi, and Hiroaki Yamazaki. \"Mean-absolute deviation portfolio optimization model and its applications to Tokyo stock market.\" Management science 37.5 (1991): 519-531. https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.37.5.519 \u21a9 Hiroshi Konno & Tomoyuki Koshizuka (2005) Mean-absolute deviation model, IIE Transactions, 37:10, 893-900, DOI: 10.1080/07408170591007786 \u21a9 MATLAB reference manual, for MAD portfolio. https://it.mathworks.com/help/finance/portfoliomad.html \u21a9","title":"References"},{"location":"efficient_mad_api/","text":"MAD: Mean Absolute Deviation portfolio \u00b6 Minimum MAD Portfolio MinimumMAD \u00b6 class skportfolio.frontier._efficientfrontier. MinimumMAD ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() ) Bases skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Estimator of the portfoloi with the Minimum mean-absolute deviation Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient return optimization on MAD frontier \u00b6 class skportfolio.frontier._efficientfrontier. MADEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient risk optimization on MAD frontier \u00b6 class skportfolio.frontier._efficientfrontier. MADEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Mean Absolute Deviation (MAD)"},{"location":"efficient_mad_api/#mad-mean-absolute-deviation-portfolio","text":"","title":"MAD: Mean Absolute Deviation portfolio"},{"location":"efficient_mad_api/#minimum-mad-portfolio-minimummad","text":"class skportfolio.frontier._efficientfrontier. MinimumMAD ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() ) Bases skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Estimator of the portfoloi with the Minimum mean-absolute deviation Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum MAD Portfolio MinimumMAD"},{"location":"efficient_mad_api/#efficient-return-optimization-on-mad-frontier","text":"class skportfolio.frontier._efficientfrontier. MADEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient return optimization on MAD frontier"},{"location":"efficient_mad_api/#efficient-risk-optimization-on-mad-frontier","text":"class skportfolio.frontier._efficientfrontier. MADEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMADPortfolio skportfolio.frontier._mixins._EfficientMADMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient risk optimization on MAD frontier"},{"location":"efficient_omega/","text":"Omega ratio \u00b6 A criticism to the classical Sharpe ratio is that it is only appropriate when the portfolio return is elliptically distributed, as it only takes into account only first and second moments of the returns distribution, neglecting other higher order moments. Especially, when the portfolio return is skewed or exhibits fat tails, then the Sharpe Ratio might result in counterintuitive performance evaluations and rankings. To address this issue, Omega ratio has been introduced as a measure of the ratio between risk and rewards that takes into consideration all moments of the portfolio returns distribution. It captures both the downside and upside potential of the constructed portfolio, while remaining consistent with utility maximization. The Omega Ratio makes use of a threshold value \\(\\tau\\) , or minimum acceptable return to distinguish the upside from the downside. This means that portfolio returns above \\(\\tau\\) are considered profits , whereas returns below \\(\\tau\\) are considered as losses . Mathematically, given the cumulative portfolio returns distribution \\(F(r)\\) , Omega ratio is defined as: \\[\\begin{equation} \\Omega(r) = \\dfrac{\\int_{\\tau}^\\infty (1-F(r)) dr}{\\int_{-\\infty}^{\\tau} F(r) dr}. \\end{equation}\\] This concept is well illustrated in the following picture, where the returns cumulative distribution is shown. Here the Omega Ratio is defined as the ratio of the green area over the red area. The green area on the right of the threshold \\(\\tau\\) (in this example 0.0015) and above the cumulative distribution represents the upside potential. The red area on the left of the threshold and below the cumulative distribution represents the downside potential (risk): After some easy manipulation, the Omega ratio can be operationally defined as: \\[\\begin{equation} \\Omega(r_P) = \\dfrac{\\mathbf{w}^T \\boldsymbol \\mu - \\tau}{\\left< (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right >} + 1 \\end{equation}\\] In the expression above, at the numerator we have the expected portfolio return, with \\(\\boldsymbol \\mu\\) being the vector of expected returns, while at the denominator we consider the average \\(\\left< \\cdot \\right>\\) of the positive excess returns, over all temporal samples \\(t=1,\\ldots, T\\) with \\(\\mathbf{R}_t\\) the return of all assets at time \\(t\\) , hence a vector of \\(N\\) assets. The product \\(\\mathbf{w}^T\\mathbf{R}\\) is then to be intended as a matrix product between the \\(N\\) dimensional weights product and the \\(N \\times T\\) dimensional returns matrix. Similarly to the classical mean-variance frontier, it is possible to draw an efficient frontier also for Omega ratio: The frontier is a direct analogue to the mean-variance efficient frontier, whereas in this case the numerators ( return ) and denominator ( volatility ) of the classical Markowitz frontiers are replaced by specific formulas for reward ( Omega numerator ) and risk ( Omega denominator ), operationally defined as: \\[\\begin{split} \\begin{equation*} \\begin{aligned} \\textrm{Omega numerator (reward)} =& \\mathbf{w}^T \\boldsymbol \\mu - \\tau \\\\ \\textrm{Omega denominator (risk)} =& \\sum_{t=1}^T \\max \\left( \\tau - \\mathbf{w}^T \\mathbf{R}_t,\\, 0 \\right ) \\end{aligned} \\end{equation*} \\end{split}\\] The slope of the tangent to the frontier passing through the origin gives the maximum Omega Ratio and indicates the associated portfolio. The affiliated Omega Ratio for each point on the frontier is given by the slope of the line passing through it and the origin. The goal is to find the line with the maximum slope that passes through the origin and a point on the frontier. Since the frontier is non-decreasing and concave, the tangent from the origin to the frontier yields the portfolio with the maximum Omega. Although Omega ratio is a non-convex function, it is possible to express its maximization in terms of a convex optimization trasforming the problem into a linear one, because Omega is quasi-concave in portfolio weights \\(\\mathbf{w}\\) . For the set of prices defined in skportfolio.data.load_tech_stock_prices the Omega efficient frontier is delineated in the following picture: As in the mean-variance case, the maximum return stock is the one with the maximum risk, as quantified by the Omega risk on the x-axis. Similarly to maximum sharpe ratio and minimum volatility, we identify two points on the frontier and the tangent line from the origin touches the frontier exactly at maximum omega ratio point. Small red points are from random uniform portfolios, while the golden dot represents the equally weighted portfolio. Maximum Omega ratio \u00b6 Maximization of the omega ratio is done through linearization of the quasi-convex Omega-ratio problem. Following a recent paper by Kapsos et al 1 , the mathematical optimization problem to find the maximum Omega ratio portfolio in skportfolio is the following: \\[\\begin{split} \\begin{equation*} \\begin{aligned} \\underset{\\mathbf{s}\\in \\mathbb{R}^n, \\mathbf{q}\\in \\mathbb{R}^m, z \\in \\mathbb{R}}{\\text{max}} & \\mathbf{s}^T \\boldsymbol \\mu - \\tau z & \\\\ & q_t \\geq \\tau z - \\mathbf{s}^T \\mathbf{R_t} & \\forall t = 1,\\ldots,T \\\\ & q_t \\geq 0 & \\forall t = 1,\\ldots,T \\\\ & \\mathbf{1}^T \\mathbf{q} = 1 \\\\ & \\mathbf{1}^T \\mathbf{s} = z \\\\ & z w_{\\min} \\leq \\mathbf{s} \\leq z w_{\\max} \\\\ & \\mathbf{s}^T \\boldsymbol \\mu \\geq \\tau z \\\\ & z \\geq 0 \\end{aligned} \\end{equation*} \\end{split}\\] Once solved, the optimal weights are then recovered from the \\(\\mathbf{s}\\) variable after normalization. The above linear program not only ensures global optimality, but is also simple and fast to solve, even if the number of constraints grows linearly with the number of data points (indicated by \\(T\\) ). Note Importantly, here the number of constraints grows linearly with number of temporal samples. The EfficientOmegaRatio class offers a way to subsample the returns at a predetermined fraction of the original, thus making the problem computationally easier to solve. Please refer to the EfficientOmegaRatio class documentation, for the fraction parameter. Minimum Omega Risk \ud83d\udcd6 \u00b6 This portfolio minimizes the denominator in the Omega ratio. It is indeed very similar to the objective function of the Minimum Absolute Deviation portfolio. The minimum Omega risk optimization problem is solved through the EfficientOmegaFrontier interface: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ \\end{aligned} \\end{equation*} \\end{split}\\] Efficient risk on omega-ratio frontier \u00b6 This portfolio minimizes the denominator in the Omega ratio, conditioned on having a return greater than target \\(\\varrho_{\\textrm{target}}\\) . The following optimization problem is solved through the EfficientOmegaFrontier interface via the .efficient_risk method: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& \\mathbf{w}^T \\boldsymbol\\mu - \\tau \\geq \\varrho_{\\textrm{target}} \\end{aligned} \\end{equation*} \\end{split}\\] Efficient return on omega-ratio frontier \u00b6 This portfolio maximizes the numerator of the Omega ratio, conditioned on having a denominator in the Omega ratio greater than target \\(\\rho_{\\textrm{target}}\\) . The following optimization problem is solved through the EfficientOmegaFrontier interface via the efficient_return method: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol\\mu - \\tau \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\leq \\rho_{\\textrm{target}} \\end{aligned} \\end{equation*} \\end{split}\\] References \u00b6 \"Optimizing the Omega Ratio using Linear Programming\", Kapsos M., Zymler S., Christofides N., Rustem B. (2011) url : \u21a9","title":"Omega ratio"},{"location":"efficient_omega/#omega-ratio","text":"A criticism to the classical Sharpe ratio is that it is only appropriate when the portfolio return is elliptically distributed, as it only takes into account only first and second moments of the returns distribution, neglecting other higher order moments. Especially, when the portfolio return is skewed or exhibits fat tails, then the Sharpe Ratio might result in counterintuitive performance evaluations and rankings. To address this issue, Omega ratio has been introduced as a measure of the ratio between risk and rewards that takes into consideration all moments of the portfolio returns distribution. It captures both the downside and upside potential of the constructed portfolio, while remaining consistent with utility maximization. The Omega Ratio makes use of a threshold value \\(\\tau\\) , or minimum acceptable return to distinguish the upside from the downside. This means that portfolio returns above \\(\\tau\\) are considered profits , whereas returns below \\(\\tau\\) are considered as losses . Mathematically, given the cumulative portfolio returns distribution \\(F(r)\\) , Omega ratio is defined as: \\[\\begin{equation} \\Omega(r) = \\dfrac{\\int_{\\tau}^\\infty (1-F(r)) dr}{\\int_{-\\infty}^{\\tau} F(r) dr}. \\end{equation}\\] This concept is well illustrated in the following picture, where the returns cumulative distribution is shown. Here the Omega Ratio is defined as the ratio of the green area over the red area. The green area on the right of the threshold \\(\\tau\\) (in this example 0.0015) and above the cumulative distribution represents the upside potential. The red area on the left of the threshold and below the cumulative distribution represents the downside potential (risk): After some easy manipulation, the Omega ratio can be operationally defined as: \\[\\begin{equation} \\Omega(r_P) = \\dfrac{\\mathbf{w}^T \\boldsymbol \\mu - \\tau}{\\left< (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right >} + 1 \\end{equation}\\] In the expression above, at the numerator we have the expected portfolio return, with \\(\\boldsymbol \\mu\\) being the vector of expected returns, while at the denominator we consider the average \\(\\left< \\cdot \\right>\\) of the positive excess returns, over all temporal samples \\(t=1,\\ldots, T\\) with \\(\\mathbf{R}_t\\) the return of all assets at time \\(t\\) , hence a vector of \\(N\\) assets. The product \\(\\mathbf{w}^T\\mathbf{R}\\) is then to be intended as a matrix product between the \\(N\\) dimensional weights product and the \\(N \\times T\\) dimensional returns matrix. Similarly to the classical mean-variance frontier, it is possible to draw an efficient frontier also for Omega ratio: The frontier is a direct analogue to the mean-variance efficient frontier, whereas in this case the numerators ( return ) and denominator ( volatility ) of the classical Markowitz frontiers are replaced by specific formulas for reward ( Omega numerator ) and risk ( Omega denominator ), operationally defined as: \\[\\begin{split} \\begin{equation*} \\begin{aligned} \\textrm{Omega numerator (reward)} =& \\mathbf{w}^T \\boldsymbol \\mu - \\tau \\\\ \\textrm{Omega denominator (risk)} =& \\sum_{t=1}^T \\max \\left( \\tau - \\mathbf{w}^T \\mathbf{R}_t,\\, 0 \\right ) \\end{aligned} \\end{equation*} \\end{split}\\] The slope of the tangent to the frontier passing through the origin gives the maximum Omega Ratio and indicates the associated portfolio. The affiliated Omega Ratio for each point on the frontier is given by the slope of the line passing through it and the origin. The goal is to find the line with the maximum slope that passes through the origin and a point on the frontier. Since the frontier is non-decreasing and concave, the tangent from the origin to the frontier yields the portfolio with the maximum Omega. Although Omega ratio is a non-convex function, it is possible to express its maximization in terms of a convex optimization trasforming the problem into a linear one, because Omega is quasi-concave in portfolio weights \\(\\mathbf{w}\\) . For the set of prices defined in skportfolio.data.load_tech_stock_prices the Omega efficient frontier is delineated in the following picture: As in the mean-variance case, the maximum return stock is the one with the maximum risk, as quantified by the Omega risk on the x-axis. Similarly to maximum sharpe ratio and minimum volatility, we identify two points on the frontier and the tangent line from the origin touches the frontier exactly at maximum omega ratio point. Small red points are from random uniform portfolios, while the golden dot represents the equally weighted portfolio.","title":"Omega ratio"},{"location":"efficient_omega/#maximum-omega-ratio","text":"Maximization of the omega ratio is done through linearization of the quasi-convex Omega-ratio problem. Following a recent paper by Kapsos et al 1 , the mathematical optimization problem to find the maximum Omega ratio portfolio in skportfolio is the following: \\[\\begin{split} \\begin{equation*} \\begin{aligned} \\underset{\\mathbf{s}\\in \\mathbb{R}^n, \\mathbf{q}\\in \\mathbb{R}^m, z \\in \\mathbb{R}}{\\text{max}} & \\mathbf{s}^T \\boldsymbol \\mu - \\tau z & \\\\ & q_t \\geq \\tau z - \\mathbf{s}^T \\mathbf{R_t} & \\forall t = 1,\\ldots,T \\\\ & q_t \\geq 0 & \\forall t = 1,\\ldots,T \\\\ & \\mathbf{1}^T \\mathbf{q} = 1 \\\\ & \\mathbf{1}^T \\mathbf{s} = z \\\\ & z w_{\\min} \\leq \\mathbf{s} \\leq z w_{\\max} \\\\ & \\mathbf{s}^T \\boldsymbol \\mu \\geq \\tau z \\\\ & z \\geq 0 \\end{aligned} \\end{equation*} \\end{split}\\] Once solved, the optimal weights are then recovered from the \\(\\mathbf{s}\\) variable after normalization. The above linear program not only ensures global optimality, but is also simple and fast to solve, even if the number of constraints grows linearly with the number of data points (indicated by \\(T\\) ). Note Importantly, here the number of constraints grows linearly with number of temporal samples. The EfficientOmegaRatio class offers a way to subsample the returns at a predetermined fraction of the original, thus making the problem computationally easier to solve. Please refer to the EfficientOmegaRatio class documentation, for the fraction parameter.","title":"Maximum Omega ratio"},{"location":"efficient_omega/#minimum-omega-risk","text":"This portfolio minimizes the denominator in the Omega ratio. It is indeed very similar to the objective function of the Minimum Absolute Deviation portfolio. The minimum Omega risk optimization problem is solved through the EfficientOmegaFrontier interface: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ \\end{aligned} \\end{equation*} \\end{split}\\]","title":"Minimum Omega Risk \ud83d\udcd6"},{"location":"efficient_omega/#efficient-risk-on-omega-ratio-frontier","text":"This portfolio minimizes the denominator in the Omega ratio, conditioned on having a return greater than target \\(\\varrho_{\\textrm{target}}\\) . The following optimization problem is solved through the EfficientOmegaFrontier interface via the .efficient_risk method: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& \\mathbf{w}^T \\boldsymbol\\mu - \\tau \\geq \\varrho_{\\textrm{target}} \\end{aligned} \\end{equation*} \\end{split}\\]","title":"Efficient risk on omega-ratio frontier"},{"location":"efficient_omega/#efficient-return-on-omega-ratio-frontier","text":"This portfolio maximizes the numerator of the Omega ratio, conditioned on having a denominator in the Omega ratio greater than target \\(\\rho_{\\textrm{target}}\\) . The following optimization problem is solved through the EfficientOmegaFrontier interface via the efficient_return method: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}\\in \\mathbb{R}^+}{\\text{minimize}} & & \\mathbf{w}^T \\boldsymbol\\mu - \\tau \\\\ & \\text{subject to} & & \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& \\left\\langle (\\tau - \\mathbf{w}^T \\mathbf{R})^+ \\right\\rangle \\leq \\rho_{\\textrm{target}} \\end{aligned} \\end{equation*} \\end{split}\\]","title":"Efficient return on omega-ratio frontier"},{"location":"efficient_omega/#references","text":"\"Optimizing the Omega Ratio using Linear Programming\", Kapsos M., Zymler S., Christofides N., Rustem B. (2011) url : \u21a9","title":"References"},{"location":"efficient_omega_api/","text":"Omega ratio portfolio \u00b6 Maximum Omega Ratio MaxOmegaratio \u00b6 class skportfolio.frontier._efficientfrontier. MaxOmegaRatio ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 ) Bases skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient return optimization on MAD frontier \u00b6 class skportfolio.frontier._efficientfrontier. OmegaEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient risk optimization on MAD frontier \u00b6 class skportfolio.frontier._efficientfrontier. OmegaEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Minimum Omega Risk \u00b6 class skportfolio.frontier._efficientfrontier. MinimumOmegaRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 ) Bases skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Omega Ratio"},{"location":"efficient_omega_api/#omega-ratio-portfolio","text":"","title":"Omega ratio portfolio"},{"location":"efficient_omega_api/#maximum-omega-ratio-maxomegaratio","text":"class skportfolio.frontier._efficientfrontier. MaxOmegaRatio ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 ) Bases skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Maximum Omega Ratio MaxOmegaratio"},{"location":"efficient_omega_api/#efficient-return-optimization-on-mad-frontier","text":"class skportfolio.frontier._efficientfrontier. OmegaEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient return optimization on MAD frontier"},{"location":"efficient_omega_api/#efficient-risk-optimization-on-mad-frontier","text":"class skportfolio.frontier._efficientfrontier. OmegaEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient risk optimization on MAD frontier"},{"location":"efficient_omega_api/#minimum-omega-risk","text":"class skportfolio.frontier._efficientfrontier. MinimumOmegaRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , rets_estimator=MeanHistoricalLinearReturns() , minimum_acceptable_return=0.02 ) Bases skportfolio.frontier._efficientfrontier._BaseOmegaPortfolio skportfolio.frontier._mixins._EfficientOmegaRatioMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum Omega Risk"},{"location":"efficient_repo/","text":"Information theory based portfolio optimization \u00b6 This section collects all the portfolio optimization methods based on information theory. One example of this kind of methods is based on evaluating the volatility through Shannon entropy of returns, the higher the larger the risk. REPO: Returns Entropy Portfolio Optimization \u00b6 Here we provide the implementation of the research paper An Entropy-Based Approach to Portfolio Optimization 1 . The basic idea of the method is to use Shannon entropy of the portfolio returns distribution as the risk proxy. Portfolio Estimator object \u00b6 The REPO optimization aims to solve the following constrained optimization problem: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & H\\left( r_P \\right) \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq \\rho_{\\textrm{target}} \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{min} \\leq \\mathbf{w}_i \\leq w_{max} \\\\ \\end{aligned} \\end{equation*}\\end{split}\\] where \\(H(r_P)\\) is the Shannon entropy of the portfolio returns distribution, \\(r_t = \\sum\\limits_{i=1}^N w_i r_{ti}\\) . The entropy is estimated through a kernel density estimator, regulated parameterized by a number of variables. REPO Function \u00b6 References \u00b6 Mercurio et al. \"An Entropy-Based Approach to Portfolio Optimization\" https://pubmed.ncbi.nlm.nih.gov/33286106/ \u21a9","title":"REPO"},{"location":"efficient_repo/#information-theory-based-portfolio-optimization","text":"This section collects all the portfolio optimization methods based on information theory. One example of this kind of methods is based on evaluating the volatility through Shannon entropy of returns, the higher the larger the risk.","title":"Information theory based portfolio optimization"},{"location":"efficient_repo/#repo-returns-entropy-portfolio-optimization","text":"Here we provide the implementation of the research paper An Entropy-Based Approach to Portfolio Optimization 1 . The basic idea of the method is to use Shannon entropy of the portfolio returns distribution as the risk proxy.","title":"REPO: Returns Entropy Portfolio Optimization"},{"location":"efficient_repo/#portfolio-estimator-object","text":"The REPO optimization aims to solve the following constrained optimization problem: \\[\\begin{split}\\begin{equation*} \\begin{aligned} & \\underset{\\mathbf{w}}{\\text{minimize}} & & H\\left( r_P \\right) \\\\ & \\text{subject to} & & \\mathbf{w}^T \\boldsymbol \\mu \\geq \\rho_{\\textrm{target}} \\\\ &&& \\mathbf{w}^T \\mathbf{1} = 1\\\\ &&& w_{min} \\leq \\mathbf{w}_i \\leq w_{max} \\\\ \\end{aligned} \\end{equation*}\\end{split}\\] where \\(H(r_P)\\) is the Shannon entropy of the portfolio returns distribution, \\(r_t = \\sum\\limits_{i=1}^N w_i r_{ti}\\) . The entropy is estimated through a kernel density estimator, regulated parameterized by a number of variables.","title":"Portfolio Estimator object"},{"location":"efficient_repo/#repo-function","text":"","title":"REPO Function"},{"location":"efficient_repo/#references","text":"Mercurio et al. \"An Entropy-Based Approach to Portfolio Optimization\" https://pubmed.ncbi.nlm.nih.gov/33286106/ \u21a9","title":"References"},{"location":"efficient_semivariance/","text":"Mean-Semivariance frontier \u00b6 Here instead of the classical Markowitz efficient frontier optimization where the covariance is taken into account, we use the semivariance, i.e. the variance of only negative returns, as investors are more interested Here instead of the classical Markowitz efficient frontier optimization where the covariance is taken into account, we use the semivariance, i.e. the variance of only negative returns, as investors are more interested negative volatility, while positive volatility is good. The optimization problem this portfolio method solves is the following: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{w}{\\text{maximise}} & & \\mathbf{w}^T \\boldsymbol \\mu \\newline & \\text{subject to} & & n^T n \\leq s^* \\newline & & & B w - p + n = 0 \\newline & & & w^T \\mathbf{1} = 1 \\newline & & & n \\geq 0 \\newline & & & p \\geq 0. \\newline \\end{aligned} \\end{equation*} \\end{split}\\] where \\(\\boldsymbol \\mu\\) are the expected returns, \\(\\mathbf{B}\\) is the \\(T \\times N\\) scaled matrix of excess returns B = (returns - benchmark) / sqrt(T) . The implementation is based on Markowitz et al. (2019) 1 . Warning As stated on the pyportfolioopt page, finding portfolios on the mean-semivariance frontier is computationally harder than standard mean-variance optimization: the pyportfolioopt implementation uses 2T + N optimization variables, meaning that for 50 assets and 3 years of data, there are about 1500 variables. While EfficientSemivariance allows for additional constraints/objectives in principle, you are much more likely to run into solver errors. I suggest that you keep EfficientSemivariance problems small and minimally constrained. Here we offer three specific portfolio estimators over the mean-semivariance frontier: Minimum semi-volatility \ud83d\udcd6 \u00b6 Efficient return on mean-semivariance frontier \ud83d\udcd6 \u00b6 Efficient risk on mean-semivariance frontier \ud83d\udcd6 \u00b6 References \u00b6 Markowitz et al., \"Avoiding the Downside: a practical review of the critical line algorithm for mean-semivariance portfolio optimization\" https://www.hudsonbaycapital.com/documents/FG/hudsonbay/research/599440_paper.pdf \u21a9","title":"Mean-Semivariance"},{"location":"efficient_semivariance/#mean-semivariance-frontier","text":"Here instead of the classical Markowitz efficient frontier optimization where the covariance is taken into account, we use the semivariance, i.e. the variance of only negative returns, as investors are more interested Here instead of the classical Markowitz efficient frontier optimization where the covariance is taken into account, we use the semivariance, i.e. the variance of only negative returns, as investors are more interested negative volatility, while positive volatility is good. The optimization problem this portfolio method solves is the following: \\[\\begin{split} \\begin{equation*} \\begin{aligned} & \\underset{w}{\\text{maximise}} & & \\mathbf{w}^T \\boldsymbol \\mu \\newline & \\text{subject to} & & n^T n \\leq s^* \\newline & & & B w - p + n = 0 \\newline & & & w^T \\mathbf{1} = 1 \\newline & & & n \\geq 0 \\newline & & & p \\geq 0. \\newline \\end{aligned} \\end{equation*} \\end{split}\\] where \\(\\boldsymbol \\mu\\) are the expected returns, \\(\\mathbf{B}\\) is the \\(T \\times N\\) scaled matrix of excess returns B = (returns - benchmark) / sqrt(T) . The implementation is based on Markowitz et al. (2019) 1 . Warning As stated on the pyportfolioopt page, finding portfolios on the mean-semivariance frontier is computationally harder than standard mean-variance optimization: the pyportfolioopt implementation uses 2T + N optimization variables, meaning that for 50 assets and 3 years of data, there are about 1500 variables. While EfficientSemivariance allows for additional constraints/objectives in principle, you are much more likely to run into solver errors. I suggest that you keep EfficientSemivariance problems small and minimally constrained. Here we offer three specific portfolio estimators over the mean-semivariance frontier:","title":"Mean-Semivariance frontier"},{"location":"efficient_semivariance/#minimum-semi-volatility","text":"","title":"Minimum semi-volatility  \ud83d\udcd6"},{"location":"efficient_semivariance/#efficient-return-on-mean-semivariance-frontier","text":"","title":"Efficient return on mean-semivariance frontier \ud83d\udcd6"},{"location":"efficient_semivariance/#efficient-risk-on-mean-semivariance-frontier","text":"","title":"Efficient risk on mean-semivariance frontier \ud83d\udcd6"},{"location":"efficient_semivariance/#references","text":"Markowitz et al., \"Avoiding the Downside: a practical review of the critical line algorithm for mean-semivariance portfolio optimization\" https://www.hudsonbaycapital.com/documents/FG/hudsonbay/research/599440_paper.pdf \u21a9","title":"References"},{"location":"efficient_semivariance_api/","text":"Efficient semivariance frontier \u00b6 Minimum SemiVolatility \u00b6 class skportfolio.frontier._efficientfrontier. MinimumSemiVolatility ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 ) Bases skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum semi-volatility portfolio. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient return optimization on semi-variance frontier \u00b6 class skportfolio.frontier._efficientfrontier. MeanSemiVarianceEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator Efficient risk optimization on semi-variance frontier \u00b6 class skportfolio.frontier._efficientfrontier. MeanSemiVarianceEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Mean semivariance frontier"},{"location":"efficient_semivariance_api/#efficient-semivariance-frontier","text":"","title":"Efficient semivariance frontier"},{"location":"efficient_semivariance_api/#minimum-semivolatility","text":"class skportfolio.frontier._efficientfrontier. MinimumSemiVolatility ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 ) Bases skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Minimum semi-volatility portfolio. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Minimum SemiVolatility"},{"location":"efficient_semivariance_api/#efficient-return-optimization-on-semi-variance-frontier","text":"class skportfolio.frontier._efficientfrontier. MeanSemiVarianceEfficientReturn ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , target_return=0.02 ) Bases skportfolio.frontier._mixins._TargetReturnMixin skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient return optimization on semi-variance frontier"},{"location":"efficient_semivariance_api/#efficient-risk-optimization-on-semi-variance-frontier","text":"class skportfolio.frontier._efficientfrontier. MeanSemiVarianceEfficientRisk ( returns_data=False , frequency=252 , weight_bounds=(0, 1) , l2_gamma=0.0 , target_risk=0.02 ) Bases skportfolio.frontier._mixins._TargetRiskMixin skportfolio.frontier._efficientfrontier._BaseMeanSemiVariancePortfolio skportfolio.frontier._mixins._EfficientSemivarianceMixin skportfolio.frontier._mixins._BaseFrontierMixin abc.ABC skportfolio.frontier._efficientfrontier._BaseEfficientFrontierPortfolioEstimator skportfolio._base.PortfolioEstimator sklearn.base.BaseEstimator Helper class that provides a standard way to create an ABC using inheritance. Classes ABCMeta \u2014 Metaclass for defining Abstract Base Classes (ABCs). Methods add_constraints ( cnstr ) (object) \u2014 Add a list of constraints to the convex optimization problem estimate_frontier ( X , num_portfolios , random_seed ) (tuple) \u2014 Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. fit ( X , y ) (self) \u2014 Fit the portfolio model from asset prices. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. predict ( X ) (pd.Series) \u2014 Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. score ( X , y , **kwargs ) (float) \u2014 Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. set_dummy_weights ( X ) (A series of assets with NaN weights.) \u2014 Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. set_returns_data ( returns_data ) \u2014 Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . set_returns_estimator ( rets_est ) (self) \u2014 Modify the base returns estimator with a specified rets_est set_risk_estimator ( risk_est ) (self) \u2014 Modify the base risk estimator with a new risk estimator method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method predict ( X ) Applies the estimated weights to the prices to get the portfolio value. In other words, generates the equity curve of the portfolio. Parameters X (pd.DataFrame) \u2014 The prices expressed as a pandas dataframe Returns (pd.Series) The estimated portfolio value time series method score ( X , y=None , **kwargs ) Score the portfolio using one of the metrics expressed as PortfolioScorer in the metrics module. Parameters X (pd.DataFrame) \u2014 Dataframe with asset prices. Do not feed returns here! **kwargs (Dict) \u2014 Additional parameters to specify to the portfolio returns scorer, like risk_free_rate for Sharpe ratio. Alternatively you can also specify the score function to be used, like sharpe_ratio, or sortino_ratio Returns (float) The specific score value from the specified, Sharpe ratio is returned if not specified. method set_dummy_weights ( X ) Creates weights with NaN values, typically used when method cannot converge or solution is unfeasible. Parameters X (pd.DataFrame) \u2014 Prices or returns data, only used to pick asset names method set_returns_data ( returns_data=False ) Inform subsequent .fit method that the input data X are returns, otherwise prices are expected. Some portfolio estimators work independently with both, but is very important to specify what is contained in the .fit argument X . method set_returns_estimator ( rets_est ) Modify the base returns estimator with a specified rets_est Parameters rets_est (BaseReturnsEstimator) \u2014 The new returns estimator method set_risk_estimator ( risk_est ) Modify the base risk estimator with a new risk estimator Parameters risk_est (BaseRiskEstimator) \u2014 The new risk estimator class abc. ABCMeta ( name , bases , namespace , **kwargs ) Metaclass for defining Abstract Base Classes (ABCs). Use this metaclass to create an ABC. An ABC can be subclassed directly, and then acts as a mix-in class. You can also register unrelated concrete classes (even built-in classes) and unrelated ABCs as 'virtual subclasses' -- these and their descendants will be considered subclasses of the registering ABC by the built-in issubclass() function, but the registering ABC won't show up in their MRO (Method Resolution Order) nor will method implementations defined by the registering ABC be callable (not even via super()). Methods __instancecheck__ ( cls , instance ) \u2014 Override for isinstance(instance, cls). __subclasscheck__ ( cls , subclass ) \u2014 Override for issubclass(subclass, cls). register ( cls , subclass ) \u2014 Register a virtual subclass of an ABC. staticmethod register ( cls , subclass ) Register a virtual subclass of an ABC. Returns the subclass, to allow usage as a class decorator. staticmethod __instancecheck__ ( cls , instance ) Override for isinstance(instance, cls). staticmethod __subclasscheck__ ( cls , subclass ) Override for issubclass(subclass, cls). method estimate_frontier ( X , num_portfolios=20 , random_seed=None ) Estimates the efficient frontier given either returns or prices (depending on self.returns_data attribute), and number of points along the frontier. It always starts from the least risky portfolio and increasing the portfolio returns, it looks for the efficient risk portfolio until the riskiest portfolio (and the one with the highest return) is met. Parameters X (pd.DataFrame) \u2014 The prices or returns to fit multiple times the efficient risk/return portfolio num_portfolios (int) \u2014 Number of portfolios along the frontier. random_seed (int, optional) \u2014 Only when the portfolio returns estimator is PerturbedReturns, this is needed to lock the same stochastic sample of the expected returns across the entire frontier. Returns (tuple) The first two elements represent, the risk and return coordinates of the portfolios along the efficient frontier. The last element contains the portfolio weights. Portfolios are indexed from the least risky to the maximum return along the frontier. Examples If you need to compute the efficient frontier for the Markowitz Mean-Variance portfolio for 128 points using 16 parallel CPU cores you can simply do: >>> from skportfolio import MinimumVolatility >>> from skportfolio.datasets import load_tech_stock_prices >>> MinimumVolatility().estimate_frontier(load_tech_stock_prices(), num_portfolios=128) method add_constraints ( cnstr ) Add a list of constraints to the convex optimization problem Parameters cnstr (list) \u2014 List of constraints, to be added to the optimization problem Returns (object) The portfolio estimator object method fit ( X , y=None ) Fit the portfolio model from asset prices. Parameters X (pd.DataFrame) \u2014 Asset prices y (None) \u2014 There for compatibility Returns (self) The current estimator","title":"Efficient risk optimization on semi-variance frontier"},{"location":"ensemble/","text":"Ensemble methods \u00b6 This class of meta-estimators are based on the idea that building a robust portfolio requires great attention to estimation risk . Estimation risk is the risk that inputs to the portfolio optimization process (i.e., expected returns and volatilities or correlations) are inaccurately estimated by sampling from historical data, leading to suboptimal allocations. It is known that in the mean-variance portoflio, even small inaccuracies in the estimation of expected returns from prices, leads to very large errors in the optimal allocation, thus producing portfolios with skewed allocations. As a consequence of the fact that more uniform portfolios typically lead to greater out-of-sample performances, this behaviour is unwanted, and could be reminiscent of the overfitting phenomenon in machine learning. In this section we collect some methods and address the reduce portfolio overfitting problem, with a multitude of different approaches, borrowing ideas from machine-learning (regularization) and classical statistics (bootstrapping) and bayesian statistics. 1. Resampled efficient frontier \u00b6 The classical approach to asset allocation is a two-step process: first the market distribution is estimated, then an optimization is performed, as if the estimated distribution were the true market distribution. Since this is not the case, the classical optimal allocation is not truly optimal. More importantly, since the optimization process is extremely sensitive to the input parameters, the sub-optimality due to estimation risk can be dramatic . Monte Carlo resampling methods are used to model more realistic investment input parameters for the portfolio optimization. The Resampled Efficient Frontier method 1 avoids the literal use of the estimated distribution of market invariants (returns), but rather seeks to +average * a randomly perturbed scenario over a large number of possible investment histories. The idea is very simple and is reminiscent of the bootstraping technique in statistics. Because of our limited ability to calculate the real estimates of risk and returns, we bootstrap on historical returns by performing random normal perturbations , sampling from \\(\\tilde{\\boldsymbol{\\mu}} \\sim N(\\hat{\\boldsymbol \\mu}, \\hat{\\mathbf{C}} )\\) , where \\(\\hat{\\boldsymbol \\mu}\\) are the sample mean of historical returns, and \\(\\hat{\\mathbf{C}}\\) is the sample covariance of historical returns, thus producing a number of \\(K\\) Monte-Carlo scenarios. Each of the \\(K\\) random scenario can be thought as a possible case, as the expected returns are compatible with the observed returns series, provided that the sample covariance is big enough to allow some wiggling of the averages around their true but unobservable values. Under very reasonable assumptions, the resampled frontier method is provably effective at improving risk-adjusted portfolio return on out-of-sample data. Such a portfolio is different from the Markowitz efficient portfolio it will have suboptimal risk/return characteristics with respect to the sample mean and covariance, but optimal characteristics when averaged over the many possible values of the unknown true mean and covariance. We then solve for the efficient frontier over each perturbed sample and average all the solutions to get a more robust portfolio, without all those extreme allocations, typical of Markowitz-like optimization. Resampled optimized portfolios perform better because they are better risk-managed by avoiding the unrealistical literal use of investment information that characterizes Markowitz Mean-Variance optimization. scikit-portfolio extends the advantages of the resampled frontier approach to virtually all portfolio estimators whose one input parameter is a rets_estimator of type BaseReturnsEstimator , not only to the classical portfolios such as the MinimumVolatility portfolio or the MaxSharpe , discussed in the classical efficient frontier approach. You can simply create a standard MichaudEfficientFrontier portfolio in scikit-portfolio by importing both the MichaudEfficientFrontier object and the desidered portfolio estimator. Here we produce an ensemble estimate of the MaxSharpeRatio portfolio, a method that is known to produce highly skewed allocations because of the strong sensitivity on expected returns. import pandas as pd from skportfolio.ensemble import MichaudResampledFrontier from skportfolio.frontier import MaxSharpe from skportfolio import SampleCovariance,MeanHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() # create a Maximum sharpe ratio portfolio estimator to be fed to resampled frontier meta-estimator ptf = MaxSharpe( returns_data=False, risk_free_rate=0.0, frequency=252, rets_estimator=MeanHistoricalLinearReturns() ) ensemble = MichaudResampledFrontier( ptf_estimator=ptf, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_iter=512, n_jobs=-1 ).fit(prices) W = pd.concat(ensemble.all_weights_, axis=1) W.T.expanding().mean().plot() Here we show the cumulative average of asset weights under the resampled frontier allocation. It is evident that after enough scenarios, the weights averages tend to stabilize around the correct values for the optimal maximum sharpe ratio allocation. Note Figure 1. The asset allocation under resampling of expected returns, results much more uniform than the extremal pointwise allocations from the maximum sharpe portfolios. We could stop here, but we want to show how to use the Resampled Frontier portfolio also to estimate Maximum Omega Ratio portfolios, to reduce the estimation error. import pandas as pd from skportfolio.ensemble import MichaudResampledFrontier from skportfolio.frontier import MaxOmegaRatio from skportfolio import SampleCovariance,MeanHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # create a Maximum sharpe ratio portfolio estimator to be fed to resampled frontier meta-estimator ptf = MaxOmegaRatio( returns_data=False, frequency=252 ) ensemble = MichaudResampledFrontier( ptf_estimator=ptf, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_iter=512, n_jobs=-1 ).fit(prices) ## Plotting part import matplotlib.pyplot as plt W = pd.concat(ensemble.all_weights_, axis=1).T fig, ax = plt.subplots(figsize=(12, 7)) W.plot(ax=ax) ax.set_xlabel('scenario') ax.set_ylabel('Cumulative average weight') The allocation weights are slightly different with the Omega ratio efficient frontier, but nonetheless we still observe a tendency to stabilization of portfolio weights when considering the cumulative average. The optimal number of scenarios should be chosen in a way such that the cumulative averages are self-stabilizing. The default value of 500 scenarios is a good trade-off in most cases. Note Figure 2. Average weights allocation for the Maximum Omega Ratio portfolio, as a function of the scenario index. 2. Subset Resampling \u00b6 Here we implement an enhanced version of the subset resampling technique discussed in the paper: \"Portfolio Selection via Subset Resampling\" 2 The technique works by averaging allocation estimated with a noise-sensitive portfolio estimator (such as MaxSharpeRatio ) over many masked subsets of assets. The mask-optimization process is repeated many times: every iteration considers only a certain fraction of the entire asset universe, and optimal weights are computed. All the local estimates are then aggregated either by averaging or by voting mechanism, and a final allocation is produced. This method is very similar to the well-known class of ensemble methods in machine learning, for example RandomForests where many weak learners are merged to produce a robust estimation. In this way the risk of parameters estimation is reduced, and outlier effects are smoothed away in the final estimate. Being controlled by a single parameter selecting the fraction of assets to be sampled at each itereation, we can see the two ends of the spectrum of possible sub-estimators produced by SubsetResampling meta-estimator. On one side, with sampling one single asset at every step (hence fraction= 1/N , we asymptotically obtain the same results as from the EquallyWeighted portfolio. On the other side, sampling with fraction=1 we simply return the results from the input portfolio estimator. In other words the fraction of assets to be selected at each iteration controls a smooth blending between the equally weighted portfolio and the single portfolio estimator. In the following code snippet we illustrate how to use the estimator SubsetResampling jointly with MaxSharpeRatio on the technological stocks example. We average 64 estimates of random subsets of the stocks from the prices dataset. By setting the subset_size=0.5 we implement what suggested by the original authors and pick on each iteration a number of columns equivalent to \\(5^{0.5}\\) (with integer approximation). While does not make much sense for our data, as we only have 5 stocks in the data, it illustrates well the point. from skportfolio.frontier import MaxSharpe from skportfolio.ensemble import SubsetResampling from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() # fit on price data and average over 64 estimates, # considering ceil(5**0.5) = 3 stocks per subsample ptf = SubsetResampling( ptf_estimator=MaxSharpe(), subset_size=0.5, n_iter=64, n_jobs=-1, agg_func=\"median\" ).fit(prices) ptf.weights_ One can also access the list of weights in the ptf.all_weights_ variable, which in this case is a \\(64 \\times 5\\) array containing all weights, in order to create nice visualizations. Here is a picture of a 2D embedding of all portfolio weights using the dimensionality reduction method UMAP from data related to cryptocurrencies prices over 2 years, for a total of more than 200 assets. Note Figure 3. Dimensionality reduction of portfolio weights as estimate from subset resampling. Point color is the Sharpe ratio of the portfolio returns, darker points corresponds to higher Sharpe Ratios. The average weights are depicted with a red dot, while median weights are indicated with the purple dot. Median weights portfolio tends to stay in sparser areas: For further description and ideas visit here 3. Bayesian Robust Allocation \u00b6 Among the just discussed methods, the Bayesian Robust allocation is by far the most complex. It is based on a variant of the Black-Litterman model, designed by Attilio Meucci. Bayesian theory provides a way to limit the sensitivity of the final allocation to the input parameters by shrinking the estimate of the market parameters toward the investor\u2019s prior, as in the Black-Litterman approach. At the same time, the theory of robust optimization provides a different approach to dealing with estimation risk: the investor chooses the best allocation in the worst market within a given uncertainty range. Robust allocations are guaranteed to perform adequately for all the markets within the given uncertainty range. Nevertheless, the choice of this range is quite arbitrary. Furthermore, the investor\u2019s prior knowledge, a key ingredient in any allocation decision, is not taken in consideration. Using the Bayesian approach to estimation we can naturally identify a suitable uncertainty range for the market parameters, namely the location-dispersion ellipsoid of their posterior distribution. Robust Bayesian allocations are the solutions to a robust optimization problem that uses as uncertainty range the Bayesian location-dispersion ellipsoid. Similarly to robust allocations, these al- locations account for estimation risk over a whole range of market parameters. Similarly to Bayesian decisions, these allocations include the investor\u2019s prior knowledge in the optimization process within a sound and self-adjusting statistical framework. Here we consider robust Bayesian decisions that also account for the estimation error in the covariances and that, unlike in the Black-Litterman framework, explicitly process the information from the market, namely the observed time series of the past returns. As it turns out, the multi-parameter, non-conically constrained mean-variance optimization simplifies to a parsimonious Bayesian efficient frontier that resembles the classical frontier, except that the classical parameterization in terms of the exposure to market risk becomes in this context a parameterization in terms of the exposure to both market risk and estimation risk. from skportfolio.ensemble import RobustBayesian from skportfolio import MeanHistoricalLinearReturns,SampleCovariance RobustBayesian( window=180, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_portfolios=16, robustness_param_loc=0.1, robustness_param_scatter=0.1, n_jobs=-1 ) References \u00b6 Efficient Asset Management: A practical Guide to Stock Portfolio Optimization and Asset Allocation. , Michaud, R., and Michaud, R. (1998) ISBN 978-0-19-533191-2. \u21a9 \"Portfolio Selection via Subset Resampling\", Shen and Wang (2017) https://aaai.org/ocs/index. php/AAAI/AAAI17/paper/download/14443/13945 \u21a9","title":"Ensemble methods"},{"location":"ensemble/#ensemble-methods","text":"This class of meta-estimators are based on the idea that building a robust portfolio requires great attention to estimation risk . Estimation risk is the risk that inputs to the portfolio optimization process (i.e., expected returns and volatilities or correlations) are inaccurately estimated by sampling from historical data, leading to suboptimal allocations. It is known that in the mean-variance portoflio, even small inaccuracies in the estimation of expected returns from prices, leads to very large errors in the optimal allocation, thus producing portfolios with skewed allocations. As a consequence of the fact that more uniform portfolios typically lead to greater out-of-sample performances, this behaviour is unwanted, and could be reminiscent of the overfitting phenomenon in machine learning. In this section we collect some methods and address the reduce portfolio overfitting problem, with a multitude of different approaches, borrowing ideas from machine-learning (regularization) and classical statistics (bootstrapping) and bayesian statistics.","title":"Ensemble methods"},{"location":"ensemble/#1-resampled-efficient-frontier","text":"The classical approach to asset allocation is a two-step process: first the market distribution is estimated, then an optimization is performed, as if the estimated distribution were the true market distribution. Since this is not the case, the classical optimal allocation is not truly optimal. More importantly, since the optimization process is extremely sensitive to the input parameters, the sub-optimality due to estimation risk can be dramatic . Monte Carlo resampling methods are used to model more realistic investment input parameters for the portfolio optimization. The Resampled Efficient Frontier method 1 avoids the literal use of the estimated distribution of market invariants (returns), but rather seeks to +average * a randomly perturbed scenario over a large number of possible investment histories. The idea is very simple and is reminiscent of the bootstraping technique in statistics. Because of our limited ability to calculate the real estimates of risk and returns, we bootstrap on historical returns by performing random normal perturbations , sampling from \\(\\tilde{\\boldsymbol{\\mu}} \\sim N(\\hat{\\boldsymbol \\mu}, \\hat{\\mathbf{C}} )\\) , where \\(\\hat{\\boldsymbol \\mu}\\) are the sample mean of historical returns, and \\(\\hat{\\mathbf{C}}\\) is the sample covariance of historical returns, thus producing a number of \\(K\\) Monte-Carlo scenarios. Each of the \\(K\\) random scenario can be thought as a possible case, as the expected returns are compatible with the observed returns series, provided that the sample covariance is big enough to allow some wiggling of the averages around their true but unobservable values. Under very reasonable assumptions, the resampled frontier method is provably effective at improving risk-adjusted portfolio return on out-of-sample data. Such a portfolio is different from the Markowitz efficient portfolio it will have suboptimal risk/return characteristics with respect to the sample mean and covariance, but optimal characteristics when averaged over the many possible values of the unknown true mean and covariance. We then solve for the efficient frontier over each perturbed sample and average all the solutions to get a more robust portfolio, without all those extreme allocations, typical of Markowitz-like optimization. Resampled optimized portfolios perform better because they are better risk-managed by avoiding the unrealistical literal use of investment information that characterizes Markowitz Mean-Variance optimization. scikit-portfolio extends the advantages of the resampled frontier approach to virtually all portfolio estimators whose one input parameter is a rets_estimator of type BaseReturnsEstimator , not only to the classical portfolios such as the MinimumVolatility portfolio or the MaxSharpe , discussed in the classical efficient frontier approach. You can simply create a standard MichaudEfficientFrontier portfolio in scikit-portfolio by importing both the MichaudEfficientFrontier object and the desidered portfolio estimator. Here we produce an ensemble estimate of the MaxSharpeRatio portfolio, a method that is known to produce highly skewed allocations because of the strong sensitivity on expected returns. import pandas as pd from skportfolio.ensemble import MichaudResampledFrontier from skportfolio.frontier import MaxSharpe from skportfolio import SampleCovariance,MeanHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() # create a Maximum sharpe ratio portfolio estimator to be fed to resampled frontier meta-estimator ptf = MaxSharpe( returns_data=False, risk_free_rate=0.0, frequency=252, rets_estimator=MeanHistoricalLinearReturns() ) ensemble = MichaudResampledFrontier( ptf_estimator=ptf, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_iter=512, n_jobs=-1 ).fit(prices) W = pd.concat(ensemble.all_weights_, axis=1) W.T.expanding().mean().plot() Here we show the cumulative average of asset weights under the resampled frontier allocation. It is evident that after enough scenarios, the weights averages tend to stabilize around the correct values for the optimal maximum sharpe ratio allocation. Note Figure 1. The asset allocation under resampling of expected returns, results much more uniform than the extremal pointwise allocations from the maximum sharpe portfolios. We could stop here, but we want to show how to use the Resampled Frontier portfolio also to estimate Maximum Omega Ratio portfolios, to reduce the estimation error. import pandas as pd from skportfolio.ensemble import MichaudResampledFrontier from skportfolio.frontier import MaxOmegaRatio from skportfolio import SampleCovariance,MeanHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() returns = prices.pct_change().dropna() # create a Maximum sharpe ratio portfolio estimator to be fed to resampled frontier meta-estimator ptf = MaxOmegaRatio( returns_data=False, frequency=252 ) ensemble = MichaudResampledFrontier( ptf_estimator=ptf, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_iter=512, n_jobs=-1 ).fit(prices) ## Plotting part import matplotlib.pyplot as plt W = pd.concat(ensemble.all_weights_, axis=1).T fig, ax = plt.subplots(figsize=(12, 7)) W.plot(ax=ax) ax.set_xlabel('scenario') ax.set_ylabel('Cumulative average weight') The allocation weights are slightly different with the Omega ratio efficient frontier, but nonetheless we still observe a tendency to stabilization of portfolio weights when considering the cumulative average. The optimal number of scenarios should be chosen in a way such that the cumulative averages are self-stabilizing. The default value of 500 scenarios is a good trade-off in most cases. Note Figure 2. Average weights allocation for the Maximum Omega Ratio portfolio, as a function of the scenario index.","title":"1. Resampled efficient frontier"},{"location":"ensemble/#2-subset-resampling","text":"Here we implement an enhanced version of the subset resampling technique discussed in the paper: \"Portfolio Selection via Subset Resampling\" 2 The technique works by averaging allocation estimated with a noise-sensitive portfolio estimator (such as MaxSharpeRatio ) over many masked subsets of assets. The mask-optimization process is repeated many times: every iteration considers only a certain fraction of the entire asset universe, and optimal weights are computed. All the local estimates are then aggregated either by averaging or by voting mechanism, and a final allocation is produced. This method is very similar to the well-known class of ensemble methods in machine learning, for example RandomForests where many weak learners are merged to produce a robust estimation. In this way the risk of parameters estimation is reduced, and outlier effects are smoothed away in the final estimate. Being controlled by a single parameter selecting the fraction of assets to be sampled at each itereation, we can see the two ends of the spectrum of possible sub-estimators produced by SubsetResampling meta-estimator. On one side, with sampling one single asset at every step (hence fraction= 1/N , we asymptotically obtain the same results as from the EquallyWeighted portfolio. On the other side, sampling with fraction=1 we simply return the results from the input portfolio estimator. In other words the fraction of assets to be selected at each iteration controls a smooth blending between the equally weighted portfolio and the single portfolio estimator. In the following code snippet we illustrate how to use the estimator SubsetResampling jointly with MaxSharpeRatio on the technological stocks example. We average 64 estimates of random subsets of the stocks from the prices dataset. By setting the subset_size=0.5 we implement what suggested by the original authors and pick on each iteration a number of columns equivalent to \\(5^{0.5}\\) (with integer approximation). While does not make much sense for our data, as we only have 5 stocks in the data, it illustrates well the point. from skportfolio.frontier import MaxSharpe from skportfolio.ensemble import SubsetResampling from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() # fit on price data and average over 64 estimates, # considering ceil(5**0.5) = 3 stocks per subsample ptf = SubsetResampling( ptf_estimator=MaxSharpe(), subset_size=0.5, n_iter=64, n_jobs=-1, agg_func=\"median\" ).fit(prices) ptf.weights_ One can also access the list of weights in the ptf.all_weights_ variable, which in this case is a \\(64 \\times 5\\) array containing all weights, in order to create nice visualizations. Here is a picture of a 2D embedding of all portfolio weights using the dimensionality reduction method UMAP from data related to cryptocurrencies prices over 2 years, for a total of more than 200 assets. Note Figure 3. Dimensionality reduction of portfolio weights as estimate from subset resampling. Point color is the Sharpe ratio of the portfolio returns, darker points corresponds to higher Sharpe Ratios. The average weights are depicted with a red dot, while median weights are indicated with the purple dot. Median weights portfolio tends to stay in sparser areas: For further description and ideas visit here","title":"2. Subset Resampling"},{"location":"ensemble/#3-bayesian-robust-allocation","text":"Among the just discussed methods, the Bayesian Robust allocation is by far the most complex. It is based on a variant of the Black-Litterman model, designed by Attilio Meucci. Bayesian theory provides a way to limit the sensitivity of the final allocation to the input parameters by shrinking the estimate of the market parameters toward the investor\u2019s prior, as in the Black-Litterman approach. At the same time, the theory of robust optimization provides a different approach to dealing with estimation risk: the investor chooses the best allocation in the worst market within a given uncertainty range. Robust allocations are guaranteed to perform adequately for all the markets within the given uncertainty range. Nevertheless, the choice of this range is quite arbitrary. Furthermore, the investor\u2019s prior knowledge, a key ingredient in any allocation decision, is not taken in consideration. Using the Bayesian approach to estimation we can naturally identify a suitable uncertainty range for the market parameters, namely the location-dispersion ellipsoid of their posterior distribution. Robust Bayesian allocations are the solutions to a robust optimization problem that uses as uncertainty range the Bayesian location-dispersion ellipsoid. Similarly to robust allocations, these al- locations account for estimation risk over a whole range of market parameters. Similarly to Bayesian decisions, these allocations include the investor\u2019s prior knowledge in the optimization process within a sound and self-adjusting statistical framework. Here we consider robust Bayesian decisions that also account for the estimation error in the covariances and that, unlike in the Black-Litterman framework, explicitly process the information from the market, namely the observed time series of the past returns. As it turns out, the multi-parameter, non-conically constrained mean-variance optimization simplifies to a parsimonious Bayesian efficient frontier that resembles the classical frontier, except that the classical parameterization in terms of the exposure to market risk becomes in this context a parameterization in terms of the exposure to both market risk and estimation risk. from skportfolio.ensemble import RobustBayesian from skportfolio import MeanHistoricalLinearReturns,SampleCovariance RobustBayesian( window=180, rets_estimator=MeanHistoricalLinearReturns(), risk_estimator=SampleCovariance(), n_portfolios=16, robustness_param_loc=0.1, robustness_param_scatter=0.1, n_jobs=-1 )","title":"3. Bayesian Robust Allocation"},{"location":"ensemble/#references","text":"Efficient Asset Management: A practical Guide to Stock Portfolio Optimization and Asset Allocation. , Michaud, R., and Michaud, R. (1998) ISBN 978-0-19-533191-2. \u21a9 \"Portfolio Selection via Subset Resampling\", Shen and Wang (2017) https://aaai.org/ocs/index. php/AAAI/AAAI17/paper/download/14443/13945 \u21a9","title":"References"},{"location":"getting_started/","text":"Getting started \u00b6 Optimize a minimum volatility portfolio on real prices data \u00b6 scikit-portfolio offers dozens of built-in portfolio optimization algorithsm and models called PortfolioEstimators . Each estimator can be fitted to either equity prices or returns using its .fit method. Here is a simple example where we fit a MinimumVolatility portfolio to some technological stock prices. The asset prices are the adjusted daily close prices of Apple, Tesla, Amazon, Microsoft and Microstrategy, sampled over a 5 years period from 2016 to 2021. from skportfolio import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices import pandas as pd prices = load_tech_stock_prices() model = MinimumVolatility( returns_data=False, risk_free_rate=0.02, frequency=252).fit(prices) # print model weights print(model.weights_) # print model annualized sharpe ratio print(f\"Portfolio annualized Sharpe ratio = {model.score(prices):.3f}\") The .fit method generally accepts 2 inputs: The prices or returns pandas dataframe X . Additional data contained in y . However, this parameter is always ignored and kept for compatibility reasons. The size of X is typically (n_temporal_samples, n_equities), which means that samples are represented as rows and prices or returns are represented as columns. Differently from sklearn , here we require the variable X to be pandas dataframe with an arbitrary number of columns but indexed by a pd.DateTimeIndex . Once the portfolio is fitted , it can be used to see how its weights work on out-of-sample data with the .predict method: model.predict(prices) 2016-08-22 266.255828 2016-08-23 267.384265 2016-08-24 265.692214 2016-08-25 266.492617 2016-08-26 269.143623 ... 2021-08-16 1178.257286 2021-08-17 1157.389918 2021-08-18 1142.985767 2021-08-19 1143.877199 2021-08-20 1152.573843 Name: MinimumVolatility, Length: 1259, dtype: float64 The time series from .predict can be directly visualized with Pandas plotting methods: Note The output of the .predict method is always a pd.Series with the same name as the model class and the values obtained by the dot product of prices with the portfolio weights. In other words, the value of the portfolio evaluated if you bought the equities with the specified weights. Internally the portfolio weights are contained as pd.Series attribute with the name model.weights_ . Under most of the standard circumstances, we deal with long portfolios, meaning that all weights are set to be positive numbers in the \\([0,1]\\) interval. It is very simple to access the .weights_ attribute. When no .fit method is called, the model.weights_ attribute is set to None print(model.weights_) AAPL 0.19389 MSTR 0.10545 TSLA 0.00000 MSFT 0.41142 AMZN 0.28924 Name: MinimumVolatility, dtype: float64 It is easy also to visualize weights portfolio with the .plot.bar() method: model.fit(prices).weights_.plot.bar() Should I feed returns or prices to .fit method? \u00b6 TL;DR: it depends. If you initialize the portfolio estimator with returns_data=False you should .fit the portfolio using prices, otherwise if you set returns_data=True you should .fit the portfolio using returns. This code produce the same allocation: MinimumVolatility(returns_data=False).weights_ as this one returns = prices.pct_change().dropna() MinimumVolatility(returns_data=True).weights_ Moreover, all portfolio estimators s can modify the returns_data parameter via the method .set_returns_data . Warning Differently from the fit method, remember that the .predict function must be fed with prices and not returns \u26a0\ufe0f. You can always .fit on prices or returns, but always predict on prices to get meaningful results. There is a mathematical reason for this. Given asset prices at time t as a \\(N\\) -dimensional vector \\(\\mathbf{P}(t)\\) , the portfolio total wealth \\(W(t)\\) is the dot product of asset prices and portfolio weights: \\begin{equation} W(t) =\\sum_{i=1}^N w_i P_i(t). \\end{equation} By taking the portfolio return \\(r_P(t)\\) of portfolio wealth \\(W(t)\\) we get the following expression: \\begin{equation}r_P(t) = \\frac{W(t)-W(t-1)}{W(t)} = \\frac{\\sum_{i=1}^N w_i \\left\\lbrack P_i(t) - P_i(t-1)\\right\\rbrack } {\\sum_{i=1}^N w_i P_i (t-1)}. \\end{equation} which is instead very different from the weighted sum of the individual asset returns \\(r_i(t)\\) : \\begin{equation} \\sum_{i=1}^N w_i r_i(t) = \\sum_{i=1}^N w_i \\frac{P_i(t)-P_i(t-1)}{P_i(t-1)} \\end{equation} This is the reason why the PortfolioEstimator class does not have a .fit_predict method. You can fit a model with both prices or returns, but remember to predict always on prices and not on returns \u26a0\ufe0f. MinimumVolatility(returns_data=False).fit(prices).predict(prices) is equivalent to: returns = prices.pct_change().dropna() MinimumVolatility(returns_data=True).fit(returns).predict(prices) Plotting the efficient frontier \u00b6 For portfolio estimators supporting the functionality, it is possible to explore the efficient frontier. Moreover, it is easy to draw multiple fitted portfolios along the efficient frontier, specifying also colors. from skportfolio import MinimumVolatility, MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() ax = ( MinimumVolatility(returns_data=False) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#777777', show_only_portfolio=True) ) ( MeanVarianceEfficientReturn() .set_target_return(0.6) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#348ABD', show_only_portfolio=True, ax=ax ) ) ( MeanVarianceEfficientReturn() .set_target_return(0.5) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#E24A33', show_only_portfolio=False, ax=ax ) ) Every portfolio estimator depicts the complete frontier for the underlying model, with an additional colored dot indicating where the fitted portfolio falls in terms of risk-reward coordinates along the frontier, if the data has previously been fit. Faster, parallel evaluation of the efficient frontier \u00b6 Furthermore, if you require high precision in your efficient frontier reconstruction, you can take advantage of parallelization of the optimization problem for each portfolio on the frontier, by setting n_jobs higher than 1. See the example below: from skportfolio import MinimumVolatility, MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices X = load_tech_stock_prices() ax = MinimumVolatility(returns_data=False).fit(X).set_n_jobs(8).plot_frontier(X, num_portfolios=20, risk_return_color='darkblue') ax = MeanVarianceEfficientReturn().set_target_return(0.6).fit(X).plot_frontier(X, frontier_line_color=None, risk_return_color='darkgreen') Returns and risk estimators \u00b6 In general, when we talk about expected returns, we mean a variety of statistical estimators of the expected value of equity returns, such as mean historical returns, whereas when we talk about risk, we usually mean volatility estimators like sample standard deviation of portfolio returns , or other more complex measures like the conditional value at risk . scikit-portfolio has devised a method to cope with the problem of assessing expected returns and or risk, using the same API as the PortfolioEstimator . All returns estimators are based on the BaseReturnsEstimator , containing the .expected_returns_ attribute. On the other hand, all risk estimators are based on the BaseRiskEstimator whose main attribute is the .risk_matrix_ . While these two kind of classes are very general, all the returns and risk estimators are based on these, and they all implement different ways of providing statistically valid estimates to these two. Please note that almost every single PortfolioEstimator object requires the returns or risk estimators, or both as arguments in its __init__ method. By default, they are initialized to MeanHistoricalLinearReturns and SampleCovariance when not specified. The annualization constants are by default set to 252, but you can change to the frequency of the PortfolioEstimator when manually modified with the .set_frequency method. For example here we modifiy the standard SampleCovariance estimator of the MinimumVolatility portfolio estimator with the CovarianceExp estimator, a way to calculate covariance based on exponential moving averages of returns, rather than all data. We can also modify the default MeanHistoricalLinearReturns estimator with the MedianHistoricalLinearReturns , an estimator of expected returns putting more emphasis on most frequent data, thus weighting outlier returns: from skportfolio import MinimumVolatility, CovarianceExp, MedianHistoricalLinearReturns model = MinimumVolatility(rets_estimator=MedianHistoricalLinearReturns(), cov_estimator=CovarianceExp()) If you have already initialized a PortfolioEstimator , but you need to feed different risk or returns estimators to the subsequent calls, you can always modify the returns or risk estimators through the two methods: .set_returns_estimator .set_risk_estimator like in the following code snippet: from skportfolio import MinimumVolatility, CovarianceExp, MedianHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() model = MinimumVolatility(returns_data=True) print(model.set_returns_data(False).fit(prices).weights_) print(model) print(model.set_returns_estimator(MedianHistoricalLinearReturns()).set_risk_estimator(CovarianceExp()).fit(prices).weights_) print(model) Backtesting and model selection \u00b6 Fitting a portfolio model to some price data does not entail that it will perform well on unseen data. Here the difference with classical machine learning algorithms is subtle. Our goal here is not to predict anything, but to fit internal parameters of a portfolio to extrapolate it to new data, measuring its performance in terms of some specific metrics. Imagine in the previous example we have fitted the minimum volatility portfolio over 4 years of data and want to compute its performance of providing good returns to the investor over 1 year of unseen equity data. How do we measure which portfolio method performs best out-of-sample, without getting trapped into the overfitting problem, or mixing training and testing data? This is known in the financial investment domain as the backtesting phase of the investment portfolio. The scikit-portfolio library, leaning on the well-established scikit-learn module for model selection, provides different methdos to split the data into train and test , adding new tools such as the very smart CombinatorialPurgedCrossValidation methods. We here briefly show how to perform a 5-fold backtesting procedure, with the portfolio_cross_validate helper: We use a total of 8 cpus We calculate Sharpe ratio and Omega ratio for each one of the 5 test folds of a minimum volatility portfolio optimized on the remaining 4 train folds. The CV method is the classical KFold from scikit-learn . from skportfolio import portfolio_cross_validate, MinimumVolatility, sharpe_ratio_scorer, omega_ratio_scorer from skportfolio.datasets import load_tech_stock_prices from sklearn.model_selection import KFold model = MinimumVolatility() prices = load_tech_stock_prices() portfolio_cross_validate( estimator=model, prices_or_returns=prices, cv=KFold(n_splits=5), scoring={ \"sharpe_ratio\": sharpe_ratio_scorer, \"omega_ratio\": omega_ratio_scorer }, n_jobs=8 ) As a result we obtain a pd.DataFrame with all the relevant information, fit time and scoring time in seconds over all folds, together with the two portfolio metrics fold fit_time score_time test_sharpe_ratio test_omega_ratio 0 0.0263493 0.00355029 1.25578 1.24039 1 0.0191877 0.00233126 1.48821 1.29355 2 0.0255792 0.00363684 0.0513611 1.00932 3 0.0245926 0.0121238 1.20801 1.27315 4 0.023535 0.00933957 0.672825 1.12108 Alternatively we could have fitted all the skportfolio score estimators to get a complete breakdown of all the metrics of the aforementioned portfolio estimator based on minimum volatility. from skportfolio import all_scorers portfolio_cross_validate( estimator=model, prices_or_returns=prices, cv=KFold(n_splits=5), scoring=all_scorers, n_jobs=n_cpus ) To have an idea of the current train-test split scheme you can use the nice utility function make_split_df from the skportfolio.model_selection module that prints a green circle for the train samples and a red circle for the test samples from skportfolio.datasets import load_tech_stock_prices from skportfolio.model_selection import make_split_df from sklearn.model_selection import KFold prices = load_tech_stock_prices().iloc[0:15,:] make_split_df(KFold().split(prices), titles=(\"train\", \"test\")) This produces a dataframe where the columns are the temporal samples and the rows denote the fold number of the cross-validation. Here we limit the results to only 15 days of data. The \ud83d\udd34 dots represent testing, while the \ud83d\udfe2 dots represent training. The total number of samples for both training and test is counted in the last two columns. Folds 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 train test cv_train cv_test Fold(1) \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(2) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(3) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(4) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(5) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 12 3 0 0 Note that it is also possible to manually iterate over the folds, use different data splitting strategies, and use custom scoring functions, all provided in the metrics submodule. If interested, please refer to the skportfolio and sklearn API for more details. Automatic parameters search (hyperparameters optimization) \u00b6 All portfolio estimators have a number of internal parameters also called hyper-parameters that can be tuned to modify the algorithm results, and to tune one or another specific behaviour. It is important to note that most of the portfolio estimators come with default choices for their internal parameters, but in order to generalize well on unseen data, it is important to tune them via sound statistical methods. Following the above example of the MinimumVolatility portfolio algorithm, we see that a number of internal parameters can be chosen via the .get_params() method, similarly to the classical sklearn.Estimator object: from skportfolio import MinimumVolatility MinimumVolatility().get_params() with the following result of internal parameters: { 'cov_estimator__frequency': 252, 'cov_estimator__returns_data': False, 'cov_estimator': SampleCovariance(), 'frequency': 252, 'l2_gamma': 0, 'max_weight': 1, 'min_weight': 0, 'rets_estimator__frequency': 252, 'rets_estimator__returns_data': False, 'rets_estimator': MeanHistoricalLinearReturns(), 'returns_data': False, 'risk_free_rate': 0.0 } Quite often among all these parameters it is not clear what the best value is, hence this has to be found through hyperparamenters selection via cross-validation. As scikit-learn already provides tools to automatically find the best parameter combinations, we can randomly search over the parameter space of the portfolio optimization algorithm with a GridSearchCV object. When the search is over, the RandomizedSearchCV behaves as a skportfolio.PortfolioEstimator , but with internal values fitted with the best set of parameters: from sklearn.model_selection import GridSearchCV, KFold, train_test_split from skportfolio import MinimumVolatility, sharpe_ratio_scorer from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() prices_validation, prices_out_of_sample = train_test_split(prices, train_size=0.7, test_size=0.3, random_state=0, shuffle=False) model = MinimumVolatility() n_cpus = 8 n_iter = 100 best_model = GridSearchCV( estimator=model, param_grid=model.grid_parameters(), cv=KFold(5), n_jobs=n_cpus, scoring=sharpe_ratio_scorer ).fit(prices_validation) The refitted portfolio estimator is made available at the best_estimator_ attribute and permits using the .predict method directly from the GridSearchCV fitted object, taking care in using the out of sample data for the portfolio prediction in order to fairly compare different methods. best_model.predict(prices_out_of_sample) print(f\"Best model Sharpe ratio = {best_model.best_estimator_.score(prices_out_of_sample):.3f}\") You can access the optimized parameters of the best estimator with .best_model and check their internal parameters still with the .get_params() method: print(best_model.best_estimator_.info()) print(best_model.best_params_) You can also access the cross-validation results using the .cv_result_ attribute of the GridSearchCV estimator: pd.DataFrame(best_model.cv_results_)","title":"Getting started"},{"location":"getting_started/#getting-started","text":"","title":"Getting started"},{"location":"getting_started/#optimize-a-minimum-volatility-portfolio-on-real-prices-data","text":"scikit-portfolio offers dozens of built-in portfolio optimization algorithsm and models called PortfolioEstimators . Each estimator can be fitted to either equity prices or returns using its .fit method. Here is a simple example where we fit a MinimumVolatility portfolio to some technological stock prices. The asset prices are the adjusted daily close prices of Apple, Tesla, Amazon, Microsoft and Microstrategy, sampled over a 5 years period from 2016 to 2021. from skportfolio import MinimumVolatility from skportfolio.datasets import load_tech_stock_prices import pandas as pd prices = load_tech_stock_prices() model = MinimumVolatility( returns_data=False, risk_free_rate=0.02, frequency=252).fit(prices) # print model weights print(model.weights_) # print model annualized sharpe ratio print(f\"Portfolio annualized Sharpe ratio = {model.score(prices):.3f}\") The .fit method generally accepts 2 inputs: The prices or returns pandas dataframe X . Additional data contained in y . However, this parameter is always ignored and kept for compatibility reasons. The size of X is typically (n_temporal_samples, n_equities), which means that samples are represented as rows and prices or returns are represented as columns. Differently from sklearn , here we require the variable X to be pandas dataframe with an arbitrary number of columns but indexed by a pd.DateTimeIndex . Once the portfolio is fitted , it can be used to see how its weights work on out-of-sample data with the .predict method: model.predict(prices) 2016-08-22 266.255828 2016-08-23 267.384265 2016-08-24 265.692214 2016-08-25 266.492617 2016-08-26 269.143623 ... 2021-08-16 1178.257286 2021-08-17 1157.389918 2021-08-18 1142.985767 2021-08-19 1143.877199 2021-08-20 1152.573843 Name: MinimumVolatility, Length: 1259, dtype: float64 The time series from .predict can be directly visualized with Pandas plotting methods: Note The output of the .predict method is always a pd.Series with the same name as the model class and the values obtained by the dot product of prices with the portfolio weights. In other words, the value of the portfolio evaluated if you bought the equities with the specified weights. Internally the portfolio weights are contained as pd.Series attribute with the name model.weights_ . Under most of the standard circumstances, we deal with long portfolios, meaning that all weights are set to be positive numbers in the \\([0,1]\\) interval. It is very simple to access the .weights_ attribute. When no .fit method is called, the model.weights_ attribute is set to None print(model.weights_) AAPL 0.19389 MSTR 0.10545 TSLA 0.00000 MSFT 0.41142 AMZN 0.28924 Name: MinimumVolatility, dtype: float64 It is easy also to visualize weights portfolio with the .plot.bar() method: model.fit(prices).weights_.plot.bar()","title":"Optimize a minimum volatility portfolio on real prices data"},{"location":"getting_started/#should-i-feed-returns-or-prices-to-fit-method","text":"TL;DR: it depends. If you initialize the portfolio estimator with returns_data=False you should .fit the portfolio using prices, otherwise if you set returns_data=True you should .fit the portfolio using returns. This code produce the same allocation: MinimumVolatility(returns_data=False).weights_ as this one returns = prices.pct_change().dropna() MinimumVolatility(returns_data=True).weights_ Moreover, all portfolio estimators s can modify the returns_data parameter via the method .set_returns_data . Warning Differently from the fit method, remember that the .predict function must be fed with prices and not returns \u26a0\ufe0f. You can always .fit on prices or returns, but always predict on prices to get meaningful results. There is a mathematical reason for this. Given asset prices at time t as a \\(N\\) -dimensional vector \\(\\mathbf{P}(t)\\) , the portfolio total wealth \\(W(t)\\) is the dot product of asset prices and portfolio weights: \\begin{equation} W(t) =\\sum_{i=1}^N w_i P_i(t). \\end{equation} By taking the portfolio return \\(r_P(t)\\) of portfolio wealth \\(W(t)\\) we get the following expression: \\begin{equation}r_P(t) = \\frac{W(t)-W(t-1)}{W(t)} = \\frac{\\sum_{i=1}^N w_i \\left\\lbrack P_i(t) - P_i(t-1)\\right\\rbrack } {\\sum_{i=1}^N w_i P_i (t-1)}. \\end{equation} which is instead very different from the weighted sum of the individual asset returns \\(r_i(t)\\) : \\begin{equation} \\sum_{i=1}^N w_i r_i(t) = \\sum_{i=1}^N w_i \\frac{P_i(t)-P_i(t-1)}{P_i(t-1)} \\end{equation} This is the reason why the PortfolioEstimator class does not have a .fit_predict method. You can fit a model with both prices or returns, but remember to predict always on prices and not on returns \u26a0\ufe0f. MinimumVolatility(returns_data=False).fit(prices).predict(prices) is equivalent to: returns = prices.pct_change().dropna() MinimumVolatility(returns_data=True).fit(returns).predict(prices)","title":"Should I feed returns or prices to .fit method?"},{"location":"getting_started/#plotting-the-efficient-frontier","text":"For portfolio estimators supporting the functionality, it is possible to explore the efficient frontier. Moreover, it is easy to draw multiple fitted portfolios along the efficient frontier, specifying also colors. from skportfolio import MinimumVolatility, MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() ax = ( MinimumVolatility(returns_data=False) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#777777', show_only_portfolio=True) ) ( MeanVarianceEfficientReturn() .set_target_return(0.6) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#348ABD', show_only_portfolio=True, ax=ax ) ) ( MeanVarianceEfficientReturn() .set_target_return(0.5) .fit(prices) .plot_frontier( prices, num_portfolios=20, risk_return_color='#E24A33', show_only_portfolio=False, ax=ax ) ) Every portfolio estimator depicts the complete frontier for the underlying model, with an additional colored dot indicating where the fitted portfolio falls in terms of risk-reward coordinates along the frontier, if the data has previously been fit.","title":"Plotting the efficient frontier"},{"location":"getting_started/#faster-parallel-evaluation-of-the-efficient-frontier","text":"Furthermore, if you require high precision in your efficient frontier reconstruction, you can take advantage of parallelization of the optimization problem for each portfolio on the frontier, by setting n_jobs higher than 1. See the example below: from skportfolio import MinimumVolatility, MeanVarianceEfficientReturn from skportfolio.datasets import load_tech_stock_prices X = load_tech_stock_prices() ax = MinimumVolatility(returns_data=False).fit(X).set_n_jobs(8).plot_frontier(X, num_portfolios=20, risk_return_color='darkblue') ax = MeanVarianceEfficientReturn().set_target_return(0.6).fit(X).plot_frontier(X, frontier_line_color=None, risk_return_color='darkgreen')","title":"Faster, parallel evaluation of the efficient frontier"},{"location":"getting_started/#returns-and-risk-estimators","text":"In general, when we talk about expected returns, we mean a variety of statistical estimators of the expected value of equity returns, such as mean historical returns, whereas when we talk about risk, we usually mean volatility estimators like sample standard deviation of portfolio returns , or other more complex measures like the conditional value at risk . scikit-portfolio has devised a method to cope with the problem of assessing expected returns and or risk, using the same API as the PortfolioEstimator . All returns estimators are based on the BaseReturnsEstimator , containing the .expected_returns_ attribute. On the other hand, all risk estimators are based on the BaseRiskEstimator whose main attribute is the .risk_matrix_ . While these two kind of classes are very general, all the returns and risk estimators are based on these, and they all implement different ways of providing statistically valid estimates to these two. Please note that almost every single PortfolioEstimator object requires the returns or risk estimators, or both as arguments in its __init__ method. By default, they are initialized to MeanHistoricalLinearReturns and SampleCovariance when not specified. The annualization constants are by default set to 252, but you can change to the frequency of the PortfolioEstimator when manually modified with the .set_frequency method. For example here we modifiy the standard SampleCovariance estimator of the MinimumVolatility portfolio estimator with the CovarianceExp estimator, a way to calculate covariance based on exponential moving averages of returns, rather than all data. We can also modify the default MeanHistoricalLinearReturns estimator with the MedianHistoricalLinearReturns , an estimator of expected returns putting more emphasis on most frequent data, thus weighting outlier returns: from skportfolio import MinimumVolatility, CovarianceExp, MedianHistoricalLinearReturns model = MinimumVolatility(rets_estimator=MedianHistoricalLinearReturns(), cov_estimator=CovarianceExp()) If you have already initialized a PortfolioEstimator , but you need to feed different risk or returns estimators to the subsequent calls, you can always modify the returns or risk estimators through the two methods: .set_returns_estimator .set_risk_estimator like in the following code snippet: from skportfolio import MinimumVolatility, CovarianceExp, MedianHistoricalLinearReturns from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() model = MinimumVolatility(returns_data=True) print(model.set_returns_data(False).fit(prices).weights_) print(model) print(model.set_returns_estimator(MedianHistoricalLinearReturns()).set_risk_estimator(CovarianceExp()).fit(prices).weights_) print(model)","title":"Returns and risk estimators"},{"location":"getting_started/#backtesting-and-model-selection","text":"Fitting a portfolio model to some price data does not entail that it will perform well on unseen data. Here the difference with classical machine learning algorithms is subtle. Our goal here is not to predict anything, but to fit internal parameters of a portfolio to extrapolate it to new data, measuring its performance in terms of some specific metrics. Imagine in the previous example we have fitted the minimum volatility portfolio over 4 years of data and want to compute its performance of providing good returns to the investor over 1 year of unseen equity data. How do we measure which portfolio method performs best out-of-sample, without getting trapped into the overfitting problem, or mixing training and testing data? This is known in the financial investment domain as the backtesting phase of the investment portfolio. The scikit-portfolio library, leaning on the well-established scikit-learn module for model selection, provides different methdos to split the data into train and test , adding new tools such as the very smart CombinatorialPurgedCrossValidation methods. We here briefly show how to perform a 5-fold backtesting procedure, with the portfolio_cross_validate helper: We use a total of 8 cpus We calculate Sharpe ratio and Omega ratio for each one of the 5 test folds of a minimum volatility portfolio optimized on the remaining 4 train folds. The CV method is the classical KFold from scikit-learn . from skportfolio import portfolio_cross_validate, MinimumVolatility, sharpe_ratio_scorer, omega_ratio_scorer from skportfolio.datasets import load_tech_stock_prices from sklearn.model_selection import KFold model = MinimumVolatility() prices = load_tech_stock_prices() portfolio_cross_validate( estimator=model, prices_or_returns=prices, cv=KFold(n_splits=5), scoring={ \"sharpe_ratio\": sharpe_ratio_scorer, \"omega_ratio\": omega_ratio_scorer }, n_jobs=8 ) As a result we obtain a pd.DataFrame with all the relevant information, fit time and scoring time in seconds over all folds, together with the two portfolio metrics fold fit_time score_time test_sharpe_ratio test_omega_ratio 0 0.0263493 0.00355029 1.25578 1.24039 1 0.0191877 0.00233126 1.48821 1.29355 2 0.0255792 0.00363684 0.0513611 1.00932 3 0.0245926 0.0121238 1.20801 1.27315 4 0.023535 0.00933957 0.672825 1.12108 Alternatively we could have fitted all the skportfolio score estimators to get a complete breakdown of all the metrics of the aforementioned portfolio estimator based on minimum volatility. from skportfolio import all_scorers portfolio_cross_validate( estimator=model, prices_or_returns=prices, cv=KFold(n_splits=5), scoring=all_scorers, n_jobs=n_cpus ) To have an idea of the current train-test split scheme you can use the nice utility function make_split_df from the skportfolio.model_selection module that prints a green circle for the train samples and a red circle for the test samples from skportfolio.datasets import load_tech_stock_prices from skportfolio.model_selection import make_split_df from sklearn.model_selection import KFold prices = load_tech_stock_prices().iloc[0:15,:] make_split_df(KFold().split(prices), titles=(\"train\", \"test\")) This produces a dataframe where the columns are the temporal samples and the rows denote the fold number of the cross-validation. Here we limit the results to only 15 days of data. The \ud83d\udd34 dots represent testing, while the \ud83d\udfe2 dots represent training. The total number of samples for both training and test is counted in the last two columns. Folds 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 train test cv_train cv_test Fold(1) \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(2) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(3) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(4) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 12 3 0 0 Fold(5) \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 \ud83d\udd34 12 3 0 0 Note that it is also possible to manually iterate over the folds, use different data splitting strategies, and use custom scoring functions, all provided in the metrics submodule. If interested, please refer to the skportfolio and sklearn API for more details.","title":"Backtesting and model selection"},{"location":"getting_started/#automatic-parameters-search-hyperparameters-optimization","text":"All portfolio estimators have a number of internal parameters also called hyper-parameters that can be tuned to modify the algorithm results, and to tune one or another specific behaviour. It is important to note that most of the portfolio estimators come with default choices for their internal parameters, but in order to generalize well on unseen data, it is important to tune them via sound statistical methods. Following the above example of the MinimumVolatility portfolio algorithm, we see that a number of internal parameters can be chosen via the .get_params() method, similarly to the classical sklearn.Estimator object: from skportfolio import MinimumVolatility MinimumVolatility().get_params() with the following result of internal parameters: { 'cov_estimator__frequency': 252, 'cov_estimator__returns_data': False, 'cov_estimator': SampleCovariance(), 'frequency': 252, 'l2_gamma': 0, 'max_weight': 1, 'min_weight': 0, 'rets_estimator__frequency': 252, 'rets_estimator__returns_data': False, 'rets_estimator': MeanHistoricalLinearReturns(), 'returns_data': False, 'risk_free_rate': 0.0 } Quite often among all these parameters it is not clear what the best value is, hence this has to be found through hyperparamenters selection via cross-validation. As scikit-learn already provides tools to automatically find the best parameter combinations, we can randomly search over the parameter space of the portfolio optimization algorithm with a GridSearchCV object. When the search is over, the RandomizedSearchCV behaves as a skportfolio.PortfolioEstimator , but with internal values fitted with the best set of parameters: from sklearn.model_selection import GridSearchCV, KFold, train_test_split from skportfolio import MinimumVolatility, sharpe_ratio_scorer from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() prices_validation, prices_out_of_sample = train_test_split(prices, train_size=0.7, test_size=0.3, random_state=0, shuffle=False) model = MinimumVolatility() n_cpus = 8 n_iter = 100 best_model = GridSearchCV( estimator=model, param_grid=model.grid_parameters(), cv=KFold(5), n_jobs=n_cpus, scoring=sharpe_ratio_scorer ).fit(prices_validation) The refitted portfolio estimator is made available at the best_estimator_ attribute and permits using the .predict method directly from the GridSearchCV fitted object, taking care in using the out of sample data for the portfolio prediction in order to fairly compare different methods. best_model.predict(prices_out_of_sample) print(f\"Best model Sharpe ratio = {best_model.best_estimator_.score(prices_out_of_sample):.3f}\") You can access the optimized parameters of the best estimator with .best_model and check their internal parameters still with the .get_params() method: print(best_model.best_estimator_.info()) print(best_model.best_params_) You can also access the cross-validation results using the .cv_result_ attribute of the GridSearchCV estimator: pd.DataFrame(best_model.cv_results_)","title":"Automatic parameters search (hyperparameters optimization)"},{"location":"hyperparameters/","text":"Portfolio hyperparameters optimization \u00b6 One of the strongest abilities on scikit-portfolio is the possibility to backtest portfolios on historical data and automatically select the best portfolio hyperparameters. by exhaustive grid search... \u00b6 ...or better with Optuna \u00b6","title":"Hyperparameters optimization"},{"location":"hyperparameters/#portfolio-hyperparameters-optimization","text":"One of the strongest abilities on scikit-portfolio is the possibility to backtest portfolios on historical data and automatically select the best portfolio hyperparameters.","title":"Portfolio hyperparameters optimization"},{"location":"hyperparameters/#by-exhaustive-grid-search","text":"","title":"by exhaustive grid search..."},{"location":"hyperparameters/#or-better-with-optuna","text":"","title":"...or better with Optuna"},{"location":"installation/","text":"Installation \u00b6 Via pip python package manager... \u00b6 The simplest way to install the library is through the pip python package manager, all the dependencies are automatically installed for you. pip install scikit-portfolio ...or from source via the scikit-portfolio repository \u00b6 Scikit-portfolio is an open source portfolio management library, whose code is hosted on github.com/carlonicolini/scikit-portfolio . We reccomend you install on a virtual envinronment. If you are on Mac/Linux, the make sure to have virtualenv installed. Download the latest version of scikit-portfolio from public repository: git clone https://github.com/carlonicolini/scikit-portfolio.git Enter downloaded directory cd scikitportfolio Create and activate a virtual envinronment named venv : virtualenv venv source venv/bin/activate Either select the stable version: git checkout master or, if you are a developer, switch to the development branch, where you can send pull requests : git checkout develop Then install the library with pip . pip install . To run all tests, you need to have pytest * installed. For this you need the requirements_dev packages: pip install -r requirements_dev.txt then run tox make test","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#via-pip-python-package-manager","text":"The simplest way to install the library is through the pip python package manager, all the dependencies are automatically installed for you. pip install scikit-portfolio","title":"Via pip python package manager..."},{"location":"installation/#or-from-source-via-the-scikit-portfolio-repository","text":"Scikit-portfolio is an open source portfolio management library, whose code is hosted on github.com/carlonicolini/scikit-portfolio . We reccomend you install on a virtual envinronment. If you are on Mac/Linux, the make sure to have virtualenv installed. Download the latest version of scikit-portfolio from public repository: git clone https://github.com/carlonicolini/scikit-portfolio.git Enter downloaded directory cd scikitportfolio Create and activate a virtual envinronment named venv : virtualenv venv source venv/bin/activate Either select the stable version: git checkout master or, if you are a developer, switch to the development branch, where you can send pull requests : git checkout develop Then install the library with pip . pip install . To run all tests, you need to have pytest * installed. For this you need the requirements_dev packages: pip install -r requirements_dev.txt then run tox make test","title":"...or from source via the scikit-portfolio repository"},{"location":"metrics/","text":"Portfolio metrics \u00b6 There are a large number of metrics to evaluate the post-hoc goodness of your portfolio. Analyzing investment performance can help quantify the overall quality of investments in a portfolio, identify successful strategies, or highlight areas that need improvement. Aggregate Returns ( aggregate_returns ) \u00b6 function skportfolio.metrics.metrics. aggregate_returns ( returns , convert_to ) Aggregates returns by week, month, or year. Parameters returns (pd.Series) \u2014 Daily returns of the strategy, noncumulative. convert_to (str) \u2014 Can be 'weekly', 'monthly', or 'yearly'. Annualized Returns ( annualize_rets ) \u00b6 function skportfolio.metrics.metrics. annualize_rets ( r , frequency=252 ) \u2192 float Compunded annual growth rate, also called cagr Annualized Volatility ( annualize_vol ) \u00b6 function skportfolio.metrics.metrics. annualize_vol ( r , frequency=252 , levy_alpha=2.0 ) \u2192 float Annualizes the volatility of a set of returns Calmar Ratio ( calmar_ratio ) \u00b6 function skportfolio.metrics.metrics. calmar_ratio ( r , frequency=252 ) \u2192 float Determines the Calmar ratio, a measure of risk-adjusted returns for investment funds based on the maximum drawdown. The Calmar ratio is a modified version of the Sterling ratio. Conditional Drawdown at Risk ( cdar ) \u00b6 function skportfolio.metrics.metrics. cdar ( r , level=0.05 ) Calculate the conditional drawdown of risk (CDaR) of a portfolio/asset. Parameters r (pd.Series) \u2014 Historical returns for an asset / portfolio level (float) \u2014 Confidence level (alpha) Conditional Value At Risk ( cvar ) \u00b6 function skportfolio.metrics.metrics. cvar ( r , level=0.05 ) \u2192 float Calculates the conditional value at risk, with cutoff level of 5% Parameters r (pd.Series) \u2014 Returns level (float) \u2014 percentile cutoff tail value Corrected Sharpe Ratio ( corrected_sharpe_ratio ) \u00b6 function skportfolio.metrics.metrics. corrected_sharpe_ratio ( r , riskfree_rate=0.0 , period='DAILY' , frequency=252 ) \u2192 float Computes the annualizatin correction of the sharpe ratio of a set of returns. Sharpe Ratio: Estimation, Confidence Intervals, and Hypothesis Testing https://www.twosigma.com/wp-content/uploads/sharpe-tr-1.pdf Equation 10 Cumulative Returns ( cumulative_returns ) \u00b6 function skportfolio.metrics.metrics. cumulative_returns ( returns , starting_value=1000 ) \u2192 Series Computes (1+r).prod() * starting_value Downside Risk ( downside_risk ) \u00b6 function skportfolio.metrics.metrics. downside_risk ( r , target_return=0.0 ) \u2192 float Calculates downside risk Drawdown ( drawdown ) \u00b6 function skportfolio.metrics.metrics. drawdown ( returns ) Takes a time series of asset returns. returns a DataFrame with columns for the wealth index, the previous peaks and the percentage drawdown Final cumulative return ( final_cum_returns ) \u00b6 function skportfolio.metrics.metrics. final_cum_returns ( returns , starting_value=0 ) Compute total returns from simple returns. Parameters returns (pd.DataFrame, pd.Series, or np.ndarray) \u2014 Noncumulative simple returns of one or more timeseries. starting_value (float, optional) \u2014 The starting returns. Returns (total_returns : pd.Series, np.ndarray, or float) If input is 1-dimensional (a Series or 1D numpy array), the result is a scalar. If input is 2-dimensional (a DataFrame or 2D numpy array), the result is a 1D array containing cumulative returns for each column of input. Kurtosis ( kurtosis ) \u00b6 function skportfolio.metrics.metrics. kurtosis ( r ) \u2192 float Alternative to scipy.stats.kurtosis Maximum drawdown ( maxdrawdown ) \u00b6 function skportfolio.metrics.metrics. maxdrawdown ( returns ) Returns the maxdrawdown measure of returns Number of Effective Assets ( number_effective_assets ) \u00b6 function skportfolio.metrics.metrics. number_effective_assets ( weigths ) Returns a measure of portfolio diversification, known as number of effective assets. Its maximum value Omega Ratio ( omega_ratio ) \u00b6 function skportfolio.metrics.metrics. omega_ratio ( ret , target_ret=0.0 , risk_free_rate=0.0 , frequency=252 ) Returns the omega ratio of a strategy. Omega is a ratio of winning size weighted by probabilities to losing size weighted by probabilities. It considers size and odds of winning and losing trades, as well as all moments because the definition incorporates the whole distribution of returns. Important advantages are: There is no parameter (estimation). There is no need to estimate (higher) moments. Works with all kinds of distributions. Use a function (of Loss Threshold) to measure performance rather than a single number (as in Sharpe Ratio). It is as smooth as the return distribution. It is monotonic decreasing Look here for further details: Omega ratio paper Beyond Markowitz optimization Parameters ret (pd.Series) \u2014 Return of the strategy, typically obtained by the dot product of the asset returns dataframe and weights vector. target_ret (float, optional) \u2014 The desidered return per sample, aka the minimum acceptable return. risk_free_rate (float, optional) \u2014 The default risk free rate (default 0) frequency (int, optional) \u2014 The annualization frequency (default APPROX_BDAYS_PER_YEAR) See Also sharpe_ratio, sortino_ratio, calmar_ratio Portfolio Return ( portfolio_return ) \u00b6 function skportfolio.metrics.metrics. portfolio_return ( prices , weights , rets_estimator=MeanHistoricalLinearReturns() ) Calculates the portfolio return as \\(\\mathbb{E}\\lbrack \\mathbf{r}^T \\mathbf{w} \\rbrack\\) . Portfolio Volatility ( portfolio_vol ) \u00b6 function skportfolio.metrics.metrics. portfolio_vol ( returns , weights , frequency=252 , risk_estimator=SampleCovariance(returns_data=True) ) Computes the portfolio volatility using the risk_estimator, default set to sample covariance Semi-volatility ( semistd ) \u00b6 function skportfolio.metrics.metrics. semistd ( r ) \u2192 float Returns the semideviation aka negative semideviation of r r must be a Series or a DataFrame Sharpe Ratio ( sharpe_ratio ) \u00b6 function skportfolio.metrics.metrics. sharpe_ratio ( r , riskfree_rate=0.0 , period='DAILY' , frequency=252 ) Computes the annualized sharpe ratio of a set of returns. See the notes above about the annualization Skewness ( skewness ) \u00b6 function skportfolio.metrics.metrics. skewness ( r ) \u2192 float Alternative to scipy.stats.skewness Sortino Ratio ( sortino_ratio ) \u00b6 function skportfolio.metrics.metrics. sortino_ratio ( r , riskfree_rate=0.0 , frequency=252 ) \u2192 float The Sortino ratio is an improvement of the Sharpe ratio. What sets the Sortino ratio apart is that it acknowledges the difference between upside and downward risks. More specifically, it provides an accurate rate of return, given the likelihood of downside risk, while the Sharpe ratio treats both upside and downside risks equally. As a rule of thumb, a Sortino ratio of 2 and above is considered ideal. Parameters r (pd.Series) \u2014 portfolio returns obtained from (prices @ weights).pct_change() Tail Ratio ( tail_ratio ) \u00b6 function skportfolio.metrics.metrics. tail_ratio ( returns , upper_tail=95.0 , lower_tail=5.0 ) Determines the ratio between the right (95%) and left tail (5%). For example, a ratio of 0.25 means that losses are four times as bad as profits. Parameters returns (pd.Series or np.ndarray) \u2014 Daily returns of the strategy, noncumulative. - See full explanation in :func: ~empyrical.stats.cum_returns . upper_tail (float) \u2014 Upper percentile lower_tail (float) \u2014 Lower percentile Value At Risk ( value_at_risk ) \u00b6 function skportfolio.metrics.metrics. value_at_risk ( r , level=0.05 ) Computes the value at risk with cutoff level of default 5% Var Gaussian ( var_gaussian ) \u00b6 function skportfolio.metrics.metrics. var_gaussian ( r , level=5 , modified=False ) Returns the parametric gaussian VaR of a Series or DataFrame args: r: pd.Series level: percentile level modified: True if Corni","title":"Metrics and scorers"},{"location":"metrics/#portfolio-metrics","text":"There are a large number of metrics to evaluate the post-hoc goodness of your portfolio. Analyzing investment performance can help quantify the overall quality of investments in a portfolio, identify successful strategies, or highlight areas that need improvement.","title":"Portfolio metrics"},{"location":"metrics/#aggregate-returns-aggregate_returns","text":"function skportfolio.metrics.metrics. aggregate_returns ( returns , convert_to ) Aggregates returns by week, month, or year. Parameters returns (pd.Series) \u2014 Daily returns of the strategy, noncumulative. convert_to (str) \u2014 Can be 'weekly', 'monthly', or 'yearly'.","title":"Aggregate Returns (aggregate_returns)"},{"location":"metrics/#annualized-returns-annualize_rets","text":"function skportfolio.metrics.metrics. annualize_rets ( r , frequency=252 ) \u2192 float Compunded annual growth rate, also called cagr","title":"Annualized Returns (annualize_rets)"},{"location":"metrics/#annualized-volatility-annualize_vol","text":"function skportfolio.metrics.metrics. annualize_vol ( r , frequency=252 , levy_alpha=2.0 ) \u2192 float Annualizes the volatility of a set of returns","title":"Annualized Volatility (annualize_vol)"},{"location":"metrics/#calmar-ratio-calmar_ratio","text":"function skportfolio.metrics.metrics. calmar_ratio ( r , frequency=252 ) \u2192 float Determines the Calmar ratio, a measure of risk-adjusted returns for investment funds based on the maximum drawdown. The Calmar ratio is a modified version of the Sterling ratio.","title":"Calmar Ratio (calmar_ratio)"},{"location":"metrics/#conditional-drawdown-at-risk-cdar","text":"function skportfolio.metrics.metrics. cdar ( r , level=0.05 ) Calculate the conditional drawdown of risk (CDaR) of a portfolio/asset. Parameters r (pd.Series) \u2014 Historical returns for an asset / portfolio level (float) \u2014 Confidence level (alpha)","title":"Conditional Drawdown at Risk (cdar)"},{"location":"metrics/#conditional-value-at-risk-cvar","text":"function skportfolio.metrics.metrics. cvar ( r , level=0.05 ) \u2192 float Calculates the conditional value at risk, with cutoff level of 5% Parameters r (pd.Series) \u2014 Returns level (float) \u2014 percentile cutoff tail value","title":"Conditional Value At Risk (cvar)"},{"location":"metrics/#corrected-sharpe-ratio-corrected_sharpe_ratio","text":"function skportfolio.metrics.metrics. corrected_sharpe_ratio ( r , riskfree_rate=0.0 , period='DAILY' , frequency=252 ) \u2192 float Computes the annualizatin correction of the sharpe ratio of a set of returns. Sharpe Ratio: Estimation, Confidence Intervals, and Hypothesis Testing https://www.twosigma.com/wp-content/uploads/sharpe-tr-1.pdf Equation 10","title":"Corrected Sharpe Ratio (corrected_sharpe_ratio)"},{"location":"metrics/#cumulative-returns-cumulative_returns","text":"function skportfolio.metrics.metrics. cumulative_returns ( returns , starting_value=1000 ) \u2192 Series Computes (1+r).prod() * starting_value","title":"Cumulative Returns (cumulative_returns)"},{"location":"metrics/#downside-risk-downside_risk","text":"function skportfolio.metrics.metrics. downside_risk ( r , target_return=0.0 ) \u2192 float Calculates downside risk","title":"Downside Risk (downside_risk)"},{"location":"metrics/#drawdown-drawdown","text":"function skportfolio.metrics.metrics. drawdown ( returns ) Takes a time series of asset returns. returns a DataFrame with columns for the wealth index, the previous peaks and the percentage drawdown","title":"Drawdown (drawdown)"},{"location":"metrics/#final-cumulative-return-final_cum_returns","text":"function skportfolio.metrics.metrics. final_cum_returns ( returns , starting_value=0 ) Compute total returns from simple returns. Parameters returns (pd.DataFrame, pd.Series, or np.ndarray) \u2014 Noncumulative simple returns of one or more timeseries. starting_value (float, optional) \u2014 The starting returns. Returns (total_returns : pd.Series, np.ndarray, or float) If input is 1-dimensional (a Series or 1D numpy array), the result is a scalar. If input is 2-dimensional (a DataFrame or 2D numpy array), the result is a 1D array containing cumulative returns for each column of input.","title":"Final cumulative return (final_cum_returns)"},{"location":"metrics/#kurtosis-kurtosis","text":"function skportfolio.metrics.metrics. kurtosis ( r ) \u2192 float Alternative to scipy.stats.kurtosis","title":"Kurtosis (kurtosis)"},{"location":"metrics/#maximum-drawdown-maxdrawdown","text":"function skportfolio.metrics.metrics. maxdrawdown ( returns ) Returns the maxdrawdown measure of returns","title":"Maximum drawdown (maxdrawdown)"},{"location":"metrics/#number-of-effective-assets-number_effective_assets","text":"function skportfolio.metrics.metrics. number_effective_assets ( weigths ) Returns a measure of portfolio diversification, known as number of effective assets. Its maximum value","title":"Number of Effective Assets (number_effective_assets)"},{"location":"metrics/#omega-ratio-omega_ratio","text":"function skportfolio.metrics.metrics. omega_ratio ( ret , target_ret=0.0 , risk_free_rate=0.0 , frequency=252 ) Returns the omega ratio of a strategy. Omega is a ratio of winning size weighted by probabilities to losing size weighted by probabilities. It considers size and odds of winning and losing trades, as well as all moments because the definition incorporates the whole distribution of returns. Important advantages are: There is no parameter (estimation). There is no need to estimate (higher) moments. Works with all kinds of distributions. Use a function (of Loss Threshold) to measure performance rather than a single number (as in Sharpe Ratio). It is as smooth as the return distribution. It is monotonic decreasing Look here for further details: Omega ratio paper Beyond Markowitz optimization Parameters ret (pd.Series) \u2014 Return of the strategy, typically obtained by the dot product of the asset returns dataframe and weights vector. target_ret (float, optional) \u2014 The desidered return per sample, aka the minimum acceptable return. risk_free_rate (float, optional) \u2014 The default risk free rate (default 0) frequency (int, optional) \u2014 The annualization frequency (default APPROX_BDAYS_PER_YEAR) See Also sharpe_ratio, sortino_ratio, calmar_ratio","title":"Omega Ratio (omega_ratio)"},{"location":"metrics/#portfolio-return-portfolio_return","text":"function skportfolio.metrics.metrics. portfolio_return ( prices , weights , rets_estimator=MeanHistoricalLinearReturns() ) Calculates the portfolio return as \\(\\mathbb{E}\\lbrack \\mathbf{r}^T \\mathbf{w} \\rbrack\\) .","title":"Portfolio Return (portfolio_return)"},{"location":"metrics/#portfolio-volatility-portfolio_vol","text":"function skportfolio.metrics.metrics. portfolio_vol ( returns , weights , frequency=252 , risk_estimator=SampleCovariance(returns_data=True) ) Computes the portfolio volatility using the risk_estimator, default set to sample covariance","title":"Portfolio Volatility (portfolio_vol)"},{"location":"metrics/#semi-volatility-semistd","text":"function skportfolio.metrics.metrics. semistd ( r ) \u2192 float Returns the semideviation aka negative semideviation of r r must be a Series or a DataFrame","title":"Semi-volatility (semistd)"},{"location":"metrics/#sharpe-ratio-sharpe_ratio","text":"function skportfolio.metrics.metrics. sharpe_ratio ( r , riskfree_rate=0.0 , period='DAILY' , frequency=252 ) Computes the annualized sharpe ratio of a set of returns. See the notes above about the annualization","title":"Sharpe Ratio (sharpe_ratio)"},{"location":"metrics/#skewness-skewness","text":"function skportfolio.metrics.metrics. skewness ( r ) \u2192 float Alternative to scipy.stats.skewness","title":"Skewness (skewness)"},{"location":"metrics/#sortino-ratio-sortino_ratio","text":"function skportfolio.metrics.metrics. sortino_ratio ( r , riskfree_rate=0.0 , frequency=252 ) \u2192 float The Sortino ratio is an improvement of the Sharpe ratio. What sets the Sortino ratio apart is that it acknowledges the difference between upside and downward risks. More specifically, it provides an accurate rate of return, given the likelihood of downside risk, while the Sharpe ratio treats both upside and downside risks equally. As a rule of thumb, a Sortino ratio of 2 and above is considered ideal. Parameters r (pd.Series) \u2014 portfolio returns obtained from (prices @ weights).pct_change()","title":"Sortino Ratio (sortino_ratio)"},{"location":"metrics/#tail-ratio-tail_ratio","text":"function skportfolio.metrics.metrics. tail_ratio ( returns , upper_tail=95.0 , lower_tail=5.0 ) Determines the ratio between the right (95%) and left tail (5%). For example, a ratio of 0.25 means that losses are four times as bad as profits. Parameters returns (pd.Series or np.ndarray) \u2014 Daily returns of the strategy, noncumulative. - See full explanation in :func: ~empyrical.stats.cum_returns . upper_tail (float) \u2014 Upper percentile lower_tail (float) \u2014 Lower percentile","title":"Tail Ratio (tail_ratio)"},{"location":"metrics/#value-at-risk-value_at_risk","text":"function skportfolio.metrics.metrics. value_at_risk ( r , level=0.05 ) Computes the value at risk with cutoff level of default 5%","title":"Value At Risk (value_at_risk)"},{"location":"metrics/#var-gaussian-var_gaussian","text":"function skportfolio.metrics.metrics. var_gaussian ( r , level=5 , modified=False ) Returns the parametric gaussian VaR of a Series or DataFrame args: r: pd.Series level: percentile level modified: True if Corni","title":"Var Gaussian (var_gaussian)"},{"location":"miscellaneous/","text":"Miscellanous portfolio \u00b6 Not all portfolio methods require hard mathematical optimization. Some of them are much simpler and require very simple calculations. Here we list the simple portfolio optimization methods implemented in scikit-portfolio . Some of them which are only useful for coding convenience, and to maintain beautiful optimization pipelines. Equally weighted portfolio \u00b6 The equally weighted portfolio. Absolutely the simplest portfolio strategy to adopt. Interestingly, many authors claim that this portfolio achieves the best risk-reward ratio most of the time. It is documented in the literature that due to estimation errors, mean-variance efficient portfolios often deliver no higher out-of-sample Sharpe ratios than does the na\u00efve equally-weighted portfolio (EWP). DeMiguel, Garlappi, and Uppal, (2007) 1 is commonly cited to dismiss optimization based methods, in favor of equally weighted portfolios. The proportion of weights given to each asset in the portfolio is equal to \\(1/N\\) . \\[\\begin{split} \\begin{equation} \\begin{aligned} w_i &= \\frac{1}{N} & & \\forall i = 1,\\ldots,N \\end{aligned} \\end{equation} \\end{split}\\] Note Other authors (see Kritzman 2 ) instead have contrasting views about the better efficiency of the 1/N portfolio and say that the minimum volatility portfolio yields better out-of-sample results . Please do your own research to convince yourself which of the two are right. Single Asset portfolio \u00b6 Here for coding convenience. A portfolio where 100% of weight is given to a specific asset \\(i^\\star\\) , chosen in the initialization phase. \\[\\begin{split} \\begin{equation} \\begin{aligned} \\begin{cases} w_i = N^{-1} & i = i^\\star \\\\ w_i =0 & \\textrm{otherwise} \\end{cases} \\end{aligned} \\end{equation} \\end{split}\\] from skportfolio import SingleAsset from skportfolio.datasets import load_tech_stock_prices print(SingleAsset(asset=\"TSLA\").fit(load_tech_stock_prices()).weights_) Inverse variance portfolio \u00b6 In this portfolio, asset weights are specified inversely proportional to asset returns variance. \\[\\begin{equation} w_i = \\frac{1/\\sigma^2 \\lbrack r_i \\rbrack}{\\sum_{j=1}^N 1/\\sigma^2 \\lbrack r_j \\rbrack} \\end{equation}\\] from skportfolio import InverseVariance from skportfolio.datasets import load_tech_stock_prices print(InverseVariance().fit(load_tech_stock_prices()).weights_) Inverse volatility portfolio \u00b6 In this portfolio, asset weights are specified inversely proportional to asset returns volatility \\(\\sigma=\\sqrt{\\sigma^2}\\) . Very similar to Inverse Variance Portfolio. \\[\\begin{equation} w_i = \\frac{1/\\sigma \\lbrack r_i \\rbrack}{\\sum_{j=1}^N 1/\\sigma \\lbrack r_j \\rbrack} \\end{equation}\\] from skportfolio import InverseVolatility from skportfolio.datasets import load_tech_stock_prices print(InverseVolatility().fit(load_tech_stock_prices()).weights_) Capitalization weighted \u00b6 First the market capitalization is calculated as the prices of the asset times the number of outstanding shares, then weights are obtained as the sum-one normalized average of the market capitalization over time. import pandas as pd from skportfolio import CapWeighted from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() shares = pd.Dataframe(index=prices.index, columns=prices.columns, data=1_000_000) # fake shares, 1M outstanding shares for each stock print(CapWeighted().fit(X=prices, y=shares).weights_) References \u00b6 DeMiguel, Victor, Lorenzo Garlappi, and Raman Uppal. \"Optimal versus naive diversification: How inefficient is the 1/N portfolio strategy?.\" The review of Financial studies 22.5 (2009): 1915-1953 http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf \u21a9 Kritzman, Page & Turkington (2010) \"In defense of optimization: The fallacy of 1/N\". Financial Analysts Journal, 66(2), 31-39. \u21a9","title":"Miscellaneous"},{"location":"miscellaneous/#miscellanous-portfolio","text":"Not all portfolio methods require hard mathematical optimization. Some of them are much simpler and require very simple calculations. Here we list the simple portfolio optimization methods implemented in scikit-portfolio . Some of them which are only useful for coding convenience, and to maintain beautiful optimization pipelines.","title":"Miscellanous portfolio"},{"location":"miscellaneous/#equally-weighted-portfolio","text":"The equally weighted portfolio. Absolutely the simplest portfolio strategy to adopt. Interestingly, many authors claim that this portfolio achieves the best risk-reward ratio most of the time. It is documented in the literature that due to estimation errors, mean-variance efficient portfolios often deliver no higher out-of-sample Sharpe ratios than does the na\u00efve equally-weighted portfolio (EWP). DeMiguel, Garlappi, and Uppal, (2007) 1 is commonly cited to dismiss optimization based methods, in favor of equally weighted portfolios. The proportion of weights given to each asset in the portfolio is equal to \\(1/N\\) . \\[\\begin{split} \\begin{equation} \\begin{aligned} w_i &= \\frac{1}{N} & & \\forall i = 1,\\ldots,N \\end{aligned} \\end{equation} \\end{split}\\] Note Other authors (see Kritzman 2 ) instead have contrasting views about the better efficiency of the 1/N portfolio and say that the minimum volatility portfolio yields better out-of-sample results . Please do your own research to convince yourself which of the two are right.","title":"Equally weighted portfolio"},{"location":"miscellaneous/#single-asset-portfolio","text":"Here for coding convenience. A portfolio where 100% of weight is given to a specific asset \\(i^\\star\\) , chosen in the initialization phase. \\[\\begin{split} \\begin{equation} \\begin{aligned} \\begin{cases} w_i = N^{-1} & i = i^\\star \\\\ w_i =0 & \\textrm{otherwise} \\end{cases} \\end{aligned} \\end{equation} \\end{split}\\] from skportfolio import SingleAsset from skportfolio.datasets import load_tech_stock_prices print(SingleAsset(asset=\"TSLA\").fit(load_tech_stock_prices()).weights_)","title":"Single Asset portfolio"},{"location":"miscellaneous/#inverse-variance-portfolio","text":"In this portfolio, asset weights are specified inversely proportional to asset returns variance. \\[\\begin{equation} w_i = \\frac{1/\\sigma^2 \\lbrack r_i \\rbrack}{\\sum_{j=1}^N 1/\\sigma^2 \\lbrack r_j \\rbrack} \\end{equation}\\] from skportfolio import InverseVariance from skportfolio.datasets import load_tech_stock_prices print(InverseVariance().fit(load_tech_stock_prices()).weights_)","title":"Inverse variance portfolio"},{"location":"miscellaneous/#inverse-volatility-portfolio","text":"In this portfolio, asset weights are specified inversely proportional to asset returns volatility \\(\\sigma=\\sqrt{\\sigma^2}\\) . Very similar to Inverse Variance Portfolio. \\[\\begin{equation} w_i = \\frac{1/\\sigma \\lbrack r_i \\rbrack}{\\sum_{j=1}^N 1/\\sigma \\lbrack r_j \\rbrack} \\end{equation}\\] from skportfolio import InverseVolatility from skportfolio.datasets import load_tech_stock_prices print(InverseVolatility().fit(load_tech_stock_prices()).weights_)","title":"Inverse volatility portfolio"},{"location":"miscellaneous/#capitalization-weighted","text":"First the market capitalization is calculated as the prices of the asset times the number of outstanding shares, then weights are obtained as the sum-one normalized average of the market capitalization over time. import pandas as pd from skportfolio import CapWeighted from skportfolio.datasets import load_tech_stock_prices prices = load_tech_stock_prices() shares = pd.Dataframe(index=prices.index, columns=prices.columns, data=1_000_000) # fake shares, 1M outstanding shares for each stock print(CapWeighted().fit(X=prices, y=shares).weights_)","title":"Capitalization weighted"},{"location":"miscellaneous/#references","text":"DeMiguel, Victor, Lorenzo Garlappi, and Raman Uppal. \"Optimal versus naive diversification: How inefficient is the 1/N portfolio strategy?.\" The review of Financial studies 22.5 (2009): 1915-1953 http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf \u21a9 Kritzman, Page & Turkington (2010) \"In defense of optimization: The fallacy of 1/N\". Financial Analysts Journal, 66(2), 31-39. \u21a9","title":"References"},{"location":"portfolio_estimator/","text":"Estimators in scikit-portfolio class \u00b6 At the very core of skportfolio lies the PortfolioEstimator class which borrows many of the ideas of the well-known scikit-learn estimators. Begin an Estimator object, the PortfolioEstimator follows all the best-practices suggested when developing new estimators. As from the official scikit-learn documentation: To have a uniform API, we try to have a common basic API for all the objects. In addition, to avoid the proliferation of framework code, we try to adopt simple conventions and limit to a minimum the number of methods an object must implement. Here we have strictly followed this suggestion. Portfolio Estimator \u00b6 The API has one predominant object: the estimator. An estimator is an object that fits a model based on some training data and is capable of inferring some properties on new data. All portfolio estimators implement the .fit method: estimator.fit(X, y) All built-in portfolio estimators also have a .set_params method, which sets data-independent parameters (overriding previous parameter values passed to __init__ ). All portfolio estimators in the skportfolio codebase should inherit from skportfolio._base.PortfolioEstimator . Instantiation \u00b6 This concerns the creation of an object. The object\u2019s __init__ method might accept constants as arguments that determine the estimator\u2019s behavior. It should not , however, take the actual training data as an argument, as this is left to the fit() method: The arguments accepted by __init__ should all be keyword arguments with a default value. In other words, a user should be able to instantiate an estimator without passing any arguments to it. The arguments should all correspond to hyperparameters describing the portfolio model or the class tries to solve. These initial arguments (or parameters) are always remembered by the estimator. Also note that they should not be documented under the \u201cAttributes\u201d section, but rather under the \u201cParameters\u201d section for that estimator. In addition, every keyword argument accepted by __init__ should correspond to an attribute on the instance. Scikit-learn and skportfolio relies on this to find the relevant attributes to set on an estimator when doing model selection. To summarize, an __init__ should look like: def __init__(self, param1=1, param2=2): self.param1 = param1 self.param2 = param2 There should be no logic, not even input validation, and the parameters should not be changed. The corresponding logic should be put where the parameters are used, typically in .fit . The following is wrong : def __init__(self, param1=1, param2=2, param3=3): # WRONG: parameters should not be modified if param1 > 1: param2 += 1 self.param1 = param1 # WRONG: the object's attributes should have exactly the name of # the argument in the constructor self.param3 = param2 The reason for postponing the validation is that the same validation would have to be performed in set_params , which is used in algorithms like GridSearchCV. Fitting \u00b6 The next thing you will probably want to do is to estimate some parameters in the portfolio model. This is implemented in the fit() method. The fit() method takes the training data as arguments, which can be one array in the case of unsupervised learning, or two arrays in the case of supervised learning. Note that the model is fitted using X and y , but the object holds no reference to X and y . |Parameters| |X| array-like of shape (n_timesteps, n_assets)| |y| array-like of shape (n_samples,)| |kwargs| optional data-dependent parameters| X.shape[0] should be the same as y.shape[0] whenever y is necessary. Most portfolio methods don't need it. If this requisite is not met, an exception of type ValueError should be raised. y is almost always ignored. However, to make it possible to use the estimator as part of a pipeline. For the same reason, fit_predict , fit_transform , score and partial_fit methods need to accept a y argument in the second place if they are implemented. The method should return the object ( self ). This pattern is useful to be able to implement quick one liners in an IPython session such as: prices_test_predicted = MinimumVolatility().fit(prices_train).predict(prices_test) Depending on the nature of the algorithm, fit can sometimes also accept additional keywords arguments. However, any parameter that can have a value assigned prior to having access to the data should be an __init__ keyword argument. fit parameters should be restricted to directly data dependent variables. A tolerance stopping criterion tol is not directly data dependent (although the optimal value according to some scoring function probably is). When fit is called, any previous call to fit should be ignored. In general, calling estimator.fit(X1) and then estimator.fit(X2) should be the same as only calling estimator.fit(X2) . However, this may not be true in practice when fit depends on some random process, see random_state . Another exception to this rule is when the hyper-parameter warm_start is set to True for estimators that support it. warm_start=True means that the previous state of the trainable parameters of the estimator are reused instead of using the default initialization strategy. Estimated Attributes \u00b6 Attributes that have been estimated from the data must always have a name ending with trailing underscore _', for example the portfolio weights would be stored in a weight_ attribute after fit` has been called. The estimated attributes are expected to be overridden when you call fit a second time. Optional Arguments \u00b6 In iterative algorithms, the number of iterations should be specified by an integer called n_iter. get_params and set_params \u00b6 All scikit-learn estimators have get_params and set_params functions. The get_params function takes no arguments and returns a dict of the __init__ parameters of the estimator, together with their values. It must take one keyword argument, deep , which receives a boolean value that determines whether the method should return the parameters of sub-estimators (for most estimators, this can be ignored). The default value for deep should be True . For instance considering the following estimator:: >>> from sklearn.base import BaseEstimator >>> from sklearn.linear_model import LogisticRegression >>> class MyEstimator(BaseEstimator): ... def __init__(self, subestimator=None, my_extra_param=\"random\"): ... self.subestimator = subestimator ... self.my_extra_param = my_extra_param The parameter deep will control whether or not the parameters of the subsestimator should be reported. Thus when deep=True , the output will be:: >>> my_estimator = MyEstimator(subestimator=LogisticRegression()) >>> for param, value in my_estimator.get_params(deep=True).items(): ... print(f\"{param} -> {value}\") my_extra_param -> random subestimator__C -> 1.0 subestimator__class_weight -> None subestimator__dual -> False subestimator__fit_intercept -> True subestimator__intercept_scaling -> 1 subestimator__l1_ratio -> None subestimator__max_iter -> 100 subestimator__multi_class -> auto subestimator__n_jobs -> None subestimator__penalty -> l2 subestimator__random_state -> None subestimator__solver -> lbfgs subestimator__tol -> 0.0001 subestimator__verbose -> 0 subestimator__warm_start -> False subestimator -> LogisticRegression() Often, the subestimator has a name (as e.g. named steps in a ~sklearn.pipeline.Pipeline object), in which case the key should become <name>__C , <name>__class_weight , etc. While when deep=False , the output will be:: >>> for param, value in my_estimator.get_params(deep=False).items(): ... print(f\"{param} -> {value}\") my_extra_param -> random subestimator -> LogisticRegression() The set_params on the other hand takes as input a dict of the form 'parameter': value and sets the parameter of the estimator using this dict. Return value must be estimator itself. While the get_params mechanism is not essential (see :ref: cloning below), the set_params function is necessary as it is used to set parameters during grid searches. The easiest way to implement these functions, and to get a sensible __repr__ method, is to inherit from sklearn.base.BaseEstimator . If you do not want to make your code dependent on scikit-learn, the easiest way to implement the interface is:: def get_params(self, deep=True): # suppose this estimator has parameters \"alpha\" and \"recursive\" return {\"alpha\": self.alpha, \"recursive\": self.recursive} def set_params(self, **parameters): for parameter, value in parameters.items(): setattr(self, parameter, value) return self Parameters and init \u00b6 As model_selection.GridSearchCV uses set_params to apply parameter setting to estimators, it is essential that calling set_params has the same effect as setting parameters using the __init__ method. The easiest and recommended way to accomplish this is to not do any parameter validation in __init__ . All logic behind estimator parameters, like translating string arguments into functions, should be done in fit . Also it is expected that parameters with trailing _ are not to be set inside the __init__ method . All and only the public attributes set by fit have a trailing _ . As a result the existence of parameters with trailing _ is used to check if the estimator has been fitted.","title":"Estimators"},{"location":"portfolio_estimator/#estimators-in-scikit-portfolio-class","text":"At the very core of skportfolio lies the PortfolioEstimator class which borrows many of the ideas of the well-known scikit-learn estimators. Begin an Estimator object, the PortfolioEstimator follows all the best-practices suggested when developing new estimators. As from the official scikit-learn documentation: To have a uniform API, we try to have a common basic API for all the objects. In addition, to avoid the proliferation of framework code, we try to adopt simple conventions and limit to a minimum the number of methods an object must implement. Here we have strictly followed this suggestion.","title":"Estimators in scikit-portfolio class"},{"location":"portfolio_estimator/#portfolio-estimator","text":"The API has one predominant object: the estimator. An estimator is an object that fits a model based on some training data and is capable of inferring some properties on new data. All portfolio estimators implement the .fit method: estimator.fit(X, y) All built-in portfolio estimators also have a .set_params method, which sets data-independent parameters (overriding previous parameter values passed to __init__ ). All portfolio estimators in the skportfolio codebase should inherit from skportfolio._base.PortfolioEstimator .","title":"Portfolio Estimator"},{"location":"portfolio_estimator/#instantiation","text":"This concerns the creation of an object. The object\u2019s __init__ method might accept constants as arguments that determine the estimator\u2019s behavior. It should not , however, take the actual training data as an argument, as this is left to the fit() method: The arguments accepted by __init__ should all be keyword arguments with a default value. In other words, a user should be able to instantiate an estimator without passing any arguments to it. The arguments should all correspond to hyperparameters describing the portfolio model or the class tries to solve. These initial arguments (or parameters) are always remembered by the estimator. Also note that they should not be documented under the \u201cAttributes\u201d section, but rather under the \u201cParameters\u201d section for that estimator. In addition, every keyword argument accepted by __init__ should correspond to an attribute on the instance. Scikit-learn and skportfolio relies on this to find the relevant attributes to set on an estimator when doing model selection. To summarize, an __init__ should look like: def __init__(self, param1=1, param2=2): self.param1 = param1 self.param2 = param2 There should be no logic, not even input validation, and the parameters should not be changed. The corresponding logic should be put where the parameters are used, typically in .fit . The following is wrong : def __init__(self, param1=1, param2=2, param3=3): # WRONG: parameters should not be modified if param1 > 1: param2 += 1 self.param1 = param1 # WRONG: the object's attributes should have exactly the name of # the argument in the constructor self.param3 = param2 The reason for postponing the validation is that the same validation would have to be performed in set_params , which is used in algorithms like GridSearchCV.","title":"Instantiation"},{"location":"portfolio_estimator/#fitting","text":"The next thing you will probably want to do is to estimate some parameters in the portfolio model. This is implemented in the fit() method. The fit() method takes the training data as arguments, which can be one array in the case of unsupervised learning, or two arrays in the case of supervised learning. Note that the model is fitted using X and y , but the object holds no reference to X and y . |Parameters| |X| array-like of shape (n_timesteps, n_assets)| |y| array-like of shape (n_samples,)| |kwargs| optional data-dependent parameters| X.shape[0] should be the same as y.shape[0] whenever y is necessary. Most portfolio methods don't need it. If this requisite is not met, an exception of type ValueError should be raised. y is almost always ignored. However, to make it possible to use the estimator as part of a pipeline. For the same reason, fit_predict , fit_transform , score and partial_fit methods need to accept a y argument in the second place if they are implemented. The method should return the object ( self ). This pattern is useful to be able to implement quick one liners in an IPython session such as: prices_test_predicted = MinimumVolatility().fit(prices_train).predict(prices_test) Depending on the nature of the algorithm, fit can sometimes also accept additional keywords arguments. However, any parameter that can have a value assigned prior to having access to the data should be an __init__ keyword argument. fit parameters should be restricted to directly data dependent variables. A tolerance stopping criterion tol is not directly data dependent (although the optimal value according to some scoring function probably is). When fit is called, any previous call to fit should be ignored. In general, calling estimator.fit(X1) and then estimator.fit(X2) should be the same as only calling estimator.fit(X2) . However, this may not be true in practice when fit depends on some random process, see random_state . Another exception to this rule is when the hyper-parameter warm_start is set to True for estimators that support it. warm_start=True means that the previous state of the trainable parameters of the estimator are reused instead of using the default initialization strategy.","title":"Fitting"},{"location":"portfolio_estimator/#estimated-attributes","text":"Attributes that have been estimated from the data must always have a name ending with trailing underscore _', for example the portfolio weights would be stored in a weight_ attribute after fit` has been called. The estimated attributes are expected to be overridden when you call fit a second time.","title":"Estimated Attributes"},{"location":"portfolio_estimator/#optional-arguments","text":"In iterative algorithms, the number of iterations should be specified by an integer called n_iter.","title":"Optional Arguments"},{"location":"portfolio_estimator/#get_params-and-set_params","text":"All scikit-learn estimators have get_params and set_params functions. The get_params function takes no arguments and returns a dict of the __init__ parameters of the estimator, together with their values. It must take one keyword argument, deep , which receives a boolean value that determines whether the method should return the parameters of sub-estimators (for most estimators, this can be ignored). The default value for deep should be True . For instance considering the following estimator:: >>> from sklearn.base import BaseEstimator >>> from sklearn.linear_model import LogisticRegression >>> class MyEstimator(BaseEstimator): ... def __init__(self, subestimator=None, my_extra_param=\"random\"): ... self.subestimator = subestimator ... self.my_extra_param = my_extra_param The parameter deep will control whether or not the parameters of the subsestimator should be reported. Thus when deep=True , the output will be:: >>> my_estimator = MyEstimator(subestimator=LogisticRegression()) >>> for param, value in my_estimator.get_params(deep=True).items(): ... print(f\"{param} -> {value}\") my_extra_param -> random subestimator__C -> 1.0 subestimator__class_weight -> None subestimator__dual -> False subestimator__fit_intercept -> True subestimator__intercept_scaling -> 1 subestimator__l1_ratio -> None subestimator__max_iter -> 100 subestimator__multi_class -> auto subestimator__n_jobs -> None subestimator__penalty -> l2 subestimator__random_state -> None subestimator__solver -> lbfgs subestimator__tol -> 0.0001 subestimator__verbose -> 0 subestimator__warm_start -> False subestimator -> LogisticRegression() Often, the subestimator has a name (as e.g. named steps in a ~sklearn.pipeline.Pipeline object), in which case the key should become <name>__C , <name>__class_weight , etc. While when deep=False , the output will be:: >>> for param, value in my_estimator.get_params(deep=False).items(): ... print(f\"{param} -> {value}\") my_extra_param -> random subestimator -> LogisticRegression() The set_params on the other hand takes as input a dict of the form 'parameter': value and sets the parameter of the estimator using this dict. Return value must be estimator itself. While the get_params mechanism is not essential (see :ref: cloning below), the set_params function is necessary as it is used to set parameters during grid searches. The easiest way to implement these functions, and to get a sensible __repr__ method, is to inherit from sklearn.base.BaseEstimator . If you do not want to make your code dependent on scikit-learn, the easiest way to implement the interface is:: def get_params(self, deep=True): # suppose this estimator has parameters \"alpha\" and \"recursive\" return {\"alpha\": self.alpha, \"recursive\": self.recursive} def set_params(self, **parameters): for parameter, value in parameters.items(): setattr(self, parameter, value) return self","title":"get_params and set_params"},{"location":"portfolio_estimator/#parameters-and-init","text":"As model_selection.GridSearchCV uses set_params to apply parameter setting to estimators, it is essential that calling set_params has the same effect as setting parameters using the __init__ method. The easiest and recommended way to accomplish this is to not do any parameter validation in __init__ . All logic behind estimator parameters, like translating string arguments into functions, should be done in fit . Also it is expected that parameters with trailing _ are not to be set inside the __init__ method . All and only the public attributes set by fit have a trailing _ . As a result the existence of parameters with trailing _ is used to check if the estimator has been fitted.","title":"Parameters and init"},{"location":"portfolio_optimization_theory/","text":"Notation \u00b6 There are \\(N\\) assets and \\(T\\) temporal samples. The asset prices are encoded in a \\(T\\) rows, \\(N\\) columns array \\(\\mathbf{P} \\in \\mathbb{R}^{T \\times N} = \\{ P_{ti} \\}\\) The asset returns are encoded in a \\(T\\) rows, \\(N\\) columns array \\(\\mathbf{R} \\in \\mathbb{R}^{T \\times N} = \\{ R_{ti} \\}\\) We denote the \\(i\\) -th asset price at time \\(t\\) as \\(P_{ti}\\) . We denote the \\(i\\) -th asset historical return at time \\(t\\) as \\(R_{ti}\\) . The demeaned \\(i\\) -th asset return matrix is \\(\\mathbf{Z} = \\mathbf{R} - \\frac{1}{T}(\\mathbf{R}^T\\mathbf{1}) = \\{ Z_{ti} \\} = \\{ R_{ti} - \\langle R_{ti} \\rangle_t \\}\\) . The temporal average operator is \\(\\langle \\cdot_{ti} \\rangle_t\\) takes a \\(T \\times N\\) array and calculates a \\(N\\) dimensional array with the temporal averages. It is equivalent to \\(\\mathbf{A}^T\\mathbf{1}/T\\) where \\(\\mathbf{A} \\in \\mathbb{R}^{T \\times N}\\) and \\(\\mathbf{1} \\in \\mathbb{T}\\) . The covariance matrices are denoted by uppercase bold symbol \\(\\boldsymbol \\Sigma\\) and are \\(N \\times N\\) matrices. Problem background and historical introduction \u00b6 Probability, statistics, and optimization are appropriate mathematical foundations for quantitative analysis of investment decisions. As a result, a vast number of financial theories and models addressing this process have been developed. Harry Markowitz established the field of portfolio theory in 1952 1 , when he proposed a model that became known as Modern Portfolio Theory (MPT). The model implies that an investor wants to maximize the expected return on a portfolio while taking a certain degree of risk. Portfolios that match these characteristics are referred to be efficient portfolios, while those with the same projected return but more risk are referred to as sub-optimal portfolios. This approach encouraged investment experts to reconsider their asset allocations, and model adopters to shift their holdings in accordance with Markowitz (1952) and his successors' theories and models. As time has passed, various flaws in MPT have been discovered (some of which had been identified by Markowitz since the beginning 2 ), prompting the development of new models that aim to address these flaws. The risk measure in MPT, the standard deviation of asset returns, was deemed to be an unwise choice by Rom & Ferguson (1994) 3 . They proposed the Post-Modern Portfolio Theory (PMPT) model, which uses the standard deviation of negative asset returns as the risk measure, which tends to better reflect reality, instead of the standard deviation of positive asset returns. In contrast to Markowitz (1952) 1 and Rom & Ferguson (1994) 3 , who employed quadratic models, Konno & Yamazaki (1991) 4 proposed a linear model that used the mean-absolute deviation as a risk measure. The model was found to operate similarly to the previous quadratic model, but because of its linearity, it significantly decreased the complexity of the mathematical procedures. Black & Litterman (1991) 7 solved MPT's problem of requiring asset expected returns input by devising a methodology that allows the portfolio manager to supply a relative perspective of specified sub-groups rather than projected returns. Indeed, there have been numerous attempts to improve portfolio optimization algorithms. Digitalization has had an impact on the practical work of investment professionals, in addition to mathematical development in the field of portfolio theory. Optimization software appeared on the market as computing power grew, and it quickly became popular. Portfolio management is available through programs like Bloomberg , Axioma , and Barra , as well as the possibility to optimize your portfolio in terms of asset weights. These systems, on the other hand, are often sophisticated and come with a significant monthly charge. Both of these characteristics could make it difficult for a retail user, or a person interested in portfolio optimization to perform simple experiments. Portfolio optimization \u00b6 Portfolio optimization is the process of selecting asset weights in order to achieve an optimal portfolio, based on an objective function. Typically, the objective is to maximize expected return or to minimize financial risk. It can also be a combination of the two. Modern portfolio theory \u00b6 MPT (Modern Portfolio Theory), or mean-variance analysis, is a theory pioneered by Harry Markowitz in 1952. It assumes that investors make rational decisions and expect a higher return for increased risk. According to the theory, it is possible to construct a portfolio which maximizes the expected return, given a certain level of risk. Such portfolio is said to be on the efficient frontier . An investor would not take on extra risk if it does not mean larger returns. Conversely, the investor must take on more risk if the goal is to achieve higher returns. A key insight in this theory is that the return and risk of an asset should not be viewed separately, since the two factors together affect a portfolios overall risk and return (Markowitz, 1952). Despite its groundbreaking theories, MPT has faced criticism. To begin with, it requires the input of expected returns, which requires the investor to predict future outcomes. In practice, this is often done by extrapolating historical data. Such predictions often fail to take new circumstances into account, which results in predictions that are flawed. Also, as the risk measure of MPT is variance, the optimization model become quadratic, since variance is quadratic. For large portfolios, this implies heavy computations, which can make the model inefficient in a computational sense. Additionally, MPT assumes that the asset returns follow a Gaussian distribution, which has two serious implications. Firstly, it underestimates the probability of large and important movements in the price of an asset. Secondly, by relying on the correlation matrix, it fails to capture the relevant dependence structure among the assets. This limits the practical usefulness of MPT (Rachev & Mittnik, 2006). Nevertheless, MPT has contributed with strong theoretical value. The findings of Markowitz can be formulated in three different ways. The three different views can be seen below, equation 1, 3 and 5. Maximization of portfolio return Minimization of portfolio risk Optimization of a combination of return and risk The Efficient Frontier \u00b6 Markowitz introduced the efficient frontier, which is a cornerstone of MPT (1952). It's the set of optimal portfolios that provides the highest expected return for a given level of risk, or the lowest risk for a given level of expected return. Portfolios that do not correspond with the efficient frontier are sub-optimal by definition. The efficient frontier is commonly depicted as a hyperbola, with the portfolio return on the vertical axis and risk or volatility on the horizontal axis, like in the following figure: Purpose and problematization \u00b6 Decisions to invest, keep, decrease or dispose of holdings are based on information and conclusions derived from a collaborative fundamental process. The implementation of ideas and the portfolio construction process is however, within relevant constraints, delegated to the manager responsible for the portfolio. In this process a variety of tools are being used today to assist and support the portfolio managers, most prominently Bloomberg\u2019s portfolio function. This approach has historically worked well for the fund management company, based on their returns. The tools that are used today are however described as somewhat cumbersome and complicated to use. The company believes that quantitative input in the portfolio construction process is an important decision support for the portfolio managers and wants to find a more comprehensive tool to use in the day-to-day decisions. The key characteristics of scikit-portfolio are: Simplicity Speed Accuracy Usability To improve simplicity , we wanted to create a tool with a straightforward API and a small number of input parameters. Despite this, users have a plethora of fine-tuning choices at their disposal, the majority of which may be determined automatically at runtime via hyperparameters optimization. The fit - transform - predict paradigma from scikit-learn is used to interface with other libraries in the data science toolkit. The API was chosen to be the same as the one available in scikit-learn because of its widespread use among non-financial sector practitioners. This choice makes portfolio optimization accessible to a wide range of users, including data scientists, machine learning engineers, and researchers. This is likely to increase the utility of the optimization tool. The request for speed has influenced our choice of optimization algorithm and the implementation of it. For this reason we largely rely on the excellent cvxpy which with its highly flexible interface but accurate routines is becoming the de-facto standard in convex optimization for Python. Moreover, cvxpy not being a library of optimization routine, but rather a lingua-franca for specifying complex convex problems, makes it possible for the final user to specify the solver of choice. By default, the ECOS 6 solver, covers a large domain of problems, but commercial and more performant solvers are available to cvxpy such as the excellent Gurobi solver 5 . The third and final requested characteristic, accuracy , is proven through testing and comparison of scikit-portfolio solutions with other commercial packages, such as Matlab Financial Toolbox. Quantitative investment managers and risk managers use portfolio optimization to determine the proportions of various assets in a portfolio. The goal of portfolio optimization is to maximize a measure of a portfolio's return as a function of a measure of portfolio's risk, or viceversa, to minimize risk given some minimum level of return. scikit-portfolio provides a large set of portfolio optimization methods to perform capital allocation, asset allocation, and risk assessment, as well as a backtesting framework for portfolio allocation backtesting strategies Portfolio optimization is a problem that requires to satisfy three conflicting \ud83d\udca3\ufe0f criteria : Minimize a measure of risk \u26a0\ufe0f Match or exceed a measure of return \ud83d\ude0e\ufe0f Satisfy additional constraints, such as minimum allocations in certain assets.\ud83d\udc68\u200d\ud83c\udf93\ufe0f\ufe0f A portfolio is completely specified by asset weights, specifying the proportion of individual assets to be held in terms of total capital invested. A proxy for risk is a function that characterizes either the variability or losses associated with portfolio choices. Typically, higher risk mean higher chance of losing the capital. Portfolio returns measures are instead a way to quantify the gross or net benefits associated with portfolio choices. It is now clear that risk and returns are conflicting objectives, in the sense that there must exist for each combination of them, a certain point such that increases in one optimization dimension (return) does not lead to further decreases in the other dimension (risk), and viceversa. The locus of those points is called the efficient frontier on a risk-satisfaction cartesian plot. Markowitz H., \"Portfolio selection\", J. Fin, Vol. 7, No. 1. (1952), pp. 77-91 url \u21a9 \u21a9 Markowitz itself noted that the average portfolio return and standard deviation were not good measures. Cited from its 1952 paper: \"One suggestion as to tentative \\(\\mu_i\\) , \\(\\sigma_{ij}\\) to use the observed \\(\\mu_i\\) , \\(\\sigma_{ii}\\) for some period of the past. I believe that better methods, which take into account more information, can be found.\" \u21a9 Rom, Brian M., and Kathleen W. Ferguson. \"Post-modern portfolio theory comes of age.\" Journal of investing 3.3 (1994): 11-17. \u21a9 \u21a9 Konno, H, Yamazaki H. \"Mean-absolute deviation portfolio optimization model and its applications to Tokyo stock market.\" Management science 37.5 (1991): 519-531. \u21a9 Various authors, \"Gurobi Optimizer Reference Manual\", (2022), https://www.gurobi.com \u21a9 Domahidi, A., Chu E., and Boyd S. \"ECOS: An SOCP solver for embedded systems.\" 2013 European Control Conference (ECC). IEEE, 2013. \u21a9 Black, Fischer, and Robert Litterman. \"Asset allocation: combining investor views with market equilibrium.\" Goldman Sachs Fixed Income Research 115 (1990). \u21a9","title":"Portfolio optimization theory"},{"location":"portfolio_optimization_theory/#notation","text":"There are \\(N\\) assets and \\(T\\) temporal samples. The asset prices are encoded in a \\(T\\) rows, \\(N\\) columns array \\(\\mathbf{P} \\in \\mathbb{R}^{T \\times N} = \\{ P_{ti} \\}\\) The asset returns are encoded in a \\(T\\) rows, \\(N\\) columns array \\(\\mathbf{R} \\in \\mathbb{R}^{T \\times N} = \\{ R_{ti} \\}\\) We denote the \\(i\\) -th asset price at time \\(t\\) as \\(P_{ti}\\) . We denote the \\(i\\) -th asset historical return at time \\(t\\) as \\(R_{ti}\\) . The demeaned \\(i\\) -th asset return matrix is \\(\\mathbf{Z} = \\mathbf{R} - \\frac{1}{T}(\\mathbf{R}^T\\mathbf{1}) = \\{ Z_{ti} \\} = \\{ R_{ti} - \\langle R_{ti} \\rangle_t \\}\\) . The temporal average operator is \\(\\langle \\cdot_{ti} \\rangle_t\\) takes a \\(T \\times N\\) array and calculates a \\(N\\) dimensional array with the temporal averages. It is equivalent to \\(\\mathbf{A}^T\\mathbf{1}/T\\) where \\(\\mathbf{A} \\in \\mathbb{R}^{T \\times N}\\) and \\(\\mathbf{1} \\in \\mathbb{T}\\) . The covariance matrices are denoted by uppercase bold symbol \\(\\boldsymbol \\Sigma\\) and are \\(N \\times N\\) matrices.","title":"Notation"},{"location":"portfolio_optimization_theory/#problem-background-and-historical-introduction","text":"Probability, statistics, and optimization are appropriate mathematical foundations for quantitative analysis of investment decisions. As a result, a vast number of financial theories and models addressing this process have been developed. Harry Markowitz established the field of portfolio theory in 1952 1 , when he proposed a model that became known as Modern Portfolio Theory (MPT). The model implies that an investor wants to maximize the expected return on a portfolio while taking a certain degree of risk. Portfolios that match these characteristics are referred to be efficient portfolios, while those with the same projected return but more risk are referred to as sub-optimal portfolios. This approach encouraged investment experts to reconsider their asset allocations, and model adopters to shift their holdings in accordance with Markowitz (1952) and his successors' theories and models. As time has passed, various flaws in MPT have been discovered (some of which had been identified by Markowitz since the beginning 2 ), prompting the development of new models that aim to address these flaws. The risk measure in MPT, the standard deviation of asset returns, was deemed to be an unwise choice by Rom & Ferguson (1994) 3 . They proposed the Post-Modern Portfolio Theory (PMPT) model, which uses the standard deviation of negative asset returns as the risk measure, which tends to better reflect reality, instead of the standard deviation of positive asset returns. In contrast to Markowitz (1952) 1 and Rom & Ferguson (1994) 3 , who employed quadratic models, Konno & Yamazaki (1991) 4 proposed a linear model that used the mean-absolute deviation as a risk measure. The model was found to operate similarly to the previous quadratic model, but because of its linearity, it significantly decreased the complexity of the mathematical procedures. Black & Litterman (1991) 7 solved MPT's problem of requiring asset expected returns input by devising a methodology that allows the portfolio manager to supply a relative perspective of specified sub-groups rather than projected returns. Indeed, there have been numerous attempts to improve portfolio optimization algorithms. Digitalization has had an impact on the practical work of investment professionals, in addition to mathematical development in the field of portfolio theory. Optimization software appeared on the market as computing power grew, and it quickly became popular. Portfolio management is available through programs like Bloomberg , Axioma , and Barra , as well as the possibility to optimize your portfolio in terms of asset weights. These systems, on the other hand, are often sophisticated and come with a significant monthly charge. Both of these characteristics could make it difficult for a retail user, or a person interested in portfolio optimization to perform simple experiments.","title":"Problem background and historical introduction"},{"location":"portfolio_optimization_theory/#portfolio-optimization","text":"Portfolio optimization is the process of selecting asset weights in order to achieve an optimal portfolio, based on an objective function. Typically, the objective is to maximize expected return or to minimize financial risk. It can also be a combination of the two.","title":"Portfolio optimization"},{"location":"portfolio_optimization_theory/#modern-portfolio-theory","text":"MPT (Modern Portfolio Theory), or mean-variance analysis, is a theory pioneered by Harry Markowitz in 1952. It assumes that investors make rational decisions and expect a higher return for increased risk. According to the theory, it is possible to construct a portfolio which maximizes the expected return, given a certain level of risk. Such portfolio is said to be on the efficient frontier . An investor would not take on extra risk if it does not mean larger returns. Conversely, the investor must take on more risk if the goal is to achieve higher returns. A key insight in this theory is that the return and risk of an asset should not be viewed separately, since the two factors together affect a portfolios overall risk and return (Markowitz, 1952). Despite its groundbreaking theories, MPT has faced criticism. To begin with, it requires the input of expected returns, which requires the investor to predict future outcomes. In practice, this is often done by extrapolating historical data. Such predictions often fail to take new circumstances into account, which results in predictions that are flawed. Also, as the risk measure of MPT is variance, the optimization model become quadratic, since variance is quadratic. For large portfolios, this implies heavy computations, which can make the model inefficient in a computational sense. Additionally, MPT assumes that the asset returns follow a Gaussian distribution, which has two serious implications. Firstly, it underestimates the probability of large and important movements in the price of an asset. Secondly, by relying on the correlation matrix, it fails to capture the relevant dependence structure among the assets. This limits the practical usefulness of MPT (Rachev & Mittnik, 2006). Nevertheless, MPT has contributed with strong theoretical value. The findings of Markowitz can be formulated in three different ways. The three different views can be seen below, equation 1, 3 and 5. Maximization of portfolio return Minimization of portfolio risk Optimization of a combination of return and risk","title":"Modern portfolio theory"},{"location":"portfolio_optimization_theory/#the-efficient-frontier","text":"Markowitz introduced the efficient frontier, which is a cornerstone of MPT (1952). It's the set of optimal portfolios that provides the highest expected return for a given level of risk, or the lowest risk for a given level of expected return. Portfolios that do not correspond with the efficient frontier are sub-optimal by definition. The efficient frontier is commonly depicted as a hyperbola, with the portfolio return on the vertical axis and risk or volatility on the horizontal axis, like in the following figure:","title":"The Efficient Frontier"},{"location":"portfolio_optimization_theory/#purpose-and-problematization","text":"Decisions to invest, keep, decrease or dispose of holdings are based on information and conclusions derived from a collaborative fundamental process. The implementation of ideas and the portfolio construction process is however, within relevant constraints, delegated to the manager responsible for the portfolio. In this process a variety of tools are being used today to assist and support the portfolio managers, most prominently Bloomberg\u2019s portfolio function. This approach has historically worked well for the fund management company, based on their returns. The tools that are used today are however described as somewhat cumbersome and complicated to use. The company believes that quantitative input in the portfolio construction process is an important decision support for the portfolio managers and wants to find a more comprehensive tool to use in the day-to-day decisions. The key characteristics of scikit-portfolio are: Simplicity Speed Accuracy Usability To improve simplicity , we wanted to create a tool with a straightforward API and a small number of input parameters. Despite this, users have a plethora of fine-tuning choices at their disposal, the majority of which may be determined automatically at runtime via hyperparameters optimization. The fit - transform - predict paradigma from scikit-learn is used to interface with other libraries in the data science toolkit. The API was chosen to be the same as the one available in scikit-learn because of its widespread use among non-financial sector practitioners. This choice makes portfolio optimization accessible to a wide range of users, including data scientists, machine learning engineers, and researchers. This is likely to increase the utility of the optimization tool. The request for speed has influenced our choice of optimization algorithm and the implementation of it. For this reason we largely rely on the excellent cvxpy which with its highly flexible interface but accurate routines is becoming the de-facto standard in convex optimization for Python. Moreover, cvxpy not being a library of optimization routine, but rather a lingua-franca for specifying complex convex problems, makes it possible for the final user to specify the solver of choice. By default, the ECOS 6 solver, covers a large domain of problems, but commercial and more performant solvers are available to cvxpy such as the excellent Gurobi solver 5 . The third and final requested characteristic, accuracy , is proven through testing and comparison of scikit-portfolio solutions with other commercial packages, such as Matlab Financial Toolbox. Quantitative investment managers and risk managers use portfolio optimization to determine the proportions of various assets in a portfolio. The goal of portfolio optimization is to maximize a measure of a portfolio's return as a function of a measure of portfolio's risk, or viceversa, to minimize risk given some minimum level of return. scikit-portfolio provides a large set of portfolio optimization methods to perform capital allocation, asset allocation, and risk assessment, as well as a backtesting framework for portfolio allocation backtesting strategies Portfolio optimization is a problem that requires to satisfy three conflicting \ud83d\udca3\ufe0f criteria : Minimize a measure of risk \u26a0\ufe0f Match or exceed a measure of return \ud83d\ude0e\ufe0f Satisfy additional constraints, such as minimum allocations in certain assets.\ud83d\udc68\u200d\ud83c\udf93\ufe0f\ufe0f A portfolio is completely specified by asset weights, specifying the proportion of individual assets to be held in terms of total capital invested. A proxy for risk is a function that characterizes either the variability or losses associated with portfolio choices. Typically, higher risk mean higher chance of losing the capital. Portfolio returns measures are instead a way to quantify the gross or net benefits associated with portfolio choices. It is now clear that risk and returns are conflicting objectives, in the sense that there must exist for each combination of them, a certain point such that increases in one optimization dimension (return) does not lead to further decreases in the other dimension (risk), and viceversa. The locus of those points is called the efficient frontier on a risk-satisfaction cartesian plot. Markowitz H., \"Portfolio selection\", J. Fin, Vol. 7, No. 1. (1952), pp. 77-91 url \u21a9 \u21a9 Markowitz itself noted that the average portfolio return and standard deviation were not good measures. Cited from its 1952 paper: \"One suggestion as to tentative \\(\\mu_i\\) , \\(\\sigma_{ij}\\) to use the observed \\(\\mu_i\\) , \\(\\sigma_{ii}\\) for some period of the past. I believe that better methods, which take into account more information, can be found.\" \u21a9 Rom, Brian M., and Kathleen W. Ferguson. \"Post-modern portfolio theory comes of age.\" Journal of investing 3.3 (1994): 11-17. \u21a9 \u21a9 Konno, H, Yamazaki H. \"Mean-absolute deviation portfolio optimization model and its applications to Tokyo stock market.\" Management science 37.5 (1991): 519-531. \u21a9 Various authors, \"Gurobi Optimizer Reference Manual\", (2022), https://www.gurobi.com \u21a9 Domahidi, A., Chu E., and Boyd S. \"ECOS: An SOCP solver for embedded systems.\" 2013 European Control Conference (ECC). IEEE, 2013. \u21a9 Black, Fischer, and Robert Litterman. \"Asset allocation: combining investor views with market equilibrium.\" Goldman Sachs Fixed Income Research 115 (1990). \u21a9","title":"Purpose and problematization"},{"location":"returns/","text":"Expected returns estimators \u00b6 One of the most, if not the most, important inputs when executing optimization methods, where the objective function, more or less aims to maximize expected return, is the vector of expected returns for each asset. A small increase in the expected return of just one of a portfolio\u2019s assets can potentially force half of the assets from the resulting optimal portfolio, see 1 . In this document, we always refer to the expected returns with the bold greek letter \\(\\boldsymbol \\mu\\) , alternatively as the expectation operator of the asset returns \\(\\mathbb{E}[{\\mathbf{R}}]\\) . Here we offer many estimators of expected returns, both using linear and logarithmic returns, with or without compounding. Additionally, scikit-portfolio introduces other estimators for the expected returns based on median or exponentially weighted averages, which turn out to be slightly better in the backtesting results than the standard mean historical returns. Returns estimator base class \u00b6 This base class is at the core of all returns estimators. THe .fit method takes either price data or return data, depending on the initialization parameter returns_data . Moreover you can always modifiy the parameter with the '.set_returns_data(True|False)' method, returning a new estimator. Mean historical linear-returns MeanHistoricalLinearReturns \ud83d\udcd6 \u00b6 Mean historical returns are simply computed as the historical average of the geometric returns over all data. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,\\T\\) , the mean historical returns are obtained as \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\frac{1}{T} \\sum_{t=1}^T r_t \\end{equation}\\] Compounded historical linear-returns CompoundedHistoricalLinearReturns \ud83d\udcd6 \u00b6 Compounded historical returns are simply computed as the geometric average of the linear historical returns. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,\\T\\) , the compounded historical returns are obtained as: \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\left(\\prod_{t=1}^T 1+ r_t\\right)^{1/T} \\end{equation}\\] Mean historical log-returns MeanHistoricalLogReturns \ud83d\udcd6 \u00b6 Here, rather than using linear returns, we compute the average of the log returns \\(\\log(p_t/p_{t-1})\\) : \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\frac{1}{T} \\sum_{t=1}^T \\left( \\log p_t - \\log p_{t-1} \\right) \\end{equation}\\] Compounded historical log-returns CompoundedHistoricalLogReturns \ud83d\udcd6 \u00b6 Here, rather than using linear returns, we compute the average of the log returns \\(\\log(p_t/p_{t-1})\\) , and geometric average \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\left(\\prod_{t=1}^T 1 + (\\log p_t - \\log p_{t-1})\\right)^{1/T} \\end{equation}\\] Median historical linear returns MedianHistoricalLinearReturns \ud83d\udcd6 \u00b6 Like for MeanHistoricalLinearReturns , but using median rather than average. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,T\\) , the median historical returns are obtained as \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\textrm{median} \\left( \\{ r_{1},\\ldots, r_{T} \\} \\right) \\end{equation}\\] Median historical log returns MedianHistoricalLogReturns \ud83d\udcd6 \u00b6 Like for MeanHistoricalLinearReturns , but using median rather than average. In other words, given the log-returns time series \\(\\log p_t/p_{t-1}\\) for \\(t=1,\\dots,T\\) , the median historical log-returns are obtained as: \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\textrm{median} \\left( \\{ \\log (p_{t+1}/p_{t})_{t=1}, \\ldots, \\log( p_T/p_{T-1})_{t=T} \\} \\right) \\end{equation}\\] Exponential Moving Average Returns EMAHistoricalLinearReturns \ud83d\udcd6 \u00b6 Estimates the (annualized if frequency=252) expected returns as the exponential moving average of linear historical returns. Compounding is set to false by default. Rolling Median Returns RollingMedianReturns \ud83d\udcd6 \u00b6 Estimates the returns from the average of the rolling median over a window of 20 observations, by default. CAPM expected returns CAPMReturns \ud83d\udcd6 \u00b6 Compute a return estimate using the Capital Asset Pricing Model. Under the CAPM, asset returns are equal to market returns plus a \\(\\beta\\) term encoding the relative risk of the asset. The formula for calculating the expected return of an asset given its risk is as follows: \\[\\begin{equation} \\mathbb{E}[R_i] = r_f + \\beta_i \\left( \\mathbb{E}\\lbrackR_m\\rbrack - r_f\\right) \\end{equation}\\] where - \\(\\mathbb{E}[R_i]\\) is the expected return of asset \\(i\\) - \\(r_f\\) is the risk-free rate (default value is 0 ) - \\(\\beta_i\\) is the beta of the investment - $ \\left( \\mathbb{E}\\lbrackR_m\\rbrack - r_f\\right)$ is the market risk premium The beta of a potential investment is a measure of how much risk the investment will add to a portfolio that looks like the market. If a stock is riskier than the market, it will have a beta greater than one. If a stock has a beta of less than one, the formula assumes it will reduce the risk of a portfolio. See this page on Investopedia for more information about the CAPM. References \u00b6 Best, M.J., and Grauer, R.R., (1991). On the Sensitivity of Mean-Variance-Ecient Portfolios to Changes in Asset Means: Some Analytical and Computational Results. The Review of Financial Studies, pp. 315-342. \u21a9 Lo, Andrew. \"The statistics of Sharpe ratio\". Financial Analysts Journal (2003). \u21a9","title":"Returns estimators"},{"location":"returns/#expected-returns-estimators","text":"One of the most, if not the most, important inputs when executing optimization methods, where the objective function, more or less aims to maximize expected return, is the vector of expected returns for each asset. A small increase in the expected return of just one of a portfolio\u2019s assets can potentially force half of the assets from the resulting optimal portfolio, see 1 . In this document, we always refer to the expected returns with the bold greek letter \\(\\boldsymbol \\mu\\) , alternatively as the expectation operator of the asset returns \\(\\mathbb{E}[{\\mathbf{R}}]\\) . Here we offer many estimators of expected returns, both using linear and logarithmic returns, with or without compounding. Additionally, scikit-portfolio introduces other estimators for the expected returns based on median or exponentially weighted averages, which turn out to be slightly better in the backtesting results than the standard mean historical returns.","title":"Expected returns estimators"},{"location":"returns/#returns-estimator-base-class","text":"This base class is at the core of all returns estimators. THe .fit method takes either price data or return data, depending on the initialization parameter returns_data . Moreover you can always modifiy the parameter with the '.set_returns_data(True|False)' method, returning a new estimator.","title":"Returns estimator base class"},{"location":"returns/#mean-historical-linear-returns-meanhistoricallinearreturns","text":"Mean historical returns are simply computed as the historical average of the geometric returns over all data. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,\\T\\) , the mean historical returns are obtained as \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\frac{1}{T} \\sum_{t=1}^T r_t \\end{equation}\\]","title":"Mean historical linear-returns MeanHistoricalLinearReturns  \ud83d\udcd6"},{"location":"returns/#compounded-historical-linear-returns-compoundedhistoricallinearreturns","text":"Compounded historical returns are simply computed as the geometric average of the linear historical returns. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,\\T\\) , the compounded historical returns are obtained as: \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\left(\\prod_{t=1}^T 1+ r_t\\right)^{1/T} \\end{equation}\\]","title":"Compounded historical linear-returns CompoundedHistoricalLinearReturns \ud83d\udcd6"},{"location":"returns/#mean-historical-log-returns-meanhistoricallogreturns","text":"Here, rather than using linear returns, we compute the average of the log returns \\(\\log(p_t/p_{t-1})\\) : \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\frac{1}{T} \\sum_{t=1}^T \\left( \\log p_t - \\log p_{t-1} \\right) \\end{equation}\\]","title":"Mean historical log-returns MeanHistoricalLogReturns \ud83d\udcd6"},{"location":"returns/#compounded-historical-log-returns-compoundedhistoricallogreturns","text":"Here, rather than using linear returns, we compute the average of the log returns \\(\\log(p_t/p_{t-1})\\) , and geometric average \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\left(\\prod_{t=1}^T 1 + (\\log p_t - \\log p_{t-1})\\right)^{1/T} \\end{equation}\\]","title":"Compounded historical log-returns CompoundedHistoricalLogReturns \ud83d\udcd6"},{"location":"returns/#median-historical-linear-returns-medianhistoricallinearreturns","text":"Like for MeanHistoricalLinearReturns , but using median rather than average. In other words, given the returns time series \\(r_t\\) for \\(t=1,\\dots,T\\) , the median historical returns are obtained as \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\textrm{median} \\left( \\{ r_{1},\\ldots, r_{T} \\} \\right) \\end{equation}\\]","title":"Median historical linear returns MedianHistoricalLinearReturns \ud83d\udcd6"},{"location":"returns/#median-historical-log-returns-medianhistoricallogreturns","text":"Like for MeanHistoricalLinearReturns , but using median rather than average. In other words, given the log-returns time series \\(\\log p_t/p_{t-1}\\) for \\(t=1,\\dots,T\\) , the median historical log-returns are obtained as: \\[\\begin{equation} \\hat{\\boldsymbol \\mu} = \\textrm{median} \\left( \\{ \\log (p_{t+1}/p_{t})_{t=1}, \\ldots, \\log( p_T/p_{T-1})_{t=T} \\} \\right) \\end{equation}\\]","title":"Median historical log returns MedianHistoricalLogReturns \ud83d\udcd6"},{"location":"returns/#exponential-moving-average-returns-emahistoricallinearreturns","text":"Estimates the (annualized if frequency=252) expected returns as the exponential moving average of linear historical returns. Compounding is set to false by default.","title":"Exponential Moving Average Returns EMAHistoricalLinearReturns \ud83d\udcd6"},{"location":"returns/#rolling-median-returns-rollingmedianreturns","text":"Estimates the returns from the average of the rolling median over a window of 20 observations, by default.","title":"Rolling Median Returns RollingMedianReturns \ud83d\udcd6"},{"location":"returns/#capm-expected-returns-capmreturns","text":"Compute a return estimate using the Capital Asset Pricing Model. Under the CAPM, asset returns are equal to market returns plus a \\(\\beta\\) term encoding the relative risk of the asset. The formula for calculating the expected return of an asset given its risk is as follows: \\[\\begin{equation} \\mathbb{E}[R_i] = r_f + \\beta_i \\left( \\mathbb{E}\\lbrackR_m\\rbrack - r_f\\right) \\end{equation}\\] where - \\(\\mathbb{E}[R_i]\\) is the expected return of asset \\(i\\) - \\(r_f\\) is the risk-free rate (default value is 0 ) - \\(\\beta_i\\) is the beta of the investment - $ \\left( \\mathbb{E}\\lbrackR_m\\rbrack - r_f\\right)$ is the market risk premium The beta of a potential investment is a measure of how much risk the investment will add to a portfolio that looks like the market. If a stock is riskier than the market, it will have a beta greater than one. If a stock has a beta of less than one, the formula assumes it will reduce the risk of a portfolio. See this page on Investopedia for more information about the CAPM.","title":"CAPM expected returns CAPMReturns \ud83d\udcd6"},{"location":"returns/#references","text":"Best, M.J., and Grauer, R.R., (1991). On the Sensitivity of Mean-Variance-Ecient Portfolios to Changes in Asset Means: Some Analytical and Computational Results. The Review of Financial Studies, pp. 315-342. \u21a9 Lo, Andrew. \"The statistics of Sharpe ratio\". Financial Analysts Journal (2003). \u21a9","title":"References"},{"location":"returns_api/","text":"Returns estimators API \u00b6 CAPMReturns \u00b6 class skportfolio.riskreturn._returns_estimators. CAPMReturns ( returns_data=False , frequency=252 , risk_free_rate=0.0 , benchmark=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CompoundedHistoricalLinearReturns \u00b6 class skportfolio.riskreturn._returns_estimators. CompoundedHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CompoundedHistoricalLogReturns \u00b6 class skportfolio.riskreturn._returns_estimators. CompoundedHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. EMAHistoricalReturns \u00b6 class skportfolio.riskreturn._returns_estimators. EMAHistoricalReturns ( returns_data=False , frequency=252 , span=180 ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. MeanHistoricalLinearReturns \u00b6 class skportfolio.riskreturn._returns_estimators. MeanHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. MeanHistoricalLogReturns \u00b6 class skportfolio.riskreturn._returns_estimators. MeanHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. MedianHistoricalLinearReturns \u00b6 class skportfolio.riskreturn._returns_estimators. MedianHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. MedianHistoricalLogReturns \u00b6 class skportfolio.riskreturn._returns_estimators. MedianHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. RollingMedianReturns \u00b6 class skportfolio.riskreturn._returns_estimators. RollingMedianReturns ( returns_data=False , frequency=252 , window=20 ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"Returns estimators"},{"location":"returns_api/#returns-estimators-api","text":"","title":"Returns estimators API"},{"location":"returns_api/#capmreturns","text":"class skportfolio.riskreturn._returns_estimators. CAPMReturns ( returns_data=False , frequency=252 , risk_free_rate=0.0 , benchmark=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CAPMReturns"},{"location":"returns_api/#compoundedhistoricallinearreturns","text":"class skportfolio.riskreturn._returns_estimators. CompoundedHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CompoundedHistoricalLinearReturns"},{"location":"returns_api/#compoundedhistoricallogreturns","text":"class skportfolio.riskreturn._returns_estimators. CompoundedHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CompoundedHistoricalLogReturns"},{"location":"returns_api/#emahistoricalreturns","text":"class skportfolio.riskreturn._returns_estimators. EMAHistoricalReturns ( returns_data=False , frequency=252 , span=180 ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"EMAHistoricalReturns"},{"location":"returns_api/#meanhistoricallinearreturns","text":"class skportfolio.riskreturn._returns_estimators. MeanHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"MeanHistoricalLinearReturns"},{"location":"returns_api/#meanhistoricallogreturns","text":"class skportfolio.riskreturn._returns_estimators. MeanHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"MeanHistoricalLogReturns"},{"location":"returns_api/#medianhistoricallinearreturns","text":"class skportfolio.riskreturn._returns_estimators. MedianHistoricalLinearReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"MedianHistoricalLinearReturns"},{"location":"returns_api/#medianhistoricallogreturns","text":"class skportfolio.riskreturn._returns_estimators. MedianHistoricalLogReturns ( returns_data=False , frequency=252 , returns_function=None ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"MedianHistoricalLogReturns"},{"location":"returns_api/#rollingmedianreturns","text":"class skportfolio.riskreturn._returns_estimators. RollingMedianReturns ( returns_data=False , frequency=252 , window=20 ) Bases skportfolio.riskreturn._returns_estimators.BaseReturnsEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Base class for return estimator. It provides the basic infrastructure for all estimators of expected returns. It either can take price data or returns data, by specifying the returns_data=False or True respectively. The returns calculation is done with the standard .pct_change() of Pandas, unless otherwise specified by specification of the returns_function callable. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"RollingMedianReturns"},{"location":"risk/","text":"Risk estimators \u00b6 Risk has always played a very large role in the world of finance with the performance of a large number of investment and trading strategies being dependent on the efficient estimation of underlying market risk. In this regard, one of the most popular and commonly used representation of risk in finance is through a covariance matrix \u2013 higher covariance values mean more volatility in the markets and vice-versa. Covariance matrix is the most commonly used risk model, as it describes asset volatilities and their co-dependence in terms of quadratic forms. This is important because one of the principles of diversification is that risk can be reduced by making many uncorrelated bets (correlation is just normalised covariance). This also comes with a caveat \u2013 empirical covariance values are always measured using historical data and are extremely sensitive to small changes in market conditions. Interestingly enough, a piece of research by Kritzman et al. (2010) 1 shows that minimum variance portfolios may perform better out of sample than the equally weighted portfolio. This makes the covariance matrix an unreliable estimator of the true risk calling for the need of better estimators. In this section we devote our analysis to presenting different covariance matrix estimators which aim to reduce the estimation risk. Asset allocation and risk assessment also rely on correlations (covariance), however in this case a large number of correlations are often required. Construction of an optimal portfolio with a set of constraints requires a forecast of the covariance matrix of returns. Similarly, the calculation of the standard deviation of today's portfolio requires a covariance matrix of all the assets in the portfolio. These functions entail estimation and forecasting of large covariance matrices, potentially with thousands of assets. Risk estimator base class \u00b6 The class BaseRiskEstimator is at the core of all risk estimators. The .fit method takes either price data or return data, depending on the initialization parameter returns_data . Moreover, you can always modifiy the parameter with the .set_returns_data(True|False) method, returning a new estimator. With the generic term risk we mean a proxy measure of portfolio risk, like the portfolio volatility as measured from the standard deviation , the Mean-Absolute-Deviation of the excess returns , or the conditional value at risk . Warning For all covariance-based estimators, keep in mind that objects are supposed to be fed with daily prices or returns, and annualized covariances are returned. Indeed, default annualization factor is 252 periods, the approximate number of business days in a year. If returns have a different frequency, and covariance over different time periods is required, you must modify the frequency parameter. For example if you are feeding price tickers at a 30 minute time-frame, and you need to compute weekly covariance , you need to specify the frequency factor as the number of units of periods in the covariance interval. In that specific case frequency=2*24*7=336 . Keep in mind though that for returns with frames shorter than one day, strong serial correlation may exist, making this covariance aggregation approximation incorrect. For more details see the paper from Andrew Lo 4 . For notation, please see the notation section Sample Covariance SampleCovariance \ud83d\udcd6 \u00b6 Sample covariance from the asset returns. For more information about the covariance estimator implemented here see the scikit learn page on covariance estimation . The SampleCovariance is obtained from the asset returns \\(r_t^{(i)}\\) for \\(i \\in 1,\\ldots,N\\) as follows: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma} = \\frac{\\mathbf{Z}\\mathbf{Z}^T}{T-1}. \\end{equation}\\] Semicovariance SemiCovariance \ud83d\udcd6 \u00b6 The semicovariance, a.k.a. the covariance matrix estimated from only the returns exceeding a given benchmark \\(b\\) (typically 0). We adopt the definition as from pyportfolioopt . There are multiple possible ways of defining a semicovariance matrix, the main differences lying in the 'pairwise' nature, i.e whether we should sum over \\(\\min(r_i,B)\\min(r_j,b)\\) or \\(\\min(r_i r_j,b)\\) . In this implementation, we have followed the advice of Estrada (2007) 3 , preferring: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma}^b = \\frac{1}{T} \\sum_{t = 1}^T \\min(R_{ti},b) \\min(R_{tj},b) \\end{equation}\\] CovarianceRMT CovarianceRMT \ud83d\udcd6 \u00b6 The random matrix theory (RMT) postulates that a covariance matrix is built from a component related to bulk random gaussian noise and from a real signal, as described from the Marchenko-Pastur distribution. Here we follow the approach from MacMahon and Garlaschelli 5 . The calculation is based on the idea that a signal eigenspectrum consists in a continuos bulk and a \"market-mode\", to filter. Basically, the deviation of the spectra of real correlation matrices from the RMT prediction provides an effective way to filter out noise from empirical data. Starting from the eigendecomposition of the sample covariance \\begin{equation} \\hat{\\boldsymbol \\Sigma} = \\sum_{k}^N \\lambda_k \\mathbf{q}_k \\mathbf{q}_k^T \\end{equation} where \\(\\lambda_k\\) is the \\(k\\) -th eigenvalue and \\(\\mathbf{q}_k\\) is the \\(k\\) -th eigenvector of the sample covariance matrix, we get the filtered covariance matrix as: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma}^{RMT} = \\sum_{k : \\lambda_{k} > \\lambda_{\\textrm{MP}}}^N \\lambda_k \\mathbf{q}_k \\mathbf{q}_k^T \\end{equation}\\] The Marchenko-Pastur distribution postulates that it is possible to set a specific limit for the eigenvalues falling outside the bulk of random noise \\(\\lambda_{\\textrm{MP}}\\) . Beyond that value, the effect of random gaussian noise is minimum and \"true\" signals are compared. We refer the reader to the paper 5 for more details, or looking into the scikit-portfolio documentation. Ledoit-Wolf covariance estimator CovarianceLedoitWolf \ud83d\udcd6 \u00b6 One popular approach to dealing with estimation risk is to simply ignore parameters that are hard to estimate. A popular approach is thus to employ \"shrinkage estimators\" for key inputs. For example, Ledoit and Wolf (2004) 2 , propose shrinking the sample correlation matrix towards (a fancy way of saying \"averaging it with\") the constant correlation matrix. The constant correlation matrix is simply the correlation matrix where each diagonal element is equal to the pairwise average correlation across all assets. Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the L2-penalized Maximum Likelihood Estimator of the covariance matrix. See scikit-learn documentation for more details. In practice, shrinkage boils down to a simple a convex transformation: \\[\\begin{equation} \\boldsymbol \\Sigma^{\\textrm{shrunk}} = (1-\\alpha)\\hat{\\boldsymbol \\Sigma} + \\alpha \\frac{\\textrm{Tr} \\hat{\\boldsymbol \\Sigma}}{T}\\mathbf{I} \\end{equation}\\] Specifically, Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient \\(\\alpha\\) is computed using the formula described in 2 . Covariance GLASSO CovarianceGLASSO \ud83d\udcd6 \u00b6 The GLASSO covariance method estimates the true covariance matrix \\(\\boldsymbol \\Sigma\\) by solving the following optimization problem in the precision matrix \\(\\boldsymbol \\Theta\\) with a L1 regularization term, inducing sparsity in the recovered precision matrix: \\begin{equation} \\underset{\\boldsymbol \\Theta \\succeq \\mathbf{0}}{\\textrm{argmin}} \\left\\lbrack \\textrm{Tr}(\\hat{\\boldsymbol \\Sigma} \\boldsymbol \\Theta) - \\log \\det(\\boldsymbol \\Theta) + \\lambda \\sum_{i,j} | \\Theta_{ij} |\\right \\rbrack \\end{equation} The latter is a convex optimization problem in \\(\\boldsymbol \\Theta\\) . More details here and in the original paper by Tibshirani et al 6 . Exponential Moving Average Covariance CovarianceExp \ud83d\udcd6 \u00b6 This method of computing the covariance takes into account with an exponential moving average only the most recent observations, given a decay factor governed by the parameter span . Given a temporal span parameter \\(K\\) the tensor \\(\\mathbf{Q} \\in \\mathbb{R}^{T \\times N \\times N}\\) is obtained as: \\[\\begin{equation} Q_{tij} = Z_{ti} Z_{tj}. \\end{equation}\\] Finally, an exponential moving average is performed on \\(\\mathbf{Q}\\) over the temporal dimension \\(t\\) : \\[\\begin{equation} \\left(\\hat{\\boldsymbol \\Sigma}^{\\textrm{EWMA}}\\right)_{ij} = \\frac{\\sum \\limits_{\\tau=0}^T (1-\\alpha)^{\\tau} \\mathbf{Q}_{T-\\tau,i,j}}{\\sum \\limits_{\\tau=0}^T (1-\\alpha)^{\\tau}} \\end{equation}\\] where \\(\\alpha\\) is the decay factor \\(0\\leq \\alpha \\leq 1\\) uniquely specified by the span factor as \\(\\alpha = 2/(\\textrm{span}+1)\\) for \\(\\textrm{span}\\geq 1\\) . Hierarchical filtered covariance: average linkage \ud83d\udcd6 \u00b6 Hierarchical filtered covariance: complete linkage \ud83d\udcd6 \u00b6 Hierarchical filtered covariance: single linkage \ud83d\udcd6 \u00b6 References \u00b6 Kritzman, Page & Turkington (2010) \"In defense of optimization: The fallacy of 1/N\". Financial Analysts Journal, 66(2), 31-39. \u21a9 O. Ledoit and M. Wolf, \"A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices\", Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411. http://www.ledoit.net/honey.pdf \u21a9 \u21a9 Estrada (2006), Mean-Semivariance Optimization: A Heuristic Approach \u21a9 Lo, A, \"The statistics of Sharpe ratio\". https://www.tandfonline.com/doi/abs/10.2469/faj.v58.n4.2453 https://doi.org/10.2469/faj.v58.n4.2453 \u21a9 MacMahon M, Garlaschelli D., \"Community detection for correlation matrices\". Phys. Rev. X 5, 02100 https://journals.aps.org/prx/pdf/10.1103/PhysRevX.5.021006 \u21a9 \u21a9 Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. \"Sparse inverse covariance estimation with the graphical lasso.\" Biostatistics 9.3 (2008): 432-441. \u21a9","title":"Risk estimators"},{"location":"risk/#risk-estimators","text":"Risk has always played a very large role in the world of finance with the performance of a large number of investment and trading strategies being dependent on the efficient estimation of underlying market risk. In this regard, one of the most popular and commonly used representation of risk in finance is through a covariance matrix \u2013 higher covariance values mean more volatility in the markets and vice-versa. Covariance matrix is the most commonly used risk model, as it describes asset volatilities and their co-dependence in terms of quadratic forms. This is important because one of the principles of diversification is that risk can be reduced by making many uncorrelated bets (correlation is just normalised covariance). This also comes with a caveat \u2013 empirical covariance values are always measured using historical data and are extremely sensitive to small changes in market conditions. Interestingly enough, a piece of research by Kritzman et al. (2010) 1 shows that minimum variance portfolios may perform better out of sample than the equally weighted portfolio. This makes the covariance matrix an unreliable estimator of the true risk calling for the need of better estimators. In this section we devote our analysis to presenting different covariance matrix estimators which aim to reduce the estimation risk. Asset allocation and risk assessment also rely on correlations (covariance), however in this case a large number of correlations are often required. Construction of an optimal portfolio with a set of constraints requires a forecast of the covariance matrix of returns. Similarly, the calculation of the standard deviation of today's portfolio requires a covariance matrix of all the assets in the portfolio. These functions entail estimation and forecasting of large covariance matrices, potentially with thousands of assets.","title":"Risk estimators"},{"location":"risk/#risk-estimator-base-class","text":"The class BaseRiskEstimator is at the core of all risk estimators. The .fit method takes either price data or return data, depending on the initialization parameter returns_data . Moreover, you can always modifiy the parameter with the .set_returns_data(True|False) method, returning a new estimator. With the generic term risk we mean a proxy measure of portfolio risk, like the portfolio volatility as measured from the standard deviation , the Mean-Absolute-Deviation of the excess returns , or the conditional value at risk . Warning For all covariance-based estimators, keep in mind that objects are supposed to be fed with daily prices or returns, and annualized covariances are returned. Indeed, default annualization factor is 252 periods, the approximate number of business days in a year. If returns have a different frequency, and covariance over different time periods is required, you must modify the frequency parameter. For example if you are feeding price tickers at a 30 minute time-frame, and you need to compute weekly covariance , you need to specify the frequency factor as the number of units of periods in the covariance interval. In that specific case frequency=2*24*7=336 . Keep in mind though that for returns with frames shorter than one day, strong serial correlation may exist, making this covariance aggregation approximation incorrect. For more details see the paper from Andrew Lo 4 . For notation, please see the notation section","title":"Risk estimator base class"},{"location":"risk/#sample-covariance-samplecovariance","text":"Sample covariance from the asset returns. For more information about the covariance estimator implemented here see the scikit learn page on covariance estimation . The SampleCovariance is obtained from the asset returns \\(r_t^{(i)}\\) for \\(i \\in 1,\\ldots,N\\) as follows: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma} = \\frac{\\mathbf{Z}\\mathbf{Z}^T}{T-1}. \\end{equation}\\]","title":"Sample Covariance SampleCovariance \ud83d\udcd6"},{"location":"risk/#semicovariance-semicovariance","text":"The semicovariance, a.k.a. the covariance matrix estimated from only the returns exceeding a given benchmark \\(b\\) (typically 0). We adopt the definition as from pyportfolioopt . There are multiple possible ways of defining a semicovariance matrix, the main differences lying in the 'pairwise' nature, i.e whether we should sum over \\(\\min(r_i,B)\\min(r_j,b)\\) or \\(\\min(r_i r_j,b)\\) . In this implementation, we have followed the advice of Estrada (2007) 3 , preferring: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma}^b = \\frac{1}{T} \\sum_{t = 1}^T \\min(R_{ti},b) \\min(R_{tj},b) \\end{equation}\\]","title":"Semicovariance SemiCovariance \ud83d\udcd6"},{"location":"risk/#covariancermt-covariancermt","text":"The random matrix theory (RMT) postulates that a covariance matrix is built from a component related to bulk random gaussian noise and from a real signal, as described from the Marchenko-Pastur distribution. Here we follow the approach from MacMahon and Garlaschelli 5 . The calculation is based on the idea that a signal eigenspectrum consists in a continuos bulk and a \"market-mode\", to filter. Basically, the deviation of the spectra of real correlation matrices from the RMT prediction provides an effective way to filter out noise from empirical data. Starting from the eigendecomposition of the sample covariance \\begin{equation} \\hat{\\boldsymbol \\Sigma} = \\sum_{k}^N \\lambda_k \\mathbf{q}_k \\mathbf{q}_k^T \\end{equation} where \\(\\lambda_k\\) is the \\(k\\) -th eigenvalue and \\(\\mathbf{q}_k\\) is the \\(k\\) -th eigenvector of the sample covariance matrix, we get the filtered covariance matrix as: \\[\\begin{equation} \\hat{\\boldsymbol \\Sigma}^{RMT} = \\sum_{k : \\lambda_{k} > \\lambda_{\\textrm{MP}}}^N \\lambda_k \\mathbf{q}_k \\mathbf{q}_k^T \\end{equation}\\] The Marchenko-Pastur distribution postulates that it is possible to set a specific limit for the eigenvalues falling outside the bulk of random noise \\(\\lambda_{\\textrm{MP}}\\) . Beyond that value, the effect of random gaussian noise is minimum and \"true\" signals are compared. We refer the reader to the paper 5 for more details, or looking into the scikit-portfolio documentation.","title":"CovarianceRMT CovarianceRMT  \ud83d\udcd6"},{"location":"risk/#ledoit-wolf-covariance-estimator-covarianceledoitwolf","text":"One popular approach to dealing with estimation risk is to simply ignore parameters that are hard to estimate. A popular approach is thus to employ \"shrinkage estimators\" for key inputs. For example, Ledoit and Wolf (2004) 2 , propose shrinking the sample correlation matrix towards (a fancy way of saying \"averaging it with\") the constant correlation matrix. The constant correlation matrix is simply the correlation matrix where each diagonal element is equal to the pairwise average correlation across all assets. Mathematically, this shrinkage consists in reducing the ratio between the smallest and the largest eigenvalues of the empirical covariance matrix. It can be done by simply shifting every eigenvalue according to a given offset, which is equivalent of finding the L2-penalized Maximum Likelihood Estimator of the covariance matrix. See scikit-learn documentation for more details. In practice, shrinkage boils down to a simple a convex transformation: \\[\\begin{equation} \\boldsymbol \\Sigma^{\\textrm{shrunk}} = (1-\\alpha)\\hat{\\boldsymbol \\Sigma} + \\alpha \\frac{\\textrm{Tr} \\hat{\\boldsymbol \\Sigma}}{T}\\mathbf{I} \\end{equation}\\] Specifically, Ledoit-Wolf is a particular form of shrinkage, where the shrinkage coefficient \\(\\alpha\\) is computed using the formula described in 2 .","title":"Ledoit-Wolf covariance estimator CovarianceLedoitWolf \ud83d\udcd6"},{"location":"risk/#covariance-glasso-covarianceglasso","text":"The GLASSO covariance method estimates the true covariance matrix \\(\\boldsymbol \\Sigma\\) by solving the following optimization problem in the precision matrix \\(\\boldsymbol \\Theta\\) with a L1 regularization term, inducing sparsity in the recovered precision matrix: \\begin{equation} \\underset{\\boldsymbol \\Theta \\succeq \\mathbf{0}}{\\textrm{argmin}} \\left\\lbrack \\textrm{Tr}(\\hat{\\boldsymbol \\Sigma} \\boldsymbol \\Theta) - \\log \\det(\\boldsymbol \\Theta) + \\lambda \\sum_{i,j} | \\Theta_{ij} |\\right \\rbrack \\end{equation} The latter is a convex optimization problem in \\(\\boldsymbol \\Theta\\) . More details here and in the original paper by Tibshirani et al 6 .","title":"Covariance GLASSO CovarianceGLASSO \ud83d\udcd6"},{"location":"risk/#exponential-moving-average-covariance-covarianceexp","text":"This method of computing the covariance takes into account with an exponential moving average only the most recent observations, given a decay factor governed by the parameter span . Given a temporal span parameter \\(K\\) the tensor \\(\\mathbf{Q} \\in \\mathbb{R}^{T \\times N \\times N}\\) is obtained as: \\[\\begin{equation} Q_{tij} = Z_{ti} Z_{tj}. \\end{equation}\\] Finally, an exponential moving average is performed on \\(\\mathbf{Q}\\) over the temporal dimension \\(t\\) : \\[\\begin{equation} \\left(\\hat{\\boldsymbol \\Sigma}^{\\textrm{EWMA}}\\right)_{ij} = \\frac{\\sum \\limits_{\\tau=0}^T (1-\\alpha)^{\\tau} \\mathbf{Q}_{T-\\tau,i,j}}{\\sum \\limits_{\\tau=0}^T (1-\\alpha)^{\\tau}} \\end{equation}\\] where \\(\\alpha\\) is the decay factor \\(0\\leq \\alpha \\leq 1\\) uniquely specified by the span factor as \\(\\alpha = 2/(\\textrm{span}+1)\\) for \\(\\textrm{span}\\geq 1\\) .","title":"Exponential Moving Average Covariance CovarianceExp \ud83d\udcd6"},{"location":"risk/#hierarchical-filtered-covariance-average-linkage","text":"","title":"Hierarchical filtered covariance: average linkage \ud83d\udcd6"},{"location":"risk/#hierarchical-filtered-covariance-complete-linkage","text":"","title":"Hierarchical filtered covariance: complete linkage \ud83d\udcd6"},{"location":"risk/#hierarchical-filtered-covariance-single-linkage","text":"","title":"Hierarchical filtered covariance: single linkage\ud83d\udcd6"},{"location":"risk/#references","text":"Kritzman, Page & Turkington (2010) \"In defense of optimization: The fallacy of 1/N\". Financial Analysts Journal, 66(2), 31-39. \u21a9 O. Ledoit and M. Wolf, \"A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices\", Journal of Multivariate Analysis, Volume 88, Issue 2, February 2004, pages 365-411. http://www.ledoit.net/honey.pdf \u21a9 \u21a9 Estrada (2006), Mean-Semivariance Optimization: A Heuristic Approach \u21a9 Lo, A, \"The statistics of Sharpe ratio\". https://www.tandfonline.com/doi/abs/10.2469/faj.v58.n4.2453 https://doi.org/10.2469/faj.v58.n4.2453 \u21a9 MacMahon M, Garlaschelli D., \"Community detection for correlation matrices\". Phys. Rev. X 5, 02100 https://journals.aps.org/prx/pdf/10.1103/PhysRevX.5.021006 \u21a9 \u21a9 Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. \"Sparse inverse covariance estimation with the graphical lasso.\" Biostatistics 9.3 (2008): 432-441. \u21a9","title":"References"},{"location":"risk_api/","text":"Risk covariance estimators API \u00b6 SampleCovariance \u00b6 class skportfolio.riskreturn._risk_estimators. SampleCovariance ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator The standard sample covariance estimator, based on historical data. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceExp \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceExp ( returns_data=False , frequency=252 , span=60 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on exponential weighted average of returns Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceGlasso \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceGlasso ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on GLASSO algorithm Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceHierarchicalFilterAverage \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterAverage ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceHierarchicalFilterComplete \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterComplete ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceHierarchicalFilterSingle \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterSingle ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceLedoitWolf \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceLedoitWolf ( returns_data=False , frequency=252 , shrinkage_target='constant_variance' ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on the Ledoit-Wolf shrinkage Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. CovarianceRMT \u00b6 class skportfolio.riskreturn._risk_estimators. CovarianceRMT ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on Random Matrix Theory Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array. SemiCovariance \u00b6 class skportfolio.riskreturn._risk_estimators. SemiCovariance ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator The semicovariance, a.k.a. the covariance matrix estimated from only the positive returns. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"Risk estimators"},{"location":"risk_api/#risk-covariance-estimators-api","text":"","title":"Risk covariance estimators API"},{"location":"risk_api/#samplecovariance","text":"class skportfolio.riskreturn._risk_estimators. SampleCovariance ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator The standard sample covariance estimator, based on historical data. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"SampleCovariance"},{"location":"risk_api/#covarianceexp","text":"class skportfolio.riskreturn._risk_estimators. CovarianceExp ( returns_data=False , frequency=252 , span=60 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on exponential weighted average of returns Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceExp"},{"location":"risk_api/#covarianceglasso","text":"class skportfolio.riskreturn._risk_estimators. CovarianceGlasso ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on GLASSO algorithm Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceGlasso"},{"location":"risk_api/#covariancehierarchicalfilteraverage","text":"class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterAverage ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceHierarchicalFilterAverage"},{"location":"risk_api/#covariancehierarchicalfiltercomplete","text":"class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterComplete ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceHierarchicalFilterComplete"},{"location":"risk_api/#covariancehierarchicalfiltersingle","text":"class skportfolio.riskreturn._risk_estimators. CovarianceHierarchicalFilterSingle ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on hierarchical filtering approach. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceHierarchicalFilterSingle"},{"location":"risk_api/#covarianceledoitwolf","text":"class skportfolio.riskreturn._risk_estimators. CovarianceLedoitWolf ( returns_data=False , frequency=252 , shrinkage_target='constant_variance' ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on the Ledoit-Wolf shrinkage Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceLedoitWolf"},{"location":"risk_api/#covariancermt","text":"class skportfolio.riskreturn._risk_estimators. CovarianceRMT ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator Estimator of covariance based on Random Matrix Theory Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"CovarianceRMT"},{"location":"risk_api/#semicovariance","text":"class skportfolio.riskreturn._risk_estimators. SemiCovariance ( returns_data=False , frequency=252 ) Bases skportfolio.riskreturn._risk_estimators.BaseRiskEstimator sklearn.base.TransformerMixin sklearn.base.BaseEstimator The semicovariance, a.k.a. the covariance matrix estimated from only the positive returns. Methods fit_transform ( X , y , **fit_params ) (X_new : ndarray array of shape (n_samples, n_features_new)) \u2014 Fit to data, then transform it. get_params ( deep ) (params : dict) \u2014 Get parameters for this estimator. set_params ( **params ) (self : estimator instance) \u2014 Set the parameters of this estimator. method get_params ( deep=True ) Get parameters for this estimator. Parameters deep (bool, default=True) \u2014 If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns (params : dict) Parameter names mapped to their values. method set_params ( **params ) Set the parameters of this estimator. The method works on simple estimators as well as on nested objects (such as :class: ~sklearn.pipeline.Pipeline ). The latter have parameters of the form <component>__<parameter> so that it's possible to update each component of a nested object. Parameters **params (dict) \u2014 Estimator parameters. Returns (self : estimator instance) Estimator instance. method fit_transform ( X , y=None , **fit_params ) Fit to data, then transform it. Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X . Parameters X (array-like of shape (n_samples, n_features)) \u2014 Input samples. y (array-like of shape (n_samples,) or (n_samples, n_outputs), default=None) \u2014 Target values (None for unsupervised transformations). **fit_params (dict) \u2014 Additional fit parameters. Returns (X_new : ndarray array of shape (n_samples, n_features_new)) Transformed array.","title":"SemiCovariance"},{"location":"splitters/","text":"Cross validation splitters \u00b6 Similarly to what is done in scikit-learn here we have implemented a number of cross-validation techniques, useful to split data into adequately formed subsets of train, test and validation data.","title":"Cross validation"},{"location":"splitters/#cross-validation-splitters","text":"Similarly to what is done in scikit-learn here we have implemented a number of cross-validation techniques, useful to split data into adequately formed subsets of train, test and validation data.","title":"Cross validation splitters"}]}